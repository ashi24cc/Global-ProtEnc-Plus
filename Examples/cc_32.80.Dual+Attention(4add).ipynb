{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"32.200.80.Simple+Rank+Attention(4add).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"tLKiBOouMMv4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628311047316,"user_tz":-330,"elapsed":36506,"user":{"displayName":"Anonymous","photoUrl":"","userId":"09503349768777325188"}},"outputId":"dc85bfae-598d-43f8-b211-39a9c8494400"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MJ3-760liiG3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628311049394,"user_tz":-330,"elapsed":2097,"user":{"displayName":"Anonymous","photoUrl":"","userId":"09503349768777325188"}},"outputId":"1f8f9fbe-7075-4081-e2f6-811243bb6ebb"},"source":["from csv import writer\n","import pandas as pd\n","\n","def test_segment(filename, low, up):\n","    myFile = open(filename, 'w', newline = '')\n","    with myFile:\n","        csv_writer = writer(myFile)\n","        for j, row in enumerate(seqData):\n","            segment = [ ]\n","            if(len(row) > low and len(row) < up):\n","                segment.append(row)\n","                for item in label[j]:\n","                    segment.append(item)\n","                csv_writer.writerow(segment)\n","    myFile.close()\n","\n","dataframe = pd.read_csv(\"/content/gdrive/My Drive/Multi-Attn/CAFA3/cc/test_data_cc2.csv\", header=None)\n","dataset = dataframe.values\n","seqData = dataset[:,0]\n","label = dataset[:,1:len(dataset[0])]\n","print('Original Dataset Size : %s' %len(dataset))\n","test_segment('testData200.csv', 0, 201)\n","test_segment('testData500.csv', 200, 501)\n","test_segment('testData1000.csv', 500, 1001)\n","test_segment('testData16000.csv', 1000, 16000)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Original Dataset Size : 1265\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x86HGt91MVJd","executionInfo":{"status":"ok","timestamp":1628311049399,"user_tz":-330,"elapsed":21,"user":{"displayName":"Anonymous","photoUrl":"","userId":"09503349768777325188"}}},"source":["from csv import writer\n","import pandas as pd\n","import math\n","\n","def segment(dataset, label, seg_size, overlap):\n","    myFile = open('trainData_Seg.csv', 'w', newline = '')\n","    print(\"Non-overlapping Region: %s\" %overlap)\n","    print(\"Segment Size: %s\" %seg_size)\n","    with myFile:\n","        csv_writer = writer(myFile)\n","        for j, row in enumerate(dataset):\n","            if(len(row) < 2001):\n","                pos = math.ceil(len(row)/overlap)\n","                if(pos < math.ceil(seg_size/overlap)):\n","                    pos = math.ceil(seg_size/overlap)\n","                for itr in range(pos - math.ceil(seg_size/overlap) + 1):\n","                    init = itr * overlap\n","                    segment = [ ]\n","                    if(len(row[init : init + seg_size]) > 40):\n","                        segment.append(row[init : init + seg_size])\n","                        for item in label[j]:\n","                            segment.append(item)\n","                        csv_writer.writerow(segment)\n","    myFile.close()\n","\n","def main_fun(segSize, overLap):\n","  dataframe = pd.read_csv('/content/gdrive/My Drive/Multi-Attn/CAFA3/cc/train_data_cc2.csv', header=None)\n","  dataset = dataframe.values\n","  print('Original Dataset Size : %s' %len(dataset))\n","  X = dataset[:,0]\n","  Y = dataset[:,1:len(dataset[0])]\n","  segment(X, Y, segSize, overLap)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"51jBN91v-7fD","executionInfo":{"status":"ok","timestamp":1628311049401,"user_tz":-330,"elapsed":20,"user":{"displayName":"Anonymous","photoUrl":"","userId":"09503349768777325188"}}},"source":["import numpy as np\n","\n","def accuracy(y_true, y_pred, normalize=True, sample_weight=None):\n","    acc_list = []\n","    for i in range(y_true.shape[0]):\n","        set_true = set( np.where(y_true[i])[0] )\n","        set_pred = set( np.where(y_pred[i])[0] )\n","        #print('\\nset_true: {0}'.format(set_true), ', set_pred: {0}'.format(set_pred))\n","        tmp_a = None\n","        if len(set_true) == 0 and len(set_pred) == 0:\n","            tmp_a = 1\n","        else:\n","            tmp_a = len(set_true.intersection(set_pred))/\\\n","                    float( len(set_true.union(set_pred)) )\n","        acc_list.append(tmp_a)\n","    return np.mean(acc_list)\n","\n","def precision(y_true, y_pred, normalize=True, sample_weight=None):\n","    pre_list = []\n","    for i in range(y_true.shape[0]):\n","        set_true = set( np.where(y_true[i])[0] )\n","        set_pred = set( np.where(y_pred[i])[0] )\n","        tmp_prec = None\n","        if len(set_true) == 0 and len(set_pred) == 0:\n","            tmp_prec = 1\n","            pre_list.append(tmp_prec)\n","        elif len(set_pred) > 0:\n","            tmp_prec = len(set_true.intersection(set_pred))/\\\n","                    float(len(set_pred))\n","            pre_list.append(tmp_prec)\n","        else:\n","            None\n","    return np.mean(pre_list)\n","\n","def recall(y_true, y_pred, normalize=True, sample_weight=None):\n","    rec_list = []\n","    for i in range(y_true.shape[0]):\n","        set_true = set( np.where(y_true[i])[0] )\n","        set_pred = set( np.where(y_pred[i])[0] )\n","        tmp_rec = None\n","        if len(set_true) == 0 and len(set_pred) == 0:\n","            tmp_rec = 1\n","        else:\n","            tmp_rec = len(set_true.intersection(set_pred))/\\\n","                    float(len(set_true))\n","        rec_list.append(tmp_rec)\n","    return np.mean(rec_list)\n","\n","def f_score(y_true, y_pred, normalize=True, sample_weight=None):\n","    acc_list = []\n","    for i in range(y_true.shape[0]):\n","        set_true = set( np.where(y_true[i])[0] )\n","        set_pred = set( np.where(y_pred[i])[0] )\n","        tmp_a = None\n","        if len(set_true) == 0 and len(set_pred) == 0:\n","            tmp_a = 1\n","        else:\n","            tmp_a = (2*len(set_true.intersection(set_pred)))/\\\n","                    float( len(set_true) + len(set_pred))\n","        acc_list.append(tmp_a)\n","    return np.mean(acc_list)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"dSSTBBiyzk9f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628311193308,"user_tz":-330,"elapsed":143925,"user":{"displayName":"Anonymous","photoUrl":"","userId":"09503349768777325188"}},"outputId":"d8aea561-bb1a-4bf4-e6e2-c2ceb3dd85cf"},"source":["import numpy as np\n","import math\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, CuDNNGRU, Bidirectional, Input, Dropout, Add\n","from keras.layers import Flatten, Activation, RepeatVector, Permute, multiply, Lambda\n","from keras import backend as K\n","from keras.layers.embeddings import Embedding\n","from keras.preprocessing import sequence\n","from keras.callbacks import EarlyStopping\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from keras.models import load_model\n","import matplotlib.pyplot as plt\n","np.random.seed(7)\n","\n","def epsilon():\n","    _EPSILON = 1e-7\n","    return _EPSILON\n","\n","def _to_tensor(x, dtype):\n","    \"\"\"Convert the input `x` to a tensor of type `dtype`.\n","        x: An object to be converted (numpy array, list, tensors).\n","    # Returns: A tensor.\n","    \"\"\"\n","    return tf.convert_to_tensor(x, dtype=dtype)\n","\n","def categorical_crossentropy(target, output, from_logits=False):\n","    # Note: tf.nn.softmax_cross_entropy_with_logits expects logits, Keras expects probabilities.\n","    if not from_logits:\n","        # scale preds so that the class probas of each sample sum to 1\n","        output /= tf.reduce_sum(output, len(output.get_shape()) - 1, True)\n","\n","        # manual computation of crossentropy\n","        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)\n","        output = tf.clip_by_value(output, _epsilon, 1. - _epsilon)\n","\n","        return - tf.reduce_sum(target * tf.log(output), len(output.get_shape()) - 1)\n","    else:\n","        return tf.nn.softmax_cross_entropy_with_logits(labels=target, logits=output)\n","\n","def cls_predict(pred, normalize=True, sample_weight=None):\n","    pred1 = pred[0]\n","    pred2 = pred[1]\n","    y_pred1 = (pred2)**(1-pred1)\n","    y_pred2 = (pred1)**(1-pred2)\n","    y_pred = y_pred1 + y_pred2\n","    s_mean = np.mean(y_pred, axis=0)\n","    m = max(s_mean)\n","    s_mean = (s_mean/m)\n","    return(list(s_mean))\n","\n","def dictionary(chunk_size):\n","    dataframe = pd.read_csv(\"/content/gdrive/My Drive/Multi-Attn/CAFA3/cc/train_data_cc2.csv\", header=None)\n","    dataset = dataframe.values\n","    seq_dataset = dataset[:,0]\n","    print('Creating Dictionary:')\n","    dict = {}\n","    j = 0\n","    for row in seq_dataset:\n","        for i in range(len(row) - chunk_size + 1):\n","            key = row[i:i + chunk_size]\n","            if key not in dict:\n","                dict[key] = j\n","                j = j + 1\n","    del dataframe, dataset, seq_dataset\n","    return(dict)\n","\n","def nGram(dataset, chunk_size, dictI):\n","    dict1 = list()\n","    for j, row in enumerate(dataset):\n","        string = row\n","        dict2 = list()\n","        for i in range(len(string) - chunk_size + 1):\n","            try:\n","                dict2.append(dictI[string[i:i + chunk_size]])\n","            except:\n","                None\n","        dict1.append(dict2)   \n","    return(dict1)\n","\n","# CREATING DICTIONARY\n","chunkSize = 4\n","dict_Prop = dictionary(chunkSize)\n","\n","# Preparing For Training\n","segmentSize = 80\n","nonOL = 40\n","SEG = str(segmentSize)\n","max_seq_len = segmentSize - chunkSize + 1\n","main_fun(segmentSize, nonOL)                                       # Create segments\n","dataframe = pd.read_csv(\"trainData_Seg.csv\", header=None)\n","dataset = dataframe.values\n","\n","X = dataset[:,0]\n","Y = dataset[:,1:len(dataset[0])].astype(None)\n","nb_of_cls = len(Y[0])\n","del dataframe, dataset\n","\n","#Split the dataset\n","x_train, x_validate, y_train, y_validate = train_test_split(X, Y, test_size = 0.1, random_state = 42)\n","del X, Y\n","\n","#CREATING N-GRAM\n","x_train = nGram(x_train, chunkSize, dict_Prop)\n","x_validate = nGram(x_validate, chunkSize, dict_Prop)\n","\n","# truncate and pad input sequences\n","x_train = sequence.pad_sequences(x_train, maxlen=max_seq_len)\n","x_validate = sequence.pad_sequences(x_validate, maxlen=max_seq_len)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Creating Dictionary:\n","Original Dataset Size : 50596\n","Non-overlapping Region: 40\n","Segment Size: 80\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wH3YAz-2gqXZ","executionInfo":{"status":"ok","timestamp":1628314872315,"user_tz":-330,"elapsed":3679036,"user":{"displayName":"Anonymous","photoUrl":"","userId":"09503349768777325188"}},"outputId":"8de6b604-bdd6-4af5-fcdc-166ba7a0f73a"},"source":["def create_rec_model1(top_words, seq_len, o_dim):\n","    embedding_vecor_length = 32\n","\n","    _input = Input(shape=[seq_len])\n","    embdd = Embedding(top_words, embedding_vecor_length, input_length = seq_len)(_input)\n","    drop1 = Dropout(0.4)(embdd)\n","    activations = Bidirectional(CuDNNGRU(200, return_sequences=True))(drop1)\n","\n","    # compute importance for each step\n","    attention1 = Dense(1, activation='tanh')(activations)\n","    attention1 = Flatten()(attention1)\n","    attention1 = Activation('softmax')(attention1)\n","    \n","    attention2 = Dense(1, activation='tanh')(activations)\n","    attention2 = Flatten()(attention2)\n","    attention2 = Activation('softmax')(attention2)\n","\n","    attention3 = Dense(1, activation='tanh')(activations)\n","    attention3 = Flatten()(attention3)\n","    attention3 = Activation('softmax')(attention3)\n","\n","    attention4 = Dense(1, activation='tanh')(activations)\n","    attention4 = Flatten()(attention4)\n","    attention4 = Activation('softmax')(attention4)\n","    \n","    attention = Add()([attention1,attention2,attention3,attention4])\n","    attention = RepeatVector(400)(attention)\n","    attention = Permute([2, 1])(attention)\n","    \n","    sent_representation = multiply([activations, attention])\n","    sent_representation = Lambda(lambda xin: K.sum(xin, axis=1))(sent_representation)\n","\n","    drop2 = Dropout(0.5)(sent_representation)\n","\n","    den1 = Dense(o_dim, kernel_initializer='normal', activation='softmax', name='RANKING')(drop2)\n","    den2 = Dense(o_dim, kernel_initializer='normal', activation='sigmoid', name='CLASSIFIER')(drop2)\n","\n","    r_model = Model(inputs = [_input], outputs = [den1,den2])\n","    r_model.compile(loss=[categorical_crossentropy,'binary_crossentropy'], loss_weights=[0.30, 1.0],\n","                    optimizer='adam', metrics=['accuracy'])\n","    return r_model\n","\n","# Create & Compile the model\n","model = create_rec_model1(len(dict_Prop), max_seq_len, nb_of_cls)\n","print(model.summary())\n","early_stopping_monitor1 = EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 1)\n","history = model.fit(x_train, [y_train, y_train],\n","          validation_data = (x_validate, [y_validate, y_validate]),\n","          epochs = 1000,\n","          batch_size = 150,\n","          callbacks=[early_stopping_monitor1],\n","          verbose=1)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 77)           0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 77, 32)       5147424     input_1[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 77, 32)       0           embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","bidirectional_1 (Bidirectional) (None, 77, 400)      280800      dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 77, 1)        401         bidirectional_1[0][0]            \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 77, 1)        401         bidirectional_1[0][0]            \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 77, 1)        401         bidirectional_1[0][0]            \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 77, 1)        401         bidirectional_1[0][0]            \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 77)           0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","flatten_2 (Flatten)             (None, 77)           0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","flatten_3 (Flatten)             (None, 77)           0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","flatten_4 (Flatten)             (None, 77)           0           dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 77)           0           flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 77)           0           flatten_2[0][0]                  \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 77)           0           flatten_3[0][0]                  \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 77)           0           flatten_4[0][0]                  \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 77)           0           activation_1[0][0]               \n","                                                                 activation_2[0][0]               \n","                                                                 activation_3[0][0]               \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","repeat_vector_1 (RepeatVector)  (None, 400, 77)      0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","permute_1 (Permute)             (None, 77, 400)      0           repeat_vector_1[0][0]            \n","__________________________________________________________________________________________________\n","multiply_1 (Multiply)           (None, 77, 400)      0           bidirectional_1[0][0]            \n","                                                                 permute_1[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 400)          0           multiply_1[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 400)          0           lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","RANKING (Dense)                 (None, 551)          220951      dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","CLASSIFIER (Dense)              (None, 551)          220951      dropout_2[0][0]                  \n","==================================================================================================\n","Total params: 5,871,730\n","Trainable params: 5,871,730\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 533533 samples, validate on 59282 samples\n","Epoch 1/1000\n","533533/533533 [==============================] - 110s 206us/step - loss: 23.4046 - RANKING_loss: 77.7705 - CLASSIFIER_loss: 0.0735 - RANKING_accuracy: 0.0215 - CLASSIFIER_accuracy: 0.9765 - val_loss: 22.8041 - val_RANKING_loss: 75.7896 - val_CLASSIFIER_loss: 0.0661 - val_RANKING_accuracy: 0.0218 - val_CLASSIFIER_accuracy: 0.9781\n","Epoch 2/1000\n","533533/533533 [==============================] - 103s 193us/step - loss: 22.2993 - RANKING_loss: 74.1240 - CLASSIFIER_loss: 0.0622 - RANKING_accuracy: 0.0275 - CLASSIFIER_accuracy: 0.9788 - val_loss: 22.3674 - val_RANKING_loss: 74.3482 - val_CLASSIFIER_loss: 0.0627 - val_RANKING_accuracy: 0.0177 - val_CLASSIFIER_accuracy: 0.9787\n","Epoch 3/1000\n","533533/533533 [==============================] - 103s 194us/step - loss: 21.7213 - RANKING_loss: 72.2124 - CLASSIFIER_loss: 0.0576 - RANKING_accuracy: 0.0284 - CLASSIFIER_accuracy: 0.9797 - val_loss: 22.1503 - val_RANKING_loss: 73.6291 - val_CLASSIFIER_loss: 0.0610 - val_RANKING_accuracy: 0.0299 - val_CLASSIFIER_accuracy: 0.9790\n","Epoch 4/1000\n","533533/533533 [==============================] - 104s 195us/step - loss: 21.3528 - RANKING_loss: 70.9942 - CLASSIFIER_loss: 0.0546 - RANKING_accuracy: 0.0295 - CLASSIFIER_accuracy: 0.9804 - val_loss: 21.9422 - val_RANKING_loss: 72.9422 - val_CLASSIFIER_loss: 0.0594 - val_RANKING_accuracy: 0.0359 - val_CLASSIFIER_accuracy: 0.9793\n","Epoch 5/1000\n","533533/533533 [==============================] - 103s 193us/step - loss: 21.0603 - RANKING_loss: 70.0271 - CLASSIFIER_loss: 0.0522 - RANKING_accuracy: 0.0306 - CLASSIFIER_accuracy: 0.9810 - val_loss: 21.8026 - val_RANKING_loss: 72.4811 - val_CLASSIFIER_loss: 0.0583 - val_RANKING_accuracy: 0.0236 - val_CLASSIFIER_accuracy: 0.9795\n","Epoch 6/1000\n","533533/533533 [==============================] - 104s 195us/step - loss: 20.8238 - RANKING_loss: 69.2454 - CLASSIFIER_loss: 0.0502 - RANKING_accuracy: 0.0315 - CLASSIFIER_accuracy: 0.9814 - val_loss: 21.6680 - val_RANKING_loss: 72.0347 - val_CLASSIFIER_loss: 0.0573 - val_RANKING_accuracy: 0.0259 - val_CLASSIFIER_accuracy: 0.9797\n","Epoch 7/1000\n","533533/533533 [==============================] - 103s 193us/step - loss: 20.6340 - RANKING_loss: 68.6180 - CLASSIFIER_loss: 0.0486 - RANKING_accuracy: 0.0337 - CLASSIFIER_accuracy: 0.9818 - val_loss: 21.5634 - val_RANKING_loss: 71.6871 - val_CLASSIFIER_loss: 0.0565 - val_RANKING_accuracy: 0.0345 - val_CLASSIFIER_accuracy: 0.9800\n","Epoch 8/1000\n","533533/533533 [==============================] - 103s 193us/step - loss: 20.4826 - RANKING_loss: 68.1179 - CLASSIFIER_loss: 0.0473 - RANKING_accuracy: 0.0344 - CLASSIFIER_accuracy: 0.9822 - val_loss: 21.4937 - val_RANKING_loss: 71.4568 - val_CLASSIFIER_loss: 0.0559 - val_RANKING_accuracy: 0.0234 - val_CLASSIFIER_accuracy: 0.9801\n","Epoch 9/1000\n","533533/533533 [==============================] - 102s 192us/step - loss: 20.3570 - RANKING_loss: 67.7030 - CLASSIFIER_loss: 0.0462 - RANKING_accuracy: 0.0352 - CLASSIFIER_accuracy: 0.9825 - val_loss: 21.4054 - val_RANKING_loss: 71.1651 - val_CLASSIFIER_loss: 0.0553 - val_RANKING_accuracy: 0.0321 - val_CLASSIFIER_accuracy: 0.9802\n","Epoch 10/1000\n","533533/533533 [==============================] - 104s 195us/step - loss: 20.2517 - RANKING_loss: 67.3551 - CLASSIFIER_loss: 0.0452 - RANKING_accuracy: 0.0354 - CLASSIFIER_accuracy: 0.9827 - val_loss: 21.3333 - val_RANKING_loss: 70.9262 - val_CLASSIFIER_loss: 0.0546 - val_RANKING_accuracy: 0.0644 - val_CLASSIFIER_accuracy: 0.9803\n","Epoch 11/1000\n","533533/533533 [==============================] - 103s 193us/step - loss: 20.1616 - RANKING_loss: 67.0571 - CLASSIFIER_loss: 0.0444 - RANKING_accuracy: 0.0369 - CLASSIFIER_accuracy: 0.9830 - val_loss: 21.2729 - val_RANKING_loss: 70.7255 - val_CLASSIFIER_loss: 0.0542 - val_RANKING_accuracy: 0.0252 - val_CLASSIFIER_accuracy: 0.9805\n","Epoch 12/1000\n","533533/533533 [==============================] - 105s 197us/step - loss: 20.0801 - RANKING_loss: 66.7878 - CLASSIFIER_loss: 0.0437 - RANKING_accuracy: 0.0369 - CLASSIFIER_accuracy: 0.9832 - val_loss: 21.2272 - val_RANKING_loss: 70.5773 - val_CLASSIFIER_loss: 0.0538 - val_RANKING_accuracy: 0.0482 - val_CLASSIFIER_accuracy: 0.9806\n","Epoch 13/1000\n","533533/533533 [==============================] - 106s 198us/step - loss: 20.0125 - RANKING_loss: 66.5649 - CLASSIFIER_loss: 0.0430 - RANKING_accuracy: 0.0380 - CLASSIFIER_accuracy: 0.9834 - val_loss: 21.2500 - val_RANKING_loss: 70.6504 - val_CLASSIFIER_loss: 0.0539 - val_RANKING_accuracy: 0.0218 - val_CLASSIFIER_accuracy: 0.9808\n","Epoch 14/1000\n","533533/533533 [==============================] - 105s 197us/step - loss: 19.9502 - RANKING_loss: 66.3592 - CLASSIFIER_loss: 0.0425 - RANKING_accuracy: 0.0380 - CLASSIFIER_accuracy: 0.9836 - val_loss: 21.2217 - val_RANKING_loss: 70.5556 - val_CLASSIFIER_loss: 0.0538 - val_RANKING_accuracy: 0.0254 - val_CLASSIFIER_accuracy: 0.9807\n","Epoch 15/1000\n","533533/533533 [==============================] - 106s 198us/step - loss: 19.8973 - RANKING_loss: 66.1842 - CLASSIFIER_loss: 0.0420 - RANKING_accuracy: 0.0383 - CLASSIFIER_accuracy: 0.9837 - val_loss: 21.1653 - val_RANKING_loss: 70.3680 - val_CLASSIFIER_loss: 0.0534 - val_RANKING_accuracy: 0.0241 - val_CLASSIFIER_accuracy: 0.9809\n","Epoch 16/1000\n","533533/533533 [==============================] - 106s 198us/step - loss: 19.8478 - RANKING_loss: 66.0210 - CLASSIFIER_loss: 0.0415 - RANKING_accuracy: 0.0385 - CLASSIFIER_accuracy: 0.9839 - val_loss: 21.0917 - val_RANKING_loss: 70.1262 - val_CLASSIFIER_loss: 0.0527 - val_RANKING_accuracy: 0.0459 - val_CLASSIFIER_accuracy: 0.9810\n","Epoch 17/1000\n","533533/533533 [==============================] - 105s 197us/step - loss: 19.8049 - RANKING_loss: 65.8794 - CLASSIFIER_loss: 0.0411 - RANKING_accuracy: 0.0394 - CLASSIFIER_accuracy: 0.9840 - val_loss: 21.1615 - val_RANKING_loss: 70.3588 - val_CLASSIFIER_loss: 0.0533 - val_RANKING_accuracy: 0.0703 - val_CLASSIFIER_accuracy: 0.9809\n","Epoch 18/1000\n","533533/533533 [==============================] - 104s 195us/step - loss: 19.7585 - RANKING_loss: 65.7261 - CLASSIFIER_loss: 0.0407 - RANKING_accuracy: 0.0397 - CLASSIFIER_accuracy: 0.9842 - val_loss: 21.1436 - val_RANKING_loss: 70.2965 - val_CLASSIFIER_loss: 0.0532 - val_RANKING_accuracy: 0.0221 - val_CLASSIFIER_accuracy: 0.9810\n","Epoch 19/1000\n","533533/533533 [==============================] - 103s 193us/step - loss: 19.7235 - RANKING_loss: 65.6102 - CLASSIFIER_loss: 0.0403 - RANKING_accuracy: 0.0407 - CLASSIFIER_accuracy: 0.9843 - val_loss: 21.0711 - val_RANKING_loss: 70.0575 - val_CLASSIFIER_loss: 0.0525 - val_RANKING_accuracy: 0.0286 - val_CLASSIFIER_accuracy: 0.9811\n","Epoch 20/1000\n","533533/533533 [==============================] - 103s 193us/step - loss: 19.6916 - RANKING_loss: 65.5052 - CLASSIFIER_loss: 0.0400 - RANKING_accuracy: 0.0404 - CLASSIFIER_accuracy: 0.9844 - val_loss: 21.0066 - val_RANKING_loss: 69.8455 - val_CLASSIFIER_loss: 0.0520 - val_RANKING_accuracy: 0.0255 - val_CLASSIFIER_accuracy: 0.9811\n","Epoch 21/1000\n","533533/533533 [==============================] - 103s 193us/step - loss: 19.6561 - RANKING_loss: 65.3881 - CLASSIFIER_loss: 0.0397 - RANKING_accuracy: 0.0404 - CLASSIFIER_accuracy: 0.9845 - val_loss: 21.0833 - val_RANKING_loss: 70.0995 - val_CLASSIFIER_loss: 0.0528 - val_RANKING_accuracy: 0.0294 - val_CLASSIFIER_accuracy: 0.9811\n","Epoch 22/1000\n","533533/533533 [==============================] - 103s 193us/step - loss: 19.6233 - RANKING_loss: 65.2798 - CLASSIFIER_loss: 0.0394 - RANKING_accuracy: 0.0412 - CLASSIFIER_accuracy: 0.9846 - val_loss: 20.9638 - val_RANKING_loss: 69.7057 - val_CLASSIFIER_loss: 0.0516 - val_RANKING_accuracy: 0.0619 - val_CLASSIFIER_accuracy: 0.9811\n","Epoch 23/1000\n","533533/533533 [==============================] - 105s 197us/step - loss: 19.5983 - RANKING_loss: 65.1972 - CLASSIFIER_loss: 0.0391 - RANKING_accuracy: 0.0413 - CLASSIFIER_accuracy: 0.9847 - val_loss: 21.0068 - val_RANKING_loss: 69.8469 - val_CLASSIFIER_loss: 0.0520 - val_RANKING_accuracy: 0.0293 - val_CLASSIFIER_accuracy: 0.9813\n","Epoch 24/1000\n","533533/533533 [==============================] - 106s 198us/step - loss: 19.5716 - RANKING_loss: 65.1090 - CLASSIFIER_loss: 0.0389 - RANKING_accuracy: 0.0420 - CLASSIFIER_accuracy: 0.9848 - val_loss: 20.9156 - val_RANKING_loss: 69.5449 - val_CLASSIFIER_loss: 0.0512 - val_RANKING_accuracy: 0.0298 - val_CLASSIFIER_accuracy: 0.9813\n","Epoch 25/1000\n","533533/533533 [==============================] - 106s 198us/step - loss: 19.5474 - RANKING_loss: 65.0290 - CLASSIFIER_loss: 0.0386 - RANKING_accuracy: 0.0428 - CLASSIFIER_accuracy: 0.9849 - val_loss: 20.9584 - val_RANKING_loss: 69.6862 - val_CLASSIFIER_loss: 0.0517 - val_RANKING_accuracy: 0.0229 - val_CLASSIFIER_accuracy: 0.9812\n","Epoch 26/1000\n","533533/533533 [==============================] - 105s 198us/step - loss: 19.5233 - RANKING_loss: 64.9501 - CLASSIFIER_loss: 0.0384 - RANKING_accuracy: 0.0421 - CLASSIFIER_accuracy: 0.9850 - val_loss: 20.9958 - val_RANKING_loss: 69.8077 - val_CLASSIFIER_loss: 0.0520 - val_RANKING_accuracy: 0.0206 - val_CLASSIFIER_accuracy: 0.9813\n","Epoch 27/1000\n","533533/533533 [==============================] - 106s 198us/step - loss: 19.4985 - RANKING_loss: 64.8676 - CLASSIFIER_loss: 0.0381 - RANKING_accuracy: 0.0424 - CLASSIFIER_accuracy: 0.9850 - val_loss: 21.0028 - val_RANKING_loss: 69.8317 - val_CLASSIFIER_loss: 0.0520 - val_RANKING_accuracy: 0.0169 - val_CLASSIFIER_accuracy: 0.9815\n","Epoch 28/1000\n","533533/533533 [==============================] - 105s 197us/step - loss: 19.4808 - RANKING_loss: 64.8092 - CLASSIFIER_loss: 0.0379 - RANKING_accuracy: 0.0429 - CLASSIFIER_accuracy: 0.9851 - val_loss: 20.9015 - val_RANKING_loss: 69.4971 - val_CLASSIFIER_loss: 0.0510 - val_RANKING_accuracy: 0.0165 - val_CLASSIFIER_accuracy: 0.9815\n","Epoch 29/1000\n","533533/533533 [==============================] - 106s 199us/step - loss: 19.4585 - RANKING_loss: 64.7358 - CLASSIFIER_loss: 0.0377 - RANKING_accuracy: 0.0432 - CLASSIFIER_accuracy: 0.9852 - val_loss: 20.9290 - val_RANKING_loss: 69.5870 - val_CLASSIFIER_loss: 0.0514 - val_RANKING_accuracy: 0.0149 - val_CLASSIFIER_accuracy: 0.9814\n","Epoch 30/1000\n","533533/533533 [==============================] - 106s 198us/step - loss: 19.4424 - RANKING_loss: 64.6830 - CLASSIFIER_loss: 0.0376 - RANKING_accuracy: 0.0429 - CLASSIFIER_accuracy: 0.9853 - val_loss: 20.8384 - val_RANKING_loss: 69.2885 - val_CLASSIFIER_loss: 0.0506 - val_RANKING_accuracy: 0.0310 - val_CLASSIFIER_accuracy: 0.9815\n","Epoch 31/1000\n","533533/533533 [==============================] - 106s 199us/step - loss: 19.4231 - RANKING_loss: 64.6194 - CLASSIFIER_loss: 0.0374 - RANKING_accuracy: 0.0432 - CLASSIFIER_accuracy: 0.9853 - val_loss: 20.9672 - val_RANKING_loss: 69.7142 - val_CLASSIFIER_loss: 0.0519 - val_RANKING_accuracy: 0.0276 - val_CLASSIFIER_accuracy: 0.9814\n","Epoch 32/1000\n","533533/533533 [==============================] - 106s 199us/step - loss: 19.4094 - RANKING_loss: 64.5737 - CLASSIFIER_loss: 0.0373 - RANKING_accuracy: 0.0433 - CLASSIFIER_accuracy: 0.9854 - val_loss: 20.8741 - val_RANKING_loss: 69.4058 - val_CLASSIFIER_loss: 0.0511 - val_RANKING_accuracy: 0.0168 - val_CLASSIFIER_accuracy: 0.9814\n","Epoch 33/1000\n","533533/533533 [==============================] - 106s 198us/step - loss: 19.3921 - RANKING_loss: 64.5167 - CLASSIFIER_loss: 0.0371 - RANKING_accuracy: 0.0430 - CLASSIFIER_accuracy: 0.9854 - val_loss: 20.9966 - val_RANKING_loss: 69.8114 - val_CLASSIFIER_loss: 0.0521 - val_RANKING_accuracy: 0.0281 - val_CLASSIFIER_accuracy: 0.9815\n","Epoch 34/1000\n","533533/533533 [==============================] - 106s 199us/step - loss: 19.3771 - RANKING_loss: 64.4674 - CLASSIFIER_loss: 0.0370 - RANKING_accuracy: 0.0435 - CLASSIFIER_accuracy: 0.9855 - val_loss: 20.9188 - val_RANKING_loss: 69.5553 - val_CLASSIFIER_loss: 0.0515 - val_RANKING_accuracy: 0.0298 - val_CLASSIFIER_accuracy: 0.9816\n","Epoch 35/1000\n","533533/533533 [==============================] - 106s 198us/step - loss: 19.3637 - RANKING_loss: 64.4230 - CLASSIFIER_loss: 0.0368 - RANKING_accuracy: 0.0438 - CLASSIFIER_accuracy: 0.9855 - val_loss: 20.8878 - val_RANKING_loss: 69.4527 - val_CLASSIFIER_loss: 0.0512 - val_RANKING_accuracy: 0.0273 - val_CLASSIFIER_accuracy: 0.9816\n","Epoch 00035: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHTPWw5AqJaN","executionInfo":{"status":"ok","timestamp":1628315262805,"user_tz":-330,"elapsed":391025,"user":{"displayName":"Anonymous","photoUrl":"","userId":"09503349768777325188"}},"outputId":"793da8d0-1d42-48ac-8967-b826959addba"},"source":["def final_model(filename):\n","    print('Extracting features based on LSTM model...... ')\n","    dataframe2 = pd.read_csv(filename, header=None)\n","    dataset2 = dataframe2.values\n","    overlap = 30\n","    X_test = dataset2[:,0]\n","    Y_test = dataset2[:,1:len(dataset2[0])]\n","    c_p = []\n","    for tag, row in enumerate(X_test):\n","        pos = math.ceil(len(row) / overlap)\n","        if(pos < math.ceil(segmentSize/ overlap)):\n","            pos = math.ceil(segmentSize/ overlap)\n","        segment = [ ]\n","        for itr in range(pos - math.ceil(segmentSize/overlap) + 1):\n","            init = itr * overlap\n","            segment.append(row[init : init + segmentSize])\n","        seg_nGram = nGram(segment, chunkSize, dict_Prop)\n","        test_seg = sequence.pad_sequences(seg_nGram, maxlen=max_seq_len)\n","        preds = model.predict(test_seg)\n","        c_p.append(cls_predict(preds))\n","    c_p = np.array(c_p)\n","    return c_p, Y_test\n","\n","def create_nn_model(dim):\n","    n_model = Sequential()\n","    n_model.add(Dense(dim, input_dim = dim, kernel_initializer='normal', activation='relu'))\n","    n_model.add(Dense(dim, kernel_initializer='normal', activation='sigmoid'))\n","    n_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    return n_model\n","\n","# Creates a HDF5 file 'my_model.h5'\n","model_path = '/content/gdrive/My Drive/Multi-Attn/CAFA3/cc/simple+rank/0.3(4L)/32.200.model_'+str(nonOL)+'_'+ SEG +'.h5'\n","model.save(model_path)\n","#del model  \n","#model = load_model(model_path, custom_objects={'categorical_crossentropy': categorical_crossentropy})\n","\n","# Training\n","X_train_new, Y_train_new = final_model(\"/content/gdrive/My Drive/Multi-Attn/CAFA3/cc/train_data_cc2.csv\")\n","\n","# Training model 2\n","model1 = create_nn_model(Y_train_new[0].shape[0])\n","print(model1.summary())\n","early_stopping_monitor = EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 1)\n","model1.fit(X_train_new, Y_train_new.astype(None),\n","           callbacks = [early_stopping_monitor],\n","           validation_split = 0.1,\n","           epochs = 1000,\n","           batch_size = 150,\n","           verbose = True)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Extracting features based on LSTM model...... \n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_5 (Dense)              (None, 551)               304152    \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 551)               304152    \n","=================================================================\n","Total params: 608,304\n","Trainable params: 608,304\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Train on 45536 samples, validate on 5060 samples\n","Epoch 1/1000\n","45536/45536 [==============================] - 2s 41us/step - loss: 0.0764 - accuracy: 0.9807 - val_loss: 0.0305 - val_accuracy: 0.9898\n","Epoch 2/1000\n","45536/45536 [==============================] - 2s 38us/step - loss: 0.0291 - accuracy: 0.9901 - val_loss: 0.0258 - val_accuracy: 0.9913\n","Epoch 3/1000\n","45536/45536 [==============================] - 2s 38us/step - loss: 0.0263 - accuracy: 0.9909 - val_loss: 0.0242 - val_accuracy: 0.9917\n","Epoch 4/1000\n","45536/45536 [==============================] - 2s 38us/step - loss: 0.0249 - accuracy: 0.9913 - val_loss: 0.0232 - val_accuracy: 0.9920\n","Epoch 5/1000\n","45536/45536 [==============================] - 2s 40us/step - loss: 0.0240 - accuracy: 0.9915 - val_loss: 0.0227 - val_accuracy: 0.9920\n","Epoch 6/1000\n","45536/45536 [==============================] - 2s 39us/step - loss: 0.0233 - accuracy: 0.9917 - val_loss: 0.0221 - val_accuracy: 0.9923\n","Epoch 7/1000\n","45536/45536 [==============================] - 2s 40us/step - loss: 0.0228 - accuracy: 0.9918 - val_loss: 0.0217 - val_accuracy: 0.9923\n","Epoch 8/1000\n","45536/45536 [==============================] - 2s 40us/step - loss: 0.0223 - accuracy: 0.9920 - val_loss: 0.0214 - val_accuracy: 0.9924\n","Epoch 9/1000\n","45536/45536 [==============================] - 2s 40us/step - loss: 0.0219 - accuracy: 0.9920 - val_loss: 0.0210 - val_accuracy: 0.9925\n","Epoch 10/1000\n","45536/45536 [==============================] - 2s 40us/step - loss: 0.0216 - accuracy: 0.9921 - val_loss: 0.0207 - val_accuracy: 0.9926\n","Epoch 11/1000\n","45536/45536 [==============================] - 2s 40us/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 0.0205 - val_accuracy: 0.9927\n","Epoch 12/1000\n","45536/45536 [==============================] - 2s 40us/step - loss: 0.0211 - accuracy: 0.9923 - val_loss: 0.0203 - val_accuracy: 0.9927\n","Epoch 13/1000\n","45536/45536 [==============================] - 2s 40us/step - loss: 0.0209 - accuracy: 0.9923 - val_loss: 0.0202 - val_accuracy: 0.9928\n","Epoch 14/1000\n","45536/45536 [==============================] - 2s 40us/step - loss: 0.0207 - accuracy: 0.9924 - val_loss: 0.0201 - val_accuracy: 0.9928\n","Epoch 15/1000\n","45536/45536 [==============================] - 2s 40us/step - loss: 0.0205 - accuracy: 0.9924 - val_loss: 0.0202 - val_accuracy: 0.9927\n","Epoch 16/1000\n","45536/45536 [==============================] - 2s 40us/step - loss: 0.0204 - accuracy: 0.9925 - val_loss: 0.0200 - val_accuracy: 0.9928\n","Epoch 17/1000\n","45536/45536 [==============================] - 2s 40us/step - loss: 0.0202 - accuracy: 0.9925 - val_loss: 0.0198 - val_accuracy: 0.9928\n","Epoch 18/1000\n","45536/45536 [==============================] - 2s 39us/step - loss: 0.0201 - accuracy: 0.9925 - val_loss: 0.0198 - val_accuracy: 0.9928\n","Epoch 19/1000\n","45536/45536 [==============================] - 2s 38us/step - loss: 0.0199 - accuracy: 0.9926 - val_loss: 0.0196 - val_accuracy: 0.9929\n","Epoch 20/1000\n","45536/45536 [==============================] - 2s 38us/step - loss: 0.0198 - accuracy: 0.9926 - val_loss: 0.0197 - val_accuracy: 0.9929\n","Epoch 21/1000\n","45536/45536 [==============================] - 2s 39us/step - loss: 0.0197 - accuracy: 0.9927 - val_loss: 0.0195 - val_accuracy: 0.9929\n","Epoch 22/1000\n","45536/45536 [==============================] - 2s 39us/step - loss: 0.0196 - accuracy: 0.9927 - val_loss: 0.0196 - val_accuracy: 0.9929\n","Epoch 23/1000\n","45536/45536 [==============================] - 2s 38us/step - loss: 0.0195 - accuracy: 0.9927 - val_loss: 0.0195 - val_accuracy: 0.9929\n","Epoch 24/1000\n","45536/45536 [==============================] - 2s 38us/step - loss: 0.0194 - accuracy: 0.9928 - val_loss: 0.0194 - val_accuracy: 0.9930\n","Epoch 25/1000\n","45536/45536 [==============================] - 2s 38us/step - loss: 0.0193 - accuracy: 0.9928 - val_loss: 0.0195 - val_accuracy: 0.9929\n","Epoch 26/1000\n","45536/45536 [==============================] - 2s 39us/step - loss: 0.0192 - accuracy: 0.9928 - val_loss: 0.0194 - val_accuracy: 0.9929\n","Epoch 27/1000\n","45536/45536 [==============================] - 2s 39us/step - loss: 0.0191 - accuracy: 0.9928 - val_loss: 0.0193 - val_accuracy: 0.9930\n","Epoch 28/1000\n","45536/45536 [==============================] - 2s 39us/step - loss: 0.0190 - accuracy: 0.9929 - val_loss: 0.0194 - val_accuracy: 0.9929\n","Epoch 29/1000\n","45536/45536 [==============================] - 2s 39us/step - loss: 0.0189 - accuracy: 0.9929 - val_loss: 0.0192 - val_accuracy: 0.9930\n","Epoch 30/1000\n","45536/45536 [==============================] - 2s 39us/step - loss: 0.0189 - accuracy: 0.9929 - val_loss: 0.0194 - val_accuracy: 0.9930\n","Epoch 31/1000\n","45536/45536 [==============================] - 2s 39us/step - loss: 0.0188 - accuracy: 0.9929 - val_loss: 0.0194 - val_accuracy: 0.9930\n","Epoch 32/1000\n","45536/45536 [==============================] - 2s 38us/step - loss: 0.0187 - accuracy: 0.9930 - val_loss: 0.0193 - val_accuracy: 0.9929\n","Epoch 33/1000\n","45536/45536 [==============================] - 2s 38us/step - loss: 0.0186 - accuracy: 0.9930 - val_loss: 0.0191 - val_accuracy: 0.9931\n","Epoch 34/1000\n","45536/45536 [==============================] - 2s 39us/step - loss: 0.0186 - accuracy: 0.9930 - val_loss: 0.0191 - val_accuracy: 0.9930\n","Epoch 35/1000\n","45536/45536 [==============================] - 2s 39us/step - loss: 0.0185 - accuracy: 0.9930 - val_loss: 0.0191 - val_accuracy: 0.9931\n","Epoch 36/1000\n","45536/45536 [==============================] - 2s 39us/step - loss: 0.0185 - accuracy: 0.9930 - val_loss: 0.0192 - val_accuracy: 0.9931\n","Epoch 37/1000\n","45536/45536 [==============================] - 2s 38us/step - loss: 0.0184 - accuracy: 0.9930 - val_loss: 0.0191 - val_accuracy: 0.9931\n","Epoch 38/1000\n","45536/45536 [==============================] - 2s 38us/step - loss: 0.0183 - accuracy: 0.9931 - val_loss: 0.0190 - val_accuracy: 0.9931\n","Epoch 39/1000\n","45536/45536 [==============================] - 2s 39us/step - loss: 0.0183 - accuracy: 0.9931 - val_loss: 0.0191 - val_accuracy: 0.9931\n","Epoch 40/1000\n","45536/45536 [==============================] - 2s 38us/step - loss: 0.0182 - accuracy: 0.9931 - val_loss: 0.0192 - val_accuracy: 0.9930\n","Epoch 41/1000\n","45536/45536 [==============================] - 2s 39us/step - loss: 0.0182 - accuracy: 0.9931 - val_loss: 0.0191 - val_accuracy: 0.9931\n","Epoch 42/1000\n","45536/45536 [==============================] - 2s 40us/step - loss: 0.0181 - accuracy: 0.9931 - val_loss: 0.0191 - val_accuracy: 0.9931\n","Epoch 43/1000\n","45536/45536 [==============================] - 2s 40us/step - loss: 0.0181 - accuracy: 0.9932 - val_loss: 0.0190 - val_accuracy: 0.9931\n","Epoch 44/1000\n","45536/45536 [==============================] - 2s 40us/step - loss: 0.0180 - accuracy: 0.9932 - val_loss: 0.0190 - val_accuracy: 0.9931\n","Epoch 45/1000\n","45536/45536 [==============================] - 2s 40us/step - loss: 0.0180 - accuracy: 0.9932 - val_loss: 0.0190 - val_accuracy: 0.9931\n","Epoch 46/1000\n","45536/45536 [==============================] - 2s 40us/step - loss: 0.0179 - accuracy: 0.9932 - val_loss: 0.0190 - val_accuracy: 0.9931\n","Epoch 47/1000\n","45536/45536 [==============================] - 2s 40us/step - loss: 0.0179 - accuracy: 0.9932 - val_loss: 0.0190 - val_accuracy: 0.9931\n","Epoch 48/1000\n","45536/45536 [==============================] - 2s 40us/step - loss: 0.0178 - accuracy: 0.9932 - val_loss: 0.0191 - val_accuracy: 0.9930\n","Epoch 00048: early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f593e41ef10>"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"n0ZS26Si7lpt","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1628315281748,"user_tz":-330,"elapsed":19308,"user":{"displayName":"Anonymous","photoUrl":"","userId":"09503349768777325188"}},"outputId":"0c51e861-7456-41a5-a10d-68ed89929896"},"source":["from matplotlib import pyplot as plt\n","\n","# Testing\n","def test_fun(file):\n","    X_test_new, Y_test_new = final_model(file)\n","    print(X_test_new.shape, Y_test_new.shape)\n","    Y_test_new = np.array(Y_test_new).astype(None)\n","\n","    fmax, tmax = 0.0, 0.0\n","    precisions, recalls = [], []\n","    for t in range(1, 101, 1):\n","        test_preds = model1.predict(X_test_new)\n","\n","        threshold = t / 100.0\n","        print(\"THRESHOLD IS =====> \", threshold)\n","        test_preds[test_preds>=threshold] = int(1)\n","        test_preds[test_preds<threshold] = int(0)\n","\n","        rec = recall(Y_test_new, test_preds)\n","        pre = precision(Y_test_new, test_preds)\n","        recalls.append(rec)\n","        precisions.append(pre)\n","\n","        f1 = f_score(Y_test_new, test_preds)*100\n","        f = 2 * pre * rec / (pre + rec)\n","        print('Recall: {0}'.format(rec*100), '     Precision: {0}'.format(pre*100),\n","              '     F1-score1: {0}'.format(f*100), '      F1-score2: {0}'.format(f1))\n","\n","        if fmax < f:\n","            fmax = f\n","            tmax = threshold\n","    \n","    precisions = np.array(precisions)\n","    recalls = np.array(recalls)\n","    sorted_index = np.argsort(recalls)\n","    recalls = recalls[sorted_index]\n","    precisions = precisions[sorted_index]\n","    aupr = np.trapz(precisions, recalls)\n","    print(f'AUPR: {aupr:0.3f}')\n","\n","    plt.figure()\n","    plt.plot(recalls, precisions, color='darkorange', lw=2, label=f'AUPR curve (area = {aupr:0.2f})')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Recall')\n","    plt.ylabel('Precision')\n","    plt.title('Area Under the Precision-Recall curve')\n","    plt.legend(loc=\"upper right\")\n","    plt.savefig(f'aupr.pdf')\n","\n","    return tmax\n","\n","th_set = test_fun(\"/content/gdrive/My Drive/Multi-Attn/CAFA3/cc/test_data_cc2.csv\")"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Extracting features based on LSTM model...... \n","(1265, 551) (1265, 551)\n","THRESHOLD IS =====>  0.01\n","Recall: 86.52700828403931      Precision: 27.845830277723543      F1-score1: 42.13266746571863       F1-score2: 36.54271142351276\n","THRESHOLD IS =====>  0.02\n","Recall: 84.00940671106882      Precision: 32.786185672641764      F1-score1: 47.165273114565345       F1-score2: 41.267702954663534\n","THRESHOLD IS =====>  0.03\n","Recall: 82.38723448932303      Precision: 35.9626250362919      F1-score1: 50.06953508170942       F1-score2: 43.99523399505006\n","THRESHOLD IS =====>  0.04\n","Recall: 81.36850457918597      Precision: 38.46934428598819      F1-score1: 52.24047404613202       F1-score2: 46.03005973682479\n","THRESHOLD IS =====>  0.05\n","Recall: 80.2853525538098      Precision: 40.48657917377609      F1-score1: 53.82838936444527       F1-score2: 47.50069838616003\n","THRESHOLD IS =====>  0.06\n","Recall: 79.35341272405212      Precision: 42.20843398870863      F1-score1: 55.105830872349024       F1-score2: 48.69122799703365\n","THRESHOLD IS =====>  0.07\n","Recall: 78.62043585099998      Precision: 43.640192153952306      F1-score1: 56.1261787012274       F1-score2: 49.62162849192229\n","THRESHOLD IS =====>  0.08\n","Recall: 77.75882203541846      Precision: 44.89977069509814      F1-score1: 56.92798525060216       F1-score2: 50.36233084269325\n","THRESHOLD IS =====>  0.09\n","Recall: 76.90874186901797      Precision: 45.86772818876768      F1-score1: 57.46425623293955       F1-score2: 50.86681886057247\n","THRESHOLD IS =====>  0.1\n","Recall: 76.26293849231385      Precision: 46.89013729588919      F1-score1: 58.07373682883033       F1-score2: 51.399901539189784\n","THRESHOLD IS =====>  0.11\n","Recall: 75.74610870381984      Precision: 47.89756419876882      F1-score1: 58.68564107289915       F1-score2: 51.94011788189719\n","THRESHOLD IS =====>  0.12\n","Recall: 75.13688670616581      Precision: 48.777839056889896      F1-score1: 59.1538244453239       F1-score2: 52.31493224125763\n","THRESHOLD IS =====>  0.13\n","Recall: 74.6026607298268      Precision: 49.667884572183965      F1-score1: 59.633702144008936       F1-score2: 52.726525407128086\n","THRESHOLD IS =====>  0.14\n","Recall: 74.0341675715445      Precision: 50.480495645208975      F1-score1: 60.0295800854589       F1-score2: 53.034969225126126\n","THRESHOLD IS =====>  0.15\n","Recall: 73.44951103981127      Precision: 51.23755064024764      F1-score1: 60.365093068924736       F1-score2: 53.3147644807745\n","THRESHOLD IS =====>  0.16\n","Recall: 72.96944697080278      Precision: 52.01868476781425      F1-score1: 60.7381614054987       F1-score2: 53.59793636982392\n","THRESHOLD IS =====>  0.17\n","Recall: 72.48943669138717      Precision: 52.764536226485006      F1-score1: 61.0738552915702       F1-score2: 53.887864162266986\n","THRESHOLD IS =====>  0.18\n","Recall: 71.95637460477849      Precision: 53.337024558572146      F1-score1: 61.263226076853314       F1-score2: 54.052413931545864\n","THRESHOLD IS =====>  0.19\n","Recall: 71.48799542918881      Precision: 53.886473011388055      F1-score1: 61.451681259315436       F1-score2: 54.198558116769725\n","THRESHOLD IS =====>  0.2\n","Recall: 71.03478394468749      Precision: 54.434668197706394      F1-score1: 61.636594860340786       F1-score2: 54.32794193156765\n","THRESHOLD IS =====>  0.21\n","Recall: 70.6333691154006      Precision: 55.073475417097384      F1-score1: 61.89042660438625       F1-score2: 54.51009499035224\n","THRESHOLD IS =====>  0.22\n","Recall: 70.17828983731626      Precision: 55.661215108853646      F1-score1: 62.08239436856159       F1-score2: 54.66988886490968\n","THRESHOLD IS =====>  0.23\n","Recall: 69.62611394555293      Precision: 56.17448794460758      F1-score1: 62.181122183808114       F1-score2: 54.76056080557068\n","THRESHOLD IS =====>  0.24\n","Recall: 69.11918529032343      Precision: 56.78895191315172      F1-score1: 62.350316300606224       F1-score2: 54.9080006166816\n","THRESHOLD IS =====>  0.25\n","Recall: 68.68771640897116      Precision: 57.40038642557938      F1-score1: 62.538833972925445       F1-score2: 55.061791864295216\n","THRESHOLD IS =====>  0.26\n","Recall: 68.33625961586847      Precision: 57.99763252930029      F1-score1: 62.74391149247227       F1-score2: 55.20179453317028\n","THRESHOLD IS =====>  0.27\n","Recall: 67.96391176898219      Precision: 58.50199190727734      F1-score1: 62.87899110694918       F1-score2: 55.28525438171261\n","THRESHOLD IS =====>  0.28\n","Recall: 67.56534669704564      Precision: 59.06358411098292      F1-score1: 63.029064719476594       F1-score2: 55.38980921006487\n","THRESHOLD IS =====>  0.29\n","Recall: 67.08370850683414      Precision: 59.638704903231485      F1-score1: 63.14250790832392       F1-score2: 55.40235434256483\n","THRESHOLD IS =====>  0.3\n","Recall: 66.65611649719219      Precision: 60.07028132641607      F1-score1: 63.19206951161001       F1-score2: 55.39180907872926\n","THRESHOLD IS =====>  0.31\n","Recall: 66.21086016461881      Precision: 60.45082671499712      F1-score1: 63.199872559196315       F1-score2: 55.3603417832533\n","THRESHOLD IS =====>  0.32\n","Recall: 65.7821291283007      Precision: 60.92749295398131      F1-score1: 63.261813003589815       F1-score2: 55.38090337752132\n","THRESHOLD IS =====>  0.33\n","Recall: 65.38293898818517      Precision: 61.42259611278155      F1-score1: 63.34092357940485       F1-score2: 55.404420615865114\n","THRESHOLD IS =====>  0.34\n","Recall: 64.94402734586423      Precision: 61.819239237216394      F1-score1: 63.34311937111548       F1-score2: 55.34124636942992\n","THRESHOLD IS =====>  0.35\n","Recall: 64.6013463525876      Precision: 62.32689676856546      F1-score1: 63.44374342887373       F1-score2: 55.425158837633184\n","THRESHOLD IS =====>  0.36\n","Recall: 64.21042945445026      Precision: 62.690966181903875      F1-score1: 63.44160111508314       F1-score2: 55.393211860723014\n","THRESHOLD IS =====>  0.37\n","Recall: 63.894287705483045      Precision: 63.18210937284383      F1-score1: 63.53620289721441       F1-score2: 55.440883360557876\n","THRESHOLD IS =====>  0.38\n","Recall: 63.46918495787971      Precision: 63.622997315442      F1-score1: 63.5459980615365       F1-score2: 55.43475019528499\n","THRESHOLD IS =====>  0.39\n","Recall: 62.9907432286324      Precision: 64.02902903963536      F1-score1: 63.50564255297293       F1-score2: 55.33402768152285\n","THRESHOLD IS =====>  0.4\n","Recall: 62.546846302377816      Precision: 64.50101659488902      F1-score1: 63.50890253966538       F1-score2: 55.28028650844921\n","THRESHOLD IS =====>  0.41\n","Recall: 62.141678752951144      Precision: 64.91145595194556      F1-score1: 63.49637657537745       F1-score2: 55.248685967947765\n","THRESHOLD IS =====>  0.42\n","Recall: 61.75422309622053      Precision: 65.32653526454132      F1-score1: 63.49016932016076       F1-score2: 55.19854855752616\n","THRESHOLD IS =====>  0.43\n","Recall: 61.334159780838874      Precision: 65.70031853431426      F1-score1: 63.44220699893198       F1-score2: 55.09299215541543\n","THRESHOLD IS =====>  0.44\n","Recall: 60.93687188075707      Precision: 66.03074555397701      F1-score1: 63.38162695825803       F1-score2: 55.007324896146024\n","THRESHOLD IS =====>  0.45\n","Recall: 60.54993769540484      Precision: 66.53520927331125      F1-score1: 63.40163067272439       F1-score2: 54.997163381702954\n","THRESHOLD IS =====>  0.46\n","Recall: 60.15548360236379      Precision: 66.96978286605348      F1-score1: 63.379999695868484       F1-score2: 54.937513676255534\n","THRESHOLD IS =====>  0.47\n","Recall: 59.714221843740404      Precision: 67.29269049125655      F1-score1: 63.27735356416182       F1-score2: 54.77354162906003\n","THRESHOLD IS =====>  0.48\n","Recall: 59.37110746353361      Precision: 67.70670296999045      F1-score1: 63.26552093271501       F1-score2: 54.73108045910149\n","THRESHOLD IS =====>  0.49\n","Recall: 58.945532250176335      Precision: 68.12146794914132      F1-score1: 63.202187501504035       F1-score2: 54.58533274407954\n","THRESHOLD IS =====>  0.5\n","Recall: 58.673257813162515      Precision: 68.6255217155037      F1-score1: 63.26035399687102       F1-score2: 54.59945989166458\n","THRESHOLD IS =====>  0.51\n","Recall: 58.377299088779225      Precision: 69.03348900532158      F1-score1: 63.25977093602485       F1-score2: 54.55513770190865\n","THRESHOLD IS =====>  0.52\n","Recall: 57.96563228033689      Precision: 69.48038253140216      F1-score1: 63.20282843620827       F1-score2: 54.42934124502219\n","THRESHOLD IS =====>  0.53\n","Recall: 57.59341515338545      Precision: 69.81587608026186      F1-score1: 63.1183910757986       F1-score2: 54.27488270547865\n","THRESHOLD IS =====>  0.54\n","Recall: 57.20571222591777      Precision: 70.22485270416045      F1-score1: 63.05022216775007       F1-score2: 54.11896583829068\n","THRESHOLD IS =====>  0.55\n","Recall: 56.82652374935999      Precision: 70.61508649883662      F1-score1: 62.97487739168039       F1-score2: 54.005174932166945\n","THRESHOLD IS =====>  0.56\n","Recall: 56.44326491200092      Precision: 71.03808332410298      F1-score1: 62.90522357007169       F1-score2: 53.84800241354867\n","THRESHOLD IS =====>  0.57\n","Recall: 55.94632098789024      Precision: 71.35826389879773      F1-score1: 62.719380307852205       F1-score2: 53.653633931456355\n","THRESHOLD IS =====>  0.58\n","Recall: 55.53857708887849      Precision: 71.70684810811863      F1-score1: 62.59551265261882       F1-score2: 53.43345305061491\n","THRESHOLD IS =====>  0.59\n","Recall: 55.08788607408734      Precision: 72.15210835018789      F1-score1: 62.475751319933245       F1-score2: 53.26635096669135\n","THRESHOLD IS =====>  0.6\n","Recall: 54.71593305970225      Precision: 72.55849360731528      F1-score1: 62.3865419487217       F1-score2: 53.11307074798748\n","THRESHOLD IS =====>  0.61\n","Recall: 54.27218257847984      Precision: 73.0143980865457      F1-score1: 62.26344871717703       F1-score2: 52.88180836034518\n","THRESHOLD IS =====>  0.62\n","Recall: 53.85293365681688      Precision: 73.3656786081987      F1-score1: 62.112877234413375       F1-score2: 52.65329663212509\n","THRESHOLD IS =====>  0.63\n","Recall: 53.43913498665557      Precision: 73.75518083602047      F1-score1: 61.974672990200084       F1-score2: 52.43341155733546\n","THRESHOLD IS =====>  0.64\n","Recall: 53.03888023378559      Precision: 74.16866785559284      F1-score1: 61.84889419813725       F1-score2: 52.26160999068706\n","THRESHOLD IS =====>  0.65\n","Recall: 52.65972711218787      Precision: 74.70517698691927      F1-score1: 61.77454082543363       F1-score2: 52.08752816470656\n","THRESHOLD IS =====>  0.66\n","Recall: 52.16324900105579      Precision: 75.17672587524994      F1-score1: 61.59043575631248       F1-score2: 51.822434408886565\n","THRESHOLD IS =====>  0.67\n","Recall: 51.6938132822341      Precision: 75.44035584172863      F1-score1: 61.349355498994164       F1-score2: 51.51550303570782\n","THRESHOLD IS =====>  0.68\n","Recall: 51.27296541119409      Precision: 75.72900704433302      F1-score1: 61.14630637201854       F1-score2: 51.26061074183361\n","THRESHOLD IS =====>  0.69\n","Recall: 50.82818044320011      Precision: 76.15727106868255      F1-score1: 60.96659845444542       F1-score2: 51.061772995779364\n","THRESHOLD IS =====>  0.7\n","Recall: 50.45735571375711      Precision: 76.49470403024972      F1-score1: 60.805953038585336       F1-score2: 50.86594760180893\n","THRESHOLD IS =====>  0.71\n","Recall: 49.94776168933367      Precision: 76.9878434289038      F1-score1: 60.58773585206056       F1-score2: 50.60030826565535\n","THRESHOLD IS =====>  0.72\n","Recall: 49.56684946719426      Precision: 77.2499645261421      F1-score1: 60.38690363589453       F1-score2: 50.347092618269116\n","THRESHOLD IS =====>  0.73\n","Recall: 49.13857600666965      Precision: 77.55624315800321      F1-score1: 60.16036605660889       F1-score2: 50.05956770156047\n","THRESHOLD IS =====>  0.74\n","Recall: 48.64001562146964      Precision: 77.97748189511691      F1-score1: 59.90998103567009       F1-score2: 49.75218796716431\n","THRESHOLD IS =====>  0.75\n","Recall: 48.21879901079698      Precision: 78.40876174502573      F1-score1: 59.71490409673728       F1-score2: 49.55922249849246\n","THRESHOLD IS =====>  0.76\n","Recall: 47.6433314049914      Precision: 78.74114698856636      F1-score1: 59.366317903427515       F1-score2: 49.12960281942358\n","THRESHOLD IS =====>  0.77\n","Recall: 47.10463495833247      Precision: 79.116415598505      F1-score1: 59.05116237803993       F1-score2: 48.73047663621779\n","THRESHOLD IS =====>  0.78\n","Recall: 46.52094976801004      Precision: 79.59074151044739      F1-score1: 58.719962443936936       F1-score2: 48.32909652794458\n","THRESHOLD IS =====>  0.79\n","Recall: 45.9488996897976      Precision: 80.01562496758649      F1-score1: 58.37564084415525       F1-score2: 47.943807788642026\n","THRESHOLD IS =====>  0.8\n","Recall: 45.37854370201093      Precision: 80.53473765852229      F1-score1: 58.04866766839319       F1-score2: 47.58998807456454\n","THRESHOLD IS =====>  0.81\n","Recall: 44.640522178039554      Precision: 81.06709828139644      F1-score1: 57.57610533894003       F1-score2: 47.09599854291998\n","THRESHOLD IS =====>  0.82\n","Recall: 43.96902994521821      Precision: 81.3741597990348      F1-score1: 57.09034334088792       F1-score2: 46.59004243249609\n","THRESHOLD IS =====>  0.83\n","Recall: 43.233275153560605      Precision: 81.88979976896003      F1-score1: 56.59010934431904       F1-score2: 46.0204819160889\n","THRESHOLD IS =====>  0.84\n","Recall: 42.526819708060586      Precision: 82.38963986211758      F1-score1: 56.09780123907363       F1-score2: 45.59395521203247\n","THRESHOLD IS =====>  0.85\n","Recall: 41.72555996788239      Precision: 82.79432103712439      F1-score1: 55.48735478306044       F1-score2: 45.019357837276544\n","THRESHOLD IS =====>  0.86\n","Recall: 41.06649594854938      Precision: 83.5086626415867      F1-score1: 55.057656676522       F1-score2: 44.599466859200085\n","THRESHOLD IS =====>  0.87\n","Recall: 40.17538117035572      Precision: 84.15835202397855      F1-score1: 54.387394062199505       F1-score2: 43.93478504672835\n","THRESHOLD IS =====>  0.88\n","Recall: 39.30236766460309      Precision: 84.67214877143479      F1-score1: 53.68548339825661       F1-score2: 43.20930074927839\n","THRESHOLD IS =====>  0.89\n","Recall: 38.30852649783161      Precision: 85.24995010367819      F1-score1: 52.86241886937724       F1-score2: 42.383611346406575\n","THRESHOLD IS =====>  0.9\n","Recall: 37.33596796820258      Precision: 85.8716036457317      F1-score1: 52.043870374158566       F1-score2: 41.71826697769435\n","THRESHOLD IS =====>  0.91\n","Recall: 36.181830915182836      Precision: 86.51399628154047      F1-score1: 51.024307130455526       F1-score2: 40.79460706910399\n","THRESHOLD IS =====>  0.92\n","Recall: 35.18344738157815      Precision: 87.2439551123253      F1-score1: 50.14470684711486       F1-score2: 40.037375981284015\n","THRESHOLD IS =====>  0.93\n","Recall: 33.896988151645694      Precision: 88.01607476258657      F1-score1: 48.944383350956954       F1-score2: 38.93594920939625\n","THRESHOLD IS =====>  0.94\n","Recall: 32.67883448993295      Precision: 88.93411205563207      F1-score1: 47.79529171733791       F1-score2: 37.97829174482151\n","THRESHOLD IS =====>  0.95\n","Recall: 31.07230114362334      Precision: 89.86730411945722      F1-score1: 46.178155294803055       F1-score2: 36.7117587874846\n","THRESHOLD IS =====>  0.96\n","Recall: 29.462640434833876      Precision: 91.17584034604839      F1-score1: 44.53439703602669       F1-score2: 35.49915481547251\n","THRESHOLD IS =====>  0.97\n","Recall: 27.350739881248572      Precision: 92.41228235535476      F1-score1: 42.20909341349785       F1-score2: 33.8619279703387\n","THRESHOLD IS =====>  0.98\n","Recall: 24.88702638293596      Precision: 93.49735526085871      F1-score1: 39.31044137415054       F1-score2: 31.879119616125262\n","THRESHOLD IS =====>  0.99\n","Recall: 21.79978110339748      Precision: 95.61416226990461      F1-score1: 35.50460444449388       F1-score2: 29.39305704499701\n","THRESHOLD IS =====>  1.0\n","Recall: 1.6784318147841877      Precision: 100.0      F1-score1: 3.301451025211703       F1-score2: 2.6601379783701256\n","AUPR: 0.646\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"m3JKiOQd7oAY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628315289916,"user_tz":-330,"elapsed":8263,"user":{"displayName":"Anonymous","photoUrl":"","userId":"09503349768777325188"}},"outputId":"ce194491-f2b9-4b53-c5b2-473dd3e3944c"},"source":["# Testing\n","def test_fun1(file):\n","    X_test_new, Y_test_new = final_model(file)\n","    print(X_test_new.shape, Y_test_new.shape)\n","    test_preds = model1.predict(X_test_new)\n","    Y_test_new = np.array(Y_test_new).astype(None)\n","    test_preds[test_preds>=th_set] = int(1)\n","    test_preds[test_preds<th_set] = int(0)\n","    rec = recall(Y_test_new, test_preds)*100\n","    pre = precision(Y_test_new, test_preds)*100\n","    f1 = f_score(Y_test_new, test_preds)*100\n","    print('      Recall: {0}'.format(rec),  '       Precision: {0}'.format(pre),  '       F1-score: {0}'.format(f1))\n","\n","test_fun1(\"testData200.csv\")\n","test_fun1(\"testData500.csv\")\n","test_fun1(\"testData1000.csv\")\n","test_fun1(\"testData16000.csv\")"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Extracting features based on LSTM model...... \n","(251, 551) (251, 551)\n","      Recall: 58.32086820166719        Precision: 54.69970526142136        F1-score: 48.09956331293865\n","Extracting features based on LSTM model...... \n","(502, 551) (502, 551)\n","      Recall: 64.8032328863861        Precision: 63.112947173012934        F1-score: 55.94445664807428\n","Extracting features based on LSTM model...... \n","(367, 551) (367, 551)\n","      Recall: 65.97868633730893        Precision: 69.87213595383781        F1-score: 60.20643458268567\n","Extracting features based on LSTM model...... \n","(145, 551) (145, 551)\n","      Recall: 61.41089833338729        Precision: 65.01856694831986        F1-score: 54.29027500902739\n"],"name":"stdout"}]}]}