{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"32.200.80.Simple+Rank+Attention(4add).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"tLKiBOouMMv4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622257144007,"user_tz":-330,"elapsed":657,"user":{"displayName":"Bikku Kumar","photoUrl":"","userId":"05745485641699477877"}},"outputId":"df234d71-294e-40e4-b8a6-4982b615ab79"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MJ3-760liiG3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622257144666,"user_tz":-330,"elapsed":31,"user":{"displayName":"Bikku Kumar","photoUrl":"","userId":"05745485641699477877"}},"outputId":"6b7a5f82-a118-4b56-e15c-b4e0b1897984"},"source":["from csv import writer\n","import pandas as pd\n","\n","def test_segment(filename, low, up):\n","    myFile = open(filename, 'w', newline = '')\n","    with myFile:\n","        csv_writer = writer(myFile)\n","        for j, row in enumerate(seqData):\n","            segment = [ ]\n","            if(len(row) > low and len(row) < up):\n","                segment.append(row)\n","                for item in label[j]:\n","                    segment.append(item)\n","                csv_writer.writerow(segment)\n","    myFile.close()\n","\n","dataframe = pd.read_csv(\"/content/gdrive/My Drive/Multi-Attn/CAFA3/mf/test_data_mf1.csv\", header=None)\n","dataset = dataframe.values\n","seqData = dataset[:,0]\n","label = dataset[:,1:len(dataset[0])]\n","print('Original Dataset Size : %s' %len(dataset))\n","test_segment('testData200.csv', 0, 201)\n","test_segment('testData500.csv', 200, 501)\n","test_segment('testData1000.csv', 500, 1001)\n","test_segment('testData16000.csv', 1000, 16000)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Original Dataset Size : 1137\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x86HGt91MVJd"},"source":["from csv import writer\n","import pandas as pd\n","import math\n","\n","def segment(dataset, label, seg_size, overlap):\n","    myFile = open('trainData_Seg.csv', 'w', newline = '')\n","    print(\"Non-overlapping Region: %s\" %overlap)\n","    print(\"Segment Size: %s\" %seg_size)\n","    with myFile:\n","        csv_writer = writer(myFile)\n","        for j, row in enumerate(dataset):\n","            if(len(row) < 2001):\n","                pos = math.ceil(len(row)/overlap)\n","                if(pos < math.ceil(seg_size/overlap)):\n","                    pos = math.ceil(seg_size/overlap)\n","                for itr in range(pos - math.ceil(seg_size/overlap) + 1):\n","                    init = itr * overlap\n","                    segment = [ ]\n","                    if(len(row[init : init + seg_size]) > 40):\n","                        segment.append(row[init : init + seg_size])\n","                        for item in label[j]:\n","                            segment.append(item)\n","                        csv_writer.writerow(segment)\n","    myFile.close()\n","\n","def main_fun(segSize, overLap):\n","  dataframe = pd.read_csv('/content/gdrive/My Drive/Multi-Attn/CAFA3/mf/train_data_mf1.csv', header=None)\n","  dataset = dataframe.values\n","  print('Original Dataset Size : %s' %len(dataset))\n","  X = dataset[:,0]\n","  Y = dataset[:,1:len(dataset[0])]\n","  segment(X, Y, segSize, overLap)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"51jBN91v-7fD"},"source":["import numpy as np\n","\n","def accuracy(y_true, y_pred, normalize=True, sample_weight=None):\n","    acc_list = []\n","    for i in range(y_true.shape[0]):\n","        set_true = set( np.where(y_true[i])[0] )\n","        set_pred = set( np.where(y_pred[i])[0] )\n","        #print('\\nset_true: {0}'.format(set_true), ', set_pred: {0}'.format(set_pred))\n","        tmp_a = None\n","        if len(set_true) == 0 and len(set_pred) == 0:\n","            tmp_a = 1\n","        else:\n","            tmp_a = len(set_true.intersection(set_pred))/\\\n","                    float( len(set_true.union(set_pred)) )\n","        acc_list.append(tmp_a)\n","    return np.mean(acc_list)\n","\n","def precision(y_true, y_pred, normalize=True, sample_weight=None):\n","    pre_list = []\n","    for i in range(y_true.shape[0]):\n","        set_true = set( np.where(y_true[i])[0] )\n","        set_pred = set( np.where(y_pred[i])[0] )\n","        tmp_prec = None\n","        if len(set_true) == 0 and len(set_pred) == 0:\n","            tmp_prec = 1\n","            pre_list.append(tmp_prec)\n","        elif len(set_pred) > 0:\n","            tmp_prec = len(set_true.intersection(set_pred))/\\\n","                    float(len(set_pred))\n","            pre_list.append(tmp_prec)\n","        else:\n","            None\n","    return np.mean(pre_list)\n","\n","def recall(y_true, y_pred, normalize=True, sample_weight=None):\n","    rec_list = []\n","    for i in range(y_true.shape[0]):\n","        set_true = set( np.where(y_true[i])[0] )\n","        set_pred = set( np.where(y_pred[i])[0] )\n","        tmp_rec = None\n","        if len(set_true) == 0 and len(set_pred) == 0:\n","            tmp_rec = 1\n","        else:\n","            tmp_rec = len(set_true.intersection(set_pred))/\\\n","                    float(len(set_true))\n","        rec_list.append(tmp_rec)\n","    return np.mean(rec_list)\n","\n","def f_score(y_true, y_pred, normalize=True, sample_weight=None):\n","    acc_list = []\n","    for i in range(y_true.shape[0]):\n","        set_true = set( np.where(y_true[i])[0] )\n","        set_pred = set( np.where(y_pred[i])[0] )\n","        tmp_a = None\n","        if len(set_true) == 0 and len(set_pred) == 0:\n","            tmp_a = 1\n","        else:\n","            tmp_a = (2*len(set_true.intersection(set_pred)))/\\\n","                    float( len(set_true) + len(set_pred))\n","        acc_list.append(tmp_a)\n","    return np.mean(acc_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dSSTBBiyzk9f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622257256648,"user_tz":-330,"elapsed":111993,"user":{"displayName":"Bikku Kumar","photoUrl":"","userId":"05745485641699477877"}},"outputId":"221545e9-a034-4572-aaf7-b719f03eb5b9"},"source":["import numpy as np\n","import math\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, CuDNNGRU, Bidirectional, Input, Dropout, Add\n","from keras.layers import Flatten, Activation, RepeatVector, Permute, multiply, Lambda\n","from keras import backend as K\n","from keras.layers.embeddings import Embedding\n","from keras.preprocessing import sequence\n","from keras.callbacks import EarlyStopping\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from keras.models import load_model\n","import matplotlib.pyplot as plt\n","np.random.seed(7)\n","\n","def epsilon():\n","    _EPSILON = 1e-7\n","    return _EPSILON\n","\n","def _to_tensor(x, dtype):\n","    \"\"\"Convert the input `x` to a tensor of type `dtype`.\n","        x: An object to be converted (numpy array, list, tensors).\n","    # Returns: A tensor.\n","    \"\"\"\n","    return tf.convert_to_tensor(x, dtype=dtype)\n","\n","def categorical_crossentropy(target, output, from_logits=False):\n","    # Note: tf.nn.softmax_cross_entropy_with_logits expects logits, Keras expects probabilities.\n","    if not from_logits:\n","        # scale preds so that the class probas of each sample sum to 1\n","        output /= tf.reduce_sum(output, len(output.get_shape()) - 1, True)\n","\n","        # manual computation of crossentropy\n","        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)\n","        output = tf.clip_by_value(output, _epsilon, 1. - _epsilon)\n","\n","        return - tf.reduce_sum(target * tf.log(output), len(output.get_shape()) - 1)\n","    else:\n","        return tf.nn.softmax_cross_entropy_with_logits(labels=target, logits=output)\n","\n","def cls_predict(pred, normalize=True, sample_weight=None):\n","    pred1 = pred[0]\n","    pred2 = pred[1]\n","    y_pred1 = (pred2)**(1-pred1)\n","    y_pred2 = (pred1)**(1-pred2)\n","    y_pred = y_pred1 + y_pred2\n","    s_mean = np.mean(y_pred, axis=0)\n","    m = max(s_mean)\n","    s_mean = (s_mean/m)\n","    return(list(s_mean))\n","\n","def dictionary(chunk_size):\n","    dataframe = pd.read_csv(\"/content/gdrive/My Drive/Multi-Attn/CAFA3/mf/train_data_mf1.csv\", header=None)\n","    dataset = dataframe.values\n","    seq_dataset = dataset[:,0]\n","    print('Creating Dictionary:')\n","    dict = {}\n","    j = 0\n","    for row in seq_dataset:\n","        for i in range(len(row) - chunk_size + 1):\n","            key = row[i:i + chunk_size]\n","            if key not in dict:\n","                dict[key] = j\n","                j = j + 1\n","    del dataframe, dataset, seq_dataset\n","    return(dict)\n","\n","def nGram(dataset, chunk_size, dictI):\n","    dict1 = list()\n","    for j, row in enumerate(dataset):\n","        string = row\n","        dict2 = list()\n","        for i in range(len(string) - chunk_size + 1):\n","            try:\n","                dict2.append(dictI[string[i:i + chunk_size]])\n","            except:\n","                None\n","        dict1.append(dict2)   \n","    return(dict1)\n","\n","# CREATING DICTIONARY\n","chunkSize = 4\n","dict_Prop = dictionary(chunkSize)\n","\n","# Preparing For Training\n","segmentSize = 80\n","nonOL = 40\n","SEG = str(segmentSize)\n","max_seq_len = segmentSize - chunkSize + 1\n","main_fun(segmentSize, nonOL)                                       # Create segments\n","dataframe = pd.read_csv(\"trainData_Seg.csv\", header=None)\n","dataset = dataframe.values\n","\n","X = dataset[:,0]\n","Y = dataset[:,1:len(dataset[0])].astype(None)\n","nb_of_cls = len(Y[0])\n","del dataframe, dataset\n","\n","#Split the dataset\n","x_train, x_validate, y_train, y_validate = train_test_split(X, Y, test_size = 0.1, random_state = 42)\n","del X, Y\n","\n","#CREATING N-GRAM\n","x_train = nGram(x_train, chunkSize, dict_Prop)\n","x_validate = nGram(x_validate, chunkSize, dict_Prop)\n","\n","# truncate and pad input sequences\n","x_train = sequence.pad_sequences(x_train, maxlen=max_seq_len)\n","x_validate = sequence.pad_sequences(x_validate, maxlen=max_seq_len)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Creating Dictionary:\n","Original Dataset Size : 36110\n","Non-overlapping Region: 40\n","Segment Size: 80\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wH3YAz-2gqXZ","executionInfo":{"status":"ok","timestamp":1622260962011,"user_tz":-330,"elapsed":3705380,"user":{"displayName":"Bikku Kumar","photoUrl":"","userId":"05745485641699477877"}},"outputId":"a109f333-fb87-4a87-b48a-f9789bb286a4"},"source":["def create_rec_model1(top_words, seq_len, o_dim):\n","    embedding_vecor_length = 32\n","\n","    _input = Input(shape=[seq_len])\n","    embdd = Embedding(top_words, embedding_vecor_length, input_length = seq_len)(_input)\n","    drop1 = Dropout(0.4)(embdd)\n","    activations = Bidirectional(CuDNNGRU(200, return_sequences=True))(drop1)\n","\n","    # compute importance for each step\n","    attention1 = Dense(1, activation='tanh')(activations)\n","    attention1 = Flatten()(attention1)\n","    attention1 = Activation('softmax')(attention1)\n","    \n","    attention2 = Dense(1, activation='tanh')(activations)\n","    attention2 = Flatten()(attention2)\n","    attention2 = Activation('softmax')(attention2)\n","\n","    attention3 = Dense(1, activation='tanh')(activations)\n","    attention3 = Flatten()(attention3)\n","    attention3 = Activation('softmax')(attention3)\n","\n","    attention4 = Dense(1, activation='tanh')(activations)\n","    attention4 = Flatten()(attention4)\n","    attention4 = Activation('softmax')(attention4)\n","    \n","    attention = Add()([attention1,attention2,attention3,attention4])\n","    attention = RepeatVector(400)(attention)\n","    attention = Permute([2, 1])(attention)\n","    \n","    sent_representation = multiply([activations, attention])\n","    sent_representation = Lambda(lambda xin: K.sum(xin, axis=1))(sent_representation)\n","\n","    drop2 = Dropout(0.5)(sent_representation)\n","\n","    den1 = Dense(o_dim, kernel_initializer='normal', activation='softmax', name='RANKING')(drop2)\n","    den2 = Dense(o_dim, kernel_initializer='normal', activation='sigmoid', name='CLASSIFIER')(drop2)\n","\n","    r_model = Model(inputs = [_input], outputs = [den1,den2])\n","    r_model.compile(loss=[categorical_crossentropy,'binary_crossentropy'], loss_weights=[0.30, 1.0],\n","                    optimizer='adam', metrics=['accuracy'])\n","    return r_model\n","\n","# Create & Compile the model\n","model = create_rec_model1(len(dict_Prop), max_seq_len, nb_of_cls)\n","print(model.summary())\n","early_stopping_monitor1 = EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 1)\n","history = model.fit(x_train, [y_train, y_train],\n","          validation_data = (x_validate, [y_validate, y_validate]),\n","          epochs = 1000,\n","          batch_size = 150,\n","          callbacks=[early_stopping_monitor1],\n","          verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 77)           0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 77, 32)       5142432     input_1[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 77, 32)       0           embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","bidirectional_1 (Bidirectional) (None, 77, 400)      280800      dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 77, 1)        401         bidirectional_1[0][0]            \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 77, 1)        401         bidirectional_1[0][0]            \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 77, 1)        401         bidirectional_1[0][0]            \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 77, 1)        401         bidirectional_1[0][0]            \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 77)           0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","flatten_2 (Flatten)             (None, 77)           0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","flatten_3 (Flatten)             (None, 77)           0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","flatten_4 (Flatten)             (None, 77)           0           dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 77)           0           flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 77)           0           flatten_2[0][0]                  \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 77)           0           flatten_3[0][0]                  \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 77)           0           flatten_4[0][0]                  \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 77)           0           activation_1[0][0]               \n","                                                                 activation_2[0][0]               \n","                                                                 activation_3[0][0]               \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","repeat_vector_1 (RepeatVector)  (None, 400, 77)      0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","permute_1 (Permute)             (None, 77, 400)      0           repeat_vector_1[0][0]            \n","__________________________________________________________________________________________________\n","multiply_1 (Multiply)           (None, 77, 400)      0           bidirectional_1[0][0]            \n","                                                                 permute_1[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 400)          0           multiply_1[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 400)          0           lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","RANKING (Dense)                 (None, 677)          271477      dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","CLASSIFIER (Dense)              (None, 677)          271477      dropout_2[0][0]                  \n","==================================================================================================\n","Total params: 5,967,790\n","Trainable params: 5,967,790\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 388863 samples, validate on 43208 samples\n","Epoch 1/1000\n","388863/388863 [==============================] - 68s 175us/step - loss: 18.2064 - RANKING_loss: 60.4759 - CLASSIFIER_loss: 0.0635 - RANKING_accuracy: 0.0539 - CLASSIFIER_accuracy: 0.9835 - val_loss: 17.4099 - val_RANKING_loss: 57.9216 - val_CLASSIFIER_loss: 0.0538 - val_RANKING_accuracy: 0.0543 - val_CLASSIFIER_accuracy: 0.9850\n","Epoch 2/1000\n","388863/388863 [==============================] - 64s 165us/step - loss: 16.6857 - RANKING_loss: 55.4533 - CLASSIFIER_loss: 0.0498 - RANKING_accuracy: 0.0538 - CLASSIFIER_accuracy: 0.9857 - val_loss: 16.7487 - val_RANKING_loss: 55.7366 - val_CLASSIFIER_loss: 0.0496 - val_RANKING_accuracy: 0.0530 - val_CLASSIFIER_accuracy: 0.9857\n","Epoch 3/1000\n","388863/388863 [==============================] - 65s 166us/step - loss: 15.8533 - RANKING_loss: 52.6945 - CLASSIFIER_loss: 0.0445 - RANKING_accuracy: 0.0587 - CLASSIFIER_accuracy: 0.9867 - val_loss: 16.3467 - val_RANKING_loss: 54.3916 - val_CLASSIFIER_loss: 0.0471 - val_RANKING_accuracy: 0.0604 - val_CLASSIFIER_accuracy: 0.9861\n","Epoch 4/1000\n","388863/388863 [==============================] - 64s 165us/step - loss: 15.3224 - RANKING_loss: 50.9356 - CLASSIFIER_loss: 0.0412 - RANKING_accuracy: 0.0641 - CLASSIFIER_accuracy: 0.9873 - val_loss: 16.1081 - val_RANKING_loss: 53.5878 - val_CLASSIFIER_loss: 0.0456 - val_RANKING_accuracy: 0.0564 - val_CLASSIFIER_accuracy: 0.9863\n","Epoch 5/1000\n","388863/388863 [==============================] - 64s 166us/step - loss: 14.9663 - RANKING_loss: 49.7573 - CLASSIFIER_loss: 0.0389 - RANKING_accuracy: 0.0693 - CLASSIFIER_accuracy: 0.9877 - val_loss: 15.8890 - val_RANKING_loss: 52.8751 - val_CLASSIFIER_loss: 0.0443 - val_RANKING_accuracy: 0.0639 - val_CLASSIFIER_accuracy: 0.9866\n","Epoch 6/1000\n","388863/388863 [==============================] - 65s 166us/step - loss: 14.6932 - RANKING_loss: 48.8541 - CLASSIFIER_loss: 0.0371 - RANKING_accuracy: 0.0735 - CLASSIFIER_accuracy: 0.9881 - val_loss: 15.7564 - val_RANKING_loss: 52.4374 - val_CLASSIFIER_loss: 0.0435 - val_RANKING_accuracy: 0.0629 - val_CLASSIFIER_accuracy: 0.9868\n","Epoch 7/1000\n","388863/388863 [==============================] - 64s 165us/step - loss: 14.4755 - RANKING_loss: 48.1347 - CLASSIFIER_loss: 0.0357 - RANKING_accuracy: 0.0773 - CLASSIFIER_accuracy: 0.9884 - val_loss: 15.6255 - val_RANKING_loss: 51.9916 - val_CLASSIFIER_loss: 0.0427 - val_RANKING_accuracy: 0.0604 - val_CLASSIFIER_accuracy: 0.9870\n","Epoch 8/1000\n","388863/388863 [==============================] - 64s 166us/step - loss: 14.2925 - RANKING_loss: 47.5285 - CLASSIFIER_loss: 0.0344 - RANKING_accuracy: 0.0793 - CLASSIFIER_accuracy: 0.9887 - val_loss: 15.4778 - val_RANKING_loss: 51.4996 - val_CLASSIFIER_loss: 0.0418 - val_RANKING_accuracy: 0.0717 - val_CLASSIFIER_accuracy: 0.9870\n","Epoch 9/1000\n","388863/388863 [==============================] - 65s 168us/step - loss: 14.1423 - RANKING_loss: 47.0291 - CLASSIFIER_loss: 0.0334 - RANKING_accuracy: 0.0810 - CLASSIFIER_accuracy: 0.9889 - val_loss: 15.4556 - val_RANKING_loss: 51.4396 - val_CLASSIFIER_loss: 0.0415 - val_RANKING_accuracy: 0.0644 - val_CLASSIFIER_accuracy: 0.9872\n","Epoch 10/1000\n","388863/388863 [==============================] - 65s 168us/step - loss: 14.0145 - RANKING_loss: 46.6051 - CLASSIFIER_loss: 0.0325 - RANKING_accuracy: 0.0832 - CLASSIFIER_accuracy: 0.9891 - val_loss: 15.3532 - val_RANKING_loss: 51.0888 - val_CLASSIFIER_loss: 0.0410 - val_RANKING_accuracy: 0.0759 - val_CLASSIFIER_accuracy: 0.9873\n","Epoch 11/1000\n","388863/388863 [==============================] - 64s 166us/step - loss: 13.9015 - RANKING_loss: 46.2328 - CLASSIFIER_loss: 0.0317 - RANKING_accuracy: 0.0843 - CLASSIFIER_accuracy: 0.9893 - val_loss: 15.2786 - val_RANKING_loss: 50.8422 - val_CLASSIFIER_loss: 0.0405 - val_RANKING_accuracy: 0.0821 - val_CLASSIFIER_accuracy: 0.9873\n","Epoch 12/1000\n","388863/388863 [==============================] - 65s 166us/step - loss: 13.7982 - RANKING_loss: 45.8931 - CLASSIFIER_loss: 0.0310 - RANKING_accuracy: 0.0851 - CLASSIFIER_accuracy: 0.9895 - val_loss: 15.1768 - val_RANKING_loss: 50.5038 - val_CLASSIFIER_loss: 0.0399 - val_RANKING_accuracy: 0.0865 - val_CLASSIFIER_accuracy: 0.9874\n","Epoch 13/1000\n","388863/388863 [==============================] - 64s 166us/step - loss: 13.7121 - RANKING_loss: 45.6083 - CLASSIFIER_loss: 0.0304 - RANKING_accuracy: 0.0867 - CLASSIFIER_accuracy: 0.9896 - val_loss: 15.1842 - val_RANKING_loss: 50.5323 - val_CLASSIFIER_loss: 0.0400 - val_RANKING_accuracy: 0.0805 - val_CLASSIFIER_accuracy: 0.9876\n","Epoch 14/1000\n","388863/388863 [==============================] - 65s 166us/step - loss: 13.6364 - RANKING_loss: 45.3561 - CLASSIFIER_loss: 0.0298 - RANKING_accuracy: 0.0873 - CLASSIFIER_accuracy: 0.9898 - val_loss: 15.0485 - val_RANKING_loss: 50.0760 - val_CLASSIFIER_loss: 0.0391 - val_RANKING_accuracy: 0.0800 - val_CLASSIFIER_accuracy: 0.9876\n","Epoch 15/1000\n","388863/388863 [==============================] - 65s 166us/step - loss: 13.5645 - RANKING_loss: 45.1158 - CLASSIFIER_loss: 0.0293 - RANKING_accuracy: 0.0884 - CLASSIFIER_accuracy: 0.9899 - val_loss: 15.0505 - val_RANKING_loss: 50.0857 - val_CLASSIFIER_loss: 0.0391 - val_RANKING_accuracy: 0.0797 - val_CLASSIFIER_accuracy: 0.9876\n","Epoch 16/1000\n","388863/388863 [==============================] - 64s 166us/step - loss: 13.5022 - RANKING_loss: 44.9105 - CLASSIFIER_loss: 0.0289 - RANKING_accuracy: 0.0893 - CLASSIFIER_accuracy: 0.9900 - val_loss: 15.0230 - val_RANKING_loss: 49.9955 - val_CLASSIFIER_loss: 0.0389 - val_RANKING_accuracy: 0.0791 - val_CLASSIFIER_accuracy: 0.9877\n","Epoch 17/1000\n","388863/388863 [==============================] - 65s 166us/step - loss: 13.4430 - RANKING_loss: 44.7158 - CLASSIFIER_loss: 0.0284 - RANKING_accuracy: 0.0893 - CLASSIFIER_accuracy: 0.9901 - val_loss: 14.9809 - val_RANKING_loss: 49.8515 - val_CLASSIFIER_loss: 0.0385 - val_RANKING_accuracy: 0.0813 - val_CLASSIFIER_accuracy: 0.9879\n","Epoch 18/1000\n","388863/388863 [==============================] - 64s 166us/step - loss: 13.3959 - RANKING_loss: 44.5586 - CLASSIFIER_loss: 0.0281 - RANKING_accuracy: 0.0903 - CLASSIFIER_accuracy: 0.9902 - val_loss: 14.9485 - val_RANKING_loss: 49.7489 - val_CLASSIFIER_loss: 0.0385 - val_RANKING_accuracy: 0.0757 - val_CLASSIFIER_accuracy: 0.9879\n","Epoch 19/1000\n","388863/388863 [==============================] - 65s 166us/step - loss: 13.3458 - RANKING_loss: 44.3922 - CLASSIFIER_loss: 0.0277 - RANKING_accuracy: 0.0905 - CLASSIFIER_accuracy: 0.9903 - val_loss: 14.9468 - val_RANKING_loss: 49.7412 - val_CLASSIFIER_loss: 0.0384 - val_RANKING_accuracy: 0.0900 - val_CLASSIFIER_accuracy: 0.9878\n","Epoch 20/1000\n","388863/388863 [==============================] - 65s 167us/step - loss: 13.3048 - RANKING_loss: 44.2589 - CLASSIFIER_loss: 0.0274 - RANKING_accuracy: 0.0914 - CLASSIFIER_accuracy: 0.9904 - val_loss: 14.8742 - val_RANKING_loss: 49.5065 - val_CLASSIFIER_loss: 0.0380 - val_RANKING_accuracy: 0.0816 - val_CLASSIFIER_accuracy: 0.9879\n","Epoch 21/1000\n","388863/388863 [==============================] - 65s 166us/step - loss: 13.2655 - RANKING_loss: 44.1267 - CLASSIFIER_loss: 0.0272 - RANKING_accuracy: 0.0923 - CLASSIFIER_accuracy: 0.9904 - val_loss: 14.8134 - val_RANKING_loss: 49.3082 - val_CLASSIFIER_loss: 0.0376 - val_RANKING_accuracy: 0.0692 - val_CLASSIFIER_accuracy: 0.9881\n","Epoch 22/1000\n","388863/388863 [==============================] - 65s 166us/step - loss: 13.2211 - RANKING_loss: 43.9799 - CLASSIFIER_loss: 0.0268 - RANKING_accuracy: 0.0932 - CLASSIFIER_accuracy: 0.9905 - val_loss: 14.7795 - val_RANKING_loss: 49.1944 - val_CLASSIFIER_loss: 0.0374 - val_RANKING_accuracy: 0.0866 - val_CLASSIFIER_accuracy: 0.9880\n","Epoch 23/1000\n","388863/388863 [==============================] - 65s 166us/step - loss: 13.1924 - RANKING_loss: 43.8865 - CLASSIFIER_loss: 0.0266 - RANKING_accuracy: 0.0929 - CLASSIFIER_accuracy: 0.9906 - val_loss: 14.7549 - val_RANKING_loss: 49.1076 - val_CLASSIFIER_loss: 0.0374 - val_RANKING_accuracy: 0.0747 - val_CLASSIFIER_accuracy: 0.9879\n","Epoch 24/1000\n","388863/388863 [==============================] - 65s 166us/step - loss: 13.1595 - RANKING_loss: 43.7763 - CLASSIFIER_loss: 0.0264 - RANKING_accuracy: 0.0929 - CLASSIFIER_accuracy: 0.9907 - val_loss: 14.7319 - val_RANKING_loss: 49.0242 - val_CLASSIFIER_loss: 0.0371 - val_RANKING_accuracy: 0.0937 - val_CLASSIFIER_accuracy: 0.9879\n","Epoch 25/1000\n","388863/388863 [==============================] - 65s 167us/step - loss: 13.1287 - RANKING_loss: 43.6747 - CLASSIFIER_loss: 0.0261 - RANKING_accuracy: 0.0946 - CLASSIFIER_accuracy: 0.9907 - val_loss: 14.7678 - val_RANKING_loss: 49.1466 - val_CLASSIFIER_loss: 0.0372 - val_RANKING_accuracy: 0.0838 - val_CLASSIFIER_accuracy: 0.9882\n","Epoch 26/1000\n","388863/388863 [==============================] - 65s 167us/step - loss: 13.0988 - RANKING_loss: 43.5761 - CLASSIFIER_loss: 0.0259 - RANKING_accuracy: 0.0945 - CLASSIFIER_accuracy: 0.9908 - val_loss: 14.7201 - val_RANKING_loss: 48.9753 - val_CLASSIFIER_loss: 0.0373 - val_RANKING_accuracy: 0.0945 - val_CLASSIFIER_accuracy: 0.9879\n","Epoch 27/1000\n","388863/388863 [==============================] - 65s 167us/step - loss: 13.0777 - RANKING_loss: 43.5081 - CLASSIFIER_loss: 0.0258 - RANKING_accuracy: 0.0947 - CLASSIFIER_accuracy: 0.9908 - val_loss: 14.7312 - val_RANKING_loss: 49.0146 - val_CLASSIFIER_loss: 0.0372 - val_RANKING_accuracy: 0.0914 - val_CLASSIFIER_accuracy: 0.9880\n","Epoch 28/1000\n","388863/388863 [==============================] - 65s 166us/step - loss: 13.0475 - RANKING_loss: 43.4062 - CLASSIFIER_loss: 0.0255 - RANKING_accuracy: 0.0948 - CLASSIFIER_accuracy: 0.9909 - val_loss: 14.6748 - val_RANKING_loss: 48.8333 - val_CLASSIFIER_loss: 0.0370 - val_RANKING_accuracy: 0.0954 - val_CLASSIFIER_accuracy: 0.9879\n","Epoch 29/1000\n","388863/388863 [==============================] - 65s 166us/step - loss: 13.0251 - RANKING_loss: 43.3343 - CLASSIFIER_loss: 0.0254 - RANKING_accuracy: 0.0956 - CLASSIFIER_accuracy: 0.9909 - val_loss: 14.6928 - val_RANKING_loss: 48.8916 - val_CLASSIFIER_loss: 0.0370 - val_RANKING_accuracy: 0.0932 - val_CLASSIFIER_accuracy: 0.9881\n","Epoch 30/1000\n","388863/388863 [==============================] - 65s 166us/step - loss: 13.0010 - RANKING_loss: 43.2506 - CLASSIFIER_loss: 0.0252 - RANKING_accuracy: 0.0954 - CLASSIFIER_accuracy: 0.9910 - val_loss: 14.6210 - val_RANKING_loss: 48.6579 - val_CLASSIFIER_loss: 0.0366 - val_RANKING_accuracy: 0.0777 - val_CLASSIFIER_accuracy: 0.9880\n","Epoch 31/1000\n","388863/388863 [==============================] - 65s 166us/step - loss: 12.9858 - RANKING_loss: 43.2022 - CLASSIFIER_loss: 0.0251 - RANKING_accuracy: 0.0957 - CLASSIFIER_accuracy: 0.9910 - val_loss: 14.6046 - val_RANKING_loss: 48.5991 - val_CLASSIFIER_loss: 0.0367 - val_RANKING_accuracy: 0.0880 - val_CLASSIFIER_accuracy: 0.9879\n","Epoch 32/1000\n","388863/388863 [==============================] - 65s 166us/step - loss: 12.9591 - RANKING_loss: 43.1120 - CLASSIFIER_loss: 0.0249 - RANKING_accuracy: 0.0959 - CLASSIFIER_accuracy: 0.9911 - val_loss: 14.6150 - val_RANKING_loss: 48.6342 - val_CLASSIFIER_loss: 0.0365 - val_RANKING_accuracy: 0.1008 - val_CLASSIFIER_accuracy: 0.9881\n","Epoch 33/1000\n","388863/388863 [==============================] - 65s 166us/step - loss: 12.9381 - RANKING_loss: 43.0463 - CLASSIFIER_loss: 0.0247 - RANKING_accuracy: 0.0962 - CLASSIFIER_accuracy: 0.9911 - val_loss: 14.5568 - val_RANKING_loss: 48.4383 - val_CLASSIFIER_loss: 0.0362 - val_RANKING_accuracy: 0.0823 - val_CLASSIFIER_accuracy: 0.9881\n","Epoch 34/1000\n","388863/388863 [==============================] - 65s 167us/step - loss: 12.9239 - RANKING_loss: 42.9983 - CLASSIFIER_loss: 0.0246 - RANKING_accuracy: 0.0954 - CLASSIFIER_accuracy: 0.9911 - val_loss: 14.5876 - val_RANKING_loss: 48.5393 - val_CLASSIFIER_loss: 0.0364 - val_RANKING_accuracy: 0.0903 - val_CLASSIFIER_accuracy: 0.9881\n","Epoch 35/1000\n","388863/388863 [==============================] - 65s 167us/step - loss: 12.9056 - RANKING_loss: 42.9404 - CLASSIFIER_loss: 0.0245 - RANKING_accuracy: 0.0964 - CLASSIFIER_accuracy: 0.9912 - val_loss: 14.5920 - val_RANKING_loss: 48.5577 - val_CLASSIFIER_loss: 0.0364 - val_RANKING_accuracy: 0.0903 - val_CLASSIFIER_accuracy: 0.9882\n","Epoch 36/1000\n","388863/388863 [==============================] - 65s 166us/step - loss: 12.8881 - RANKING_loss: 42.8779 - CLASSIFIER_loss: 0.0243 - RANKING_accuracy: 0.0956 - CLASSIFIER_accuracy: 0.9912 - val_loss: 14.5440 - val_RANKING_loss: 48.4096 - val_CLASSIFIER_loss: 0.0362 - val_RANKING_accuracy: 0.0928 - val_CLASSIFIER_accuracy: 0.9881\n","Epoch 37/1000\n","388863/388863 [==============================] - 65s 166us/step - loss: 12.8742 - RANKING_loss: 42.8336 - CLASSIFIER_loss: 0.0243 - RANKING_accuracy: 0.0961 - CLASSIFIER_accuracy: 0.9912 - val_loss: 14.5512 - val_RANKING_loss: 48.4250 - val_CLASSIFIER_loss: 0.0362 - val_RANKING_accuracy: 0.1025 - val_CLASSIFIER_accuracy: 0.9882\n","Epoch 38/1000\n","388863/388863 [==============================] - 65s 166us/step - loss: 12.8566 - RANKING_loss: 42.7766 - CLASSIFIER_loss: 0.0241 - RANKING_accuracy: 0.0966 - CLASSIFIER_accuracy: 0.9913 - val_loss: 14.5095 - val_RANKING_loss: 48.2864 - val_CLASSIFIER_loss: 0.0360 - val_RANKING_accuracy: 0.1023 - val_CLASSIFIER_accuracy: 0.9882\n","Epoch 39/1000\n","388863/388863 [==============================] - 65s 167us/step - loss: 12.8408 - RANKING_loss: 42.7221 - CLASSIFIER_loss: 0.0240 - RANKING_accuracy: 0.0959 - CLASSIFIER_accuracy: 0.9913 - val_loss: 14.4899 - val_RANKING_loss: 48.2250 - val_CLASSIFIER_loss: 0.0357 - val_RANKING_accuracy: 0.0836 - val_CLASSIFIER_accuracy: 0.9883\n","Epoch 40/1000\n","388863/388863 [==============================] - 65s 167us/step - loss: 12.8294 - RANKING_loss: 42.6846 - CLASSIFIER_loss: 0.0239 - RANKING_accuracy: 0.0968 - CLASSIFIER_accuracy: 0.9914 - val_loss: 14.5163 - val_RANKING_loss: 48.3120 - val_CLASSIFIER_loss: 0.0361 - val_RANKING_accuracy: 0.0764 - val_CLASSIFIER_accuracy: 0.9881\n","Epoch 41/1000\n","388863/388863 [==============================] - 65s 167us/step - loss: 12.8155 - RANKING_loss: 42.6382 - CLASSIFIER_loss: 0.0238 - RANKING_accuracy: 0.0963 - CLASSIFIER_accuracy: 0.9914 - val_loss: 14.5428 - val_RANKING_loss: 48.4003 - val_CLASSIFIER_loss: 0.0365 - val_RANKING_accuracy: 0.0752 - val_CLASSIFIER_accuracy: 0.9878\n","Epoch 42/1000\n","388863/388863 [==============================] - 65s 167us/step - loss: 12.7981 - RANKING_loss: 42.5801 - CLASSIFIER_loss: 0.0237 - RANKING_accuracy: 0.0960 - CLASSIFIER_accuracy: 0.9914 - val_loss: 14.4907 - val_RANKING_loss: 48.2208 - val_CLASSIFIER_loss: 0.0360 - val_RANKING_accuracy: 0.0873 - val_CLASSIFIER_accuracy: 0.9881\n","Epoch 43/1000\n","388863/388863 [==============================] - 65s 167us/step - loss: 12.7898 - RANKING_loss: 42.5556 - CLASSIFIER_loss: 0.0236 - RANKING_accuracy: 0.0975 - CLASSIFIER_accuracy: 0.9914 - val_loss: 14.4789 - val_RANKING_loss: 48.1838 - val_CLASSIFIER_loss: 0.0357 - val_RANKING_accuracy: 0.0897 - val_CLASSIFIER_accuracy: 0.9882\n","Epoch 44/1000\n","388863/388863 [==============================] - 65s 167us/step - loss: 12.7730 - RANKING_loss: 42.4983 - CLASSIFIER_loss: 0.0235 - RANKING_accuracy: 0.0964 - CLASSIFIER_accuracy: 0.9915 - val_loss: 14.4918 - val_RANKING_loss: 48.2345 - val_CLASSIFIER_loss: 0.0358 - val_RANKING_accuracy: 0.0726 - val_CLASSIFIER_accuracy: 0.9883\n","Epoch 45/1000\n","388863/388863 [==============================] - 65s 167us/step - loss: 12.7608 - RANKING_loss: 42.4592 - CLASSIFIER_loss: 0.0234 - RANKING_accuracy: 0.0969 - CLASSIFIER_accuracy: 0.9915 - val_loss: 14.4887 - val_RANKING_loss: 48.2165 - val_CLASSIFIER_loss: 0.0360 - val_RANKING_accuracy: 0.1000 - val_CLASSIFIER_accuracy: 0.9881\n","Epoch 46/1000\n","388863/388863 [==============================] - 65s 167us/step - loss: 12.7538 - RANKING_loss: 42.4327 - CLASSIFIER_loss: 0.0233 - RANKING_accuracy: 0.0971 - CLASSIFIER_accuracy: 0.9915 - val_loss: 14.6194 - val_RANKING_loss: 48.6502 - val_CLASSIFIER_loss: 0.0367 - val_RANKING_accuracy: 0.0892 - val_CLASSIFIER_accuracy: 0.9883\n","Epoch 47/1000\n","388863/388863 [==============================] - 65s 167us/step - loss: 12.7401 - RANKING_loss: 42.3896 - CLASSIFIER_loss: 0.0233 - RANKING_accuracy: 0.0969 - CLASSIFIER_accuracy: 0.9915 - val_loss: 14.4226 - val_RANKING_loss: 47.9943 - val_CLASSIFIER_loss: 0.0356 - val_RANKING_accuracy: 0.0865 - val_CLASSIFIER_accuracy: 0.9881\n","Epoch 48/1000\n","388863/388863 [==============================] - 65s 167us/step - loss: 12.7264 - RANKING_loss: 42.3436 - CLASSIFIER_loss: 0.0232 - RANKING_accuracy: 0.0971 - CLASSIFIER_accuracy: 0.9916 - val_loss: 14.4629 - val_RANKING_loss: 48.1293 - val_CLASSIFIER_loss: 0.0360 - val_RANKING_accuracy: 0.0792 - val_CLASSIFIER_accuracy: 0.9881\n","Epoch 49/1000\n","388863/388863 [==============================] - 65s 167us/step - loss: 12.7156 - RANKING_loss: 42.3086 - CLASSIFIER_loss: 0.0231 - RANKING_accuracy: 0.0974 - CLASSIFIER_accuracy: 0.9916 - val_loss: 14.4346 - val_RANKING_loss: 48.0289 - val_CLASSIFIER_loss: 0.0359 - val_RANKING_accuracy: 0.0851 - val_CLASSIFIER_accuracy: 0.9880\n","Epoch 50/1000\n","388863/388863 [==============================] - 65s 167us/step - loss: 12.7086 - RANKING_loss: 42.2841 - CLASSIFIER_loss: 0.0230 - RANKING_accuracy: 0.0973 - CLASSIFIER_accuracy: 0.9916 - val_loss: 14.3889 - val_RANKING_loss: 47.8846 - val_CLASSIFIER_loss: 0.0352 - val_RANKING_accuracy: 0.0991 - val_CLASSIFIER_accuracy: 0.9882\n","Epoch 51/1000\n","388863/388863 [==============================] - 65s 168us/step - loss: 12.6930 - RANKING_loss: 42.2337 - CLASSIFIER_loss: 0.0229 - RANKING_accuracy: 0.0977 - CLASSIFIER_accuracy: 0.9916 - val_loss: 14.3896 - val_RANKING_loss: 47.8899 - val_CLASSIFIER_loss: 0.0354 - val_RANKING_accuracy: 0.1009 - val_CLASSIFIER_accuracy: 0.9882\n","Epoch 52/1000\n","388863/388863 [==============================] - 65s 167us/step - loss: 12.6855 - RANKING_loss: 42.2099 - CLASSIFIER_loss: 0.0229 - RANKING_accuracy: 0.0974 - CLASSIFIER_accuracy: 0.9916 - val_loss: 14.3341 - val_RANKING_loss: 47.7044 - val_CLASSIFIER_loss: 0.0349 - val_RANKING_accuracy: 0.0748 - val_CLASSIFIER_accuracy: 0.9882\n","Epoch 53/1000\n","388863/388863 [==============================] - 65s 168us/step - loss: 12.6775 - RANKING_loss: 42.1860 - CLASSIFIER_loss: 0.0228 - RANKING_accuracy: 0.0973 - CLASSIFIER_accuracy: 0.9917 - val_loss: 14.3811 - val_RANKING_loss: 47.8612 - val_CLASSIFIER_loss: 0.0353 - val_RANKING_accuracy: 0.0879 - val_CLASSIFIER_accuracy: 0.9882\n","Epoch 54/1000\n","388863/388863 [==============================] - 65s 167us/step - loss: 12.6724 - RANKING_loss: 42.1671 - CLASSIFIER_loss: 0.0227 - RANKING_accuracy: 0.0976 - CLASSIFIER_accuracy: 0.9917 - val_loss: 14.4226 - val_RANKING_loss: 47.9939 - val_CLASSIFIER_loss: 0.0359 - val_RANKING_accuracy: 0.0778 - val_CLASSIFIER_accuracy: 0.9879\n","Epoch 55/1000\n","388863/388863 [==============================] - 65s 168us/step - loss: 12.6593 - RANKING_loss: 42.1210 - CLASSIFIER_loss: 0.0226 - RANKING_accuracy: 0.0976 - CLASSIFIER_accuracy: 0.9917 - val_loss: 14.3656 - val_RANKING_loss: 47.8102 - val_CLASSIFIER_loss: 0.0352 - val_RANKING_accuracy: 0.0879 - val_CLASSIFIER_accuracy: 0.9882\n","Epoch 56/1000\n","388863/388863 [==============================] - 65s 168us/step - loss: 12.6506 - RANKING_loss: 42.0931 - CLASSIFIER_loss: 0.0226 - RANKING_accuracy: 0.0983 - CLASSIFIER_accuracy: 0.9917 - val_loss: 14.3835 - val_RANKING_loss: 47.8683 - val_CLASSIFIER_loss: 0.0356 - val_RANKING_accuracy: 0.0772 - val_CLASSIFIER_accuracy: 0.9879\n","Epoch 57/1000\n","388863/388863 [==============================] - 65s 168us/step - loss: 12.6361 - RANKING_loss: 42.0456 - CLASSIFIER_loss: 0.0225 - RANKING_accuracy: 0.0975 - CLASSIFIER_accuracy: 0.9918 - val_loss: 14.3823 - val_RANKING_loss: 47.8591 - val_CLASSIFIER_loss: 0.0359 - val_RANKING_accuracy: 0.0881 - val_CLASSIFIER_accuracy: 0.9878\n","Epoch 00057: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X5GOjLGM8Do0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622261240888,"user_tz":-330,"elapsed":278891,"user":{"displayName":"Bikku Kumar","photoUrl":"","userId":"05745485641699477877"}},"outputId":"252fc374-eed5-435f-9979-837c97b08c7a"},"source":["def final_model(filename):\n","    print('Extracting features based on LSTM model...... ')\n","    dataframe2 = pd.read_csv(filename, header=None)\n","    dataset2 = dataframe2.values\n","    overlap = 30\n","    X_test = dataset2[:,0]\n","    Y_test = dataset2[:,1:len(dataset2[0])]\n","    c_p = []\n","    for tag, row in enumerate(X_test):\n","        pos = math.ceil(len(row) / overlap)\n","        if(pos < math.ceil(segmentSize/ overlap)):\n","            pos = math.ceil(segmentSize/ overlap)\n","        segment = [ ]\n","        for itr in range(pos - math.ceil(segmentSize/overlap) + 1):\n","            init = itr * overlap\n","            segment.append(row[init : init + segmentSize])\n","        seg_nGram = nGram(segment, chunkSize, dict_Prop)\n","        test_seg = sequence.pad_sequences(seg_nGram, maxlen=max_seq_len)\n","        preds = model.predict(test_seg)\n","        c_p.append(cls_predict(preds))\n","    c_p = np.array(c_p)\n","    return c_p, Y_test\n","\n","def create_nn_model(dim):\n","    n_model = Sequential()\n","    n_model.add(Dense(dim, input_dim = dim, kernel_initializer='normal', activation='relu'))\n","    n_model.add(Dense(dim, kernel_initializer='normal', activation='sigmoid'))\n","    n_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    return n_model\n","\n","# Creates a HDF5 file 'my_model.h5'\n","model_path = '/content/gdrive/My Drive/Multi-Attn/CAFA3/mf/simple+rank/0.3(4L)/32.model_'+str(nonOL)+'_'+ SEG +'.h5'\n","model.save(model_path)\n","#del model  \n","#model = load_model(model_path, custom_objects={'categorical_crossentropy': categorical_crossentropy})\n","\n","# Training\n","X_train_new, Y_train_new = final_model(\"/content/gdrive/My Drive/Multi-Attn/CAFA3/mf/train_data_mf1.csv\")\n","\n","# Training model 2\n","model1 = create_nn_model(Y_train_new[0].shape[0])\n","print(model1.summary())\n","early_stopping_monitor = EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 1)\n","model1.fit(X_train_new, Y_train_new.astype(None),\n","           callbacks = [early_stopping_monitor],\n","           validation_split = 0.1,\n","           epochs = 1000,\n","           batch_size = 150,\n","           verbose = True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Extracting features based on LSTM model...... \n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_5 (Dense)              (None, 677)               459006    \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 677)               459006    \n","=================================================================\n","Total params: 918,012\n","Trainable params: 918,012\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Train on 32499 samples, validate on 3611 samples\n","Epoch 1/1000\n","32499/32499 [==============================] - 2s 49us/step - loss: 0.0858 - accuracy: 0.9822 - val_loss: 0.0255 - val_accuracy: 0.9933\n","Epoch 2/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0224 - accuracy: 0.9935 - val_loss: 0.0182 - val_accuracy: 0.9946\n","Epoch 3/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 0.0158 - val_accuracy: 0.9951\n","Epoch 4/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.0147 - val_accuracy: 0.9954\n","Epoch 5/1000\n","32499/32499 [==============================] - 1s 43us/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0139 - val_accuracy: 0.9956\n","Epoch 6/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0145 - accuracy: 0.9953 - val_loss: 0.0134 - val_accuracy: 0.9957\n","Epoch 7/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 0.0129 - val_accuracy: 0.9958\n","Epoch 8/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.0126 - val_accuracy: 0.9959\n","Epoch 9/1000\n","32499/32499 [==============================] - 1s 43us/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.0124 - val_accuracy: 0.9959\n","Epoch 10/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.0121 - val_accuracy: 0.9960\n","Epoch 11/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0119 - val_accuracy: 0.9961\n","Epoch 12/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.0118 - val_accuracy: 0.9961\n","Epoch 13/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.0116 - val_accuracy: 0.9961\n","Epoch 14/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.0114 - val_accuracy: 0.9962\n","Epoch 15/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.0114 - val_accuracy: 0.9962\n","Epoch 16/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.0113 - val_accuracy: 0.9962\n","Epoch 17/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0111 - val_accuracy: 0.9962\n","Epoch 18/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.0111 - val_accuracy: 0.9963\n","Epoch 19/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 0.0109 - val_accuracy: 0.9963\n","Epoch 20/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0110 - val_accuracy: 0.9963\n","Epoch 21/1000\n","32499/32499 [==============================] - 1s 45us/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0109 - val_accuracy: 0.9963\n","Epoch 22/1000\n","32499/32499 [==============================] - 1s 45us/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.0107 - val_accuracy: 0.9964\n","Epoch 23/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0108 - val_accuracy: 0.9963\n","Epoch 24/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 0.0107 - val_accuracy: 0.9964\n","Epoch 25/1000\n","32499/32499 [==============================] - 1s 46us/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 0.0107 - val_accuracy: 0.9964\n","Epoch 26/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.0107 - val_accuracy: 0.9964\n","Epoch 27/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.0107 - val_accuracy: 0.9964\n","Epoch 28/1000\n","32499/32499 [==============================] - 1s 43us/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.0107 - val_accuracy: 0.9964\n","Epoch 29/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0099 - accuracy: 0.9965 - val_loss: 0.0108 - val_accuracy: 0.9963\n","Epoch 30/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 0.0106 - val_accuracy: 0.9964\n","Epoch 31/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0097 - accuracy: 0.9965 - val_loss: 0.0107 - val_accuracy: 0.9964\n","Epoch 32/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.0106 - val_accuracy: 0.9964\n","Epoch 33/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.0105 - val_accuracy: 0.9964\n","Epoch 34/1000\n","32499/32499 [==============================] - 1s 45us/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.0106 - val_accuracy: 0.9964\n","Epoch 35/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 0.0106 - val_accuracy: 0.9964\n","Epoch 36/1000\n","32499/32499 [==============================] - 1s 43us/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 0.0105 - val_accuracy: 0.9964\n","Epoch 37/1000\n","32499/32499 [==============================] - 1s 44us/step - loss: 0.0092 - accuracy: 0.9967 - val_loss: 0.0105 - val_accuracy: 0.9964\n","Epoch 38/1000\n","32499/32499 [==============================] - 1s 43us/step - loss: 0.0092 - accuracy: 0.9967 - val_loss: 0.0106 - val_accuracy: 0.9964\n","Epoch 00038: early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7fb607a37050>"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"n0ZS26Si7lpt","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1622261257429,"user_tz":-330,"elapsed":16555,"user":{"displayName":"Bikku Kumar","photoUrl":"","userId":"05745485641699477877"}},"outputId":"3fcc1af7-96d1-401e-b35f-3980612a1568"},"source":["from matplotlib import pyplot as plt\n","\n","# Testing\n","def test_fun(file):\n","    X_test_new, Y_test_new = final_model(file)\n","    print(X_test_new.shape, Y_test_new.shape)\n","    Y_test_new = np.array(Y_test_new).astype(None)\n","\n","    fmax, tmax = 0.0, 0.0\n","    precisions, recalls = [], []\n","    for t in range(1, 101, 1):\n","        test_preds = model1.predict(X_test_new)\n","\n","        threshold = t / 100.0\n","        print(\"THRESHOLD IS =====> \", threshold)\n","        test_preds[test_preds>=threshold] = int(1)\n","        test_preds[test_preds<threshold] = int(0)\n","\n","        rec = recall(Y_test_new, test_preds)\n","        pre = precision(Y_test_new, test_preds)\n","        recalls.append(rec)\n","        precisions.append(pre)\n","\n","        f1 = f_score(Y_test_new, test_preds)*100\n","        f = 2 * pre * rec / (pre + rec)\n","        print('Recall: {0}'.format(rec*100), '     Precision: {0}'.format(pre*100),\n","              '     F1-score1: {0}'.format(f*100), '      F1-score2: {0}'.format(f1))\n","\n","        if fmax < f:\n","            fmax = f\n","            tmax = threshold\n","    \n","    precisions = np.array(precisions)\n","    recalls = np.array(recalls)\n","    sorted_index = np.argsort(recalls)\n","    recalls = recalls[sorted_index]\n","    precisions = precisions[sorted_index]\n","    aupr = np.trapz(precisions, recalls)\n","    print(f'AUPR: {aupr:0.3f}')\n","\n","    plt.figure()\n","    plt.plot(recalls, precisions, color='darkorange', lw=2, label=f'AUPR curve (area = {aupr:0.2f})')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Recall')\n","    plt.ylabel('Precision')\n","    plt.title('Area Under the Precision-Recall curve')\n","    plt.legend(loc=\"upper right\")\n","    plt.savefig(f'aupr.pdf')\n","\n","    return tmax\n","\n","th_set = test_fun(\"/content/gdrive/My Drive/Multi-Attn/CAFA3/mf/test_data_mf1.csv\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Extracting features based on LSTM model...... \n","(1137, 677) (1137, 677)\n","THRESHOLD IS =====>  0.01\n","Recall: 75.76868235218484      Precision: 14.780508699476078      F1-score1: 24.735718909192077       F1-score2: 21.928474302415896\n","THRESHOLD IS =====>  0.02\n","Recall: 70.48326997174321      Precision: 19.878176335497074      F1-score1: 31.010545458445034       F1-score2: 27.498108906978935\n","THRESHOLD IS =====>  0.03\n","Recall: 67.26274387486272      Precision: 23.62969052369436      F1-score1: 34.9731599126969       F1-score2: 31.098515399209887\n","THRESHOLD IS =====>  0.04\n","Recall: 65.05477692637655      Precision: 26.425231397267712      F1-score1: 37.58389543855804       F1-score2: 33.600352314865916\n","THRESHOLD IS =====>  0.05\n","Recall: 63.27316685281291      Precision: 28.710831290552974      F1-score1: 39.49872272128758       F1-score2: 35.36629031146292\n","THRESHOLD IS =====>  0.06\n","Recall: 61.805891520146915      Precision: 30.74883830724684      F1-score1: 41.06671519289013       F1-score2: 36.83135169125955\n","THRESHOLD IS =====>  0.07\n","Recall: 60.757886687232045      Precision: 32.745165056433315      F1-score1: 42.555338910385295       F1-score2: 38.22563082248573\n","THRESHOLD IS =====>  0.08\n","Recall: 59.81313590948463      Precision: 34.39400653198296      F1-score1: 43.674255132988       F1-score2: 39.29811688506696\n","THRESHOLD IS =====>  0.09\n","Recall: 58.946658518850334      Precision: 35.743703038263405      F1-score1: 44.502351085117745       F1-score2: 40.12744994942729\n","THRESHOLD IS =====>  0.1\n","Recall: 57.9844235579183      Precision: 37.077429085855826      F1-score1: 45.231884141987585       F1-score2: 40.87232812050631\n","THRESHOLD IS =====>  0.11\n","Recall: 57.20224946545671      Precision: 38.32131173449716      F1-score1: 45.8958021695133       F1-score2: 41.50051417480543\n","THRESHOLD IS =====>  0.12\n","Recall: 56.49880821063371      Precision: 39.469915773979075      F1-score1: 46.47354072898707       F1-score2: 42.06977494176883\n","THRESHOLD IS =====>  0.13\n","Recall: 55.94462077917841      Precision: 40.516503107450916      F1-score1: 46.99676533540648       F1-score2: 42.57913606019587\n","THRESHOLD IS =====>  0.14\n","Recall: 55.210984482131806      Precision: 41.37360788001669      F1-score1: 47.30107705105595       F1-score2: 42.89193764541043\n","THRESHOLD IS =====>  0.15\n","Recall: 54.72630566319038      Precision: 42.4570722003567      F1-score1: 47.81720417380969       F1-score2: 43.364378009270624\n","THRESHOLD IS =====>  0.16\n","Recall: 54.100265495401935      Precision: 43.41924651147045      F1-score1: 48.174826053586436       F1-score2: 43.68090122999749\n","THRESHOLD IS =====>  0.17\n","Recall: 53.58479431044816      Precision: 44.31829388489259      F1-score1: 48.513008236750984       F1-score2: 43.93939950192903\n","THRESHOLD IS =====>  0.18\n","Recall: 53.05619966996545      Precision: 45.00585665222933      F1-score1: 48.70058423031607       F1-score2: 44.16381686884946\n","THRESHOLD IS =====>  0.19\n","Recall: 52.68088966081535      Precision: 45.66745252012196      F1-score1: 48.92409925684302       F1-score2: 44.36628143574356\n","THRESHOLD IS =====>  0.2\n","Recall: 52.20054171459463      Precision: 46.29573884464395      F1-score1: 49.07114528683879       F1-score2: 44.482430812942376\n","THRESHOLD IS =====>  0.21\n","Recall: 51.93844115903521      Precision: 47.10428207374582      F1-score1: 49.40338680057814       F1-score2: 44.77604506109337\n","THRESHOLD IS =====>  0.22\n","Recall: 51.70033633269671      Precision: 47.84802144351134      F1-score1: 49.69964059165717       F1-score2: 45.04833659550827\n","THRESHOLD IS =====>  0.23\n","Recall: 51.223766151397996      Precision: 48.541963097134946      F1-score1: 49.84681984377908       F1-score2: 45.180509562557084\n","THRESHOLD IS =====>  0.24\n","Recall: 50.75020243254228      Precision: 49.33422126072691      F1-score1: 50.032195289587314       F1-score2: 45.358691455262644\n","THRESHOLD IS =====>  0.25\n","Recall: 50.408862684041644      Precision: 49.9542929821914      F1-score1: 50.18054840347938       F1-score2: 45.537965686057326\n","THRESHOLD IS =====>  0.26\n","Recall: 50.15441061734129      Precision: 50.60952159815135      F1-score1: 50.38093832925307       F1-score2: 45.74082747593663\n","THRESHOLD IS =====>  0.27\n","Recall: 49.80433667979788      Precision: 51.05449451034671      F1-score1: 50.42166766371695       F1-score2: 45.75768109904282\n","THRESHOLD IS =====>  0.28\n","Recall: 49.424216355356805      Precision: 51.520309930618424      F1-score1: 50.45050065403499       F1-score2: 45.793007153255076\n","THRESHOLD IS =====>  0.29\n","Recall: 49.067898280290514      Precision: 52.019107050906754      F1-score1: 50.500422780210656       F1-score2: 45.83411459037105\n","THRESHOLD IS =====>  0.3\n","Recall: 48.814842214192446      Precision: 52.49355556254236      F1-score1: 50.58740811782757       F1-score2: 45.92704692430633\n","THRESHOLD IS =====>  0.31\n","Recall: 48.49697460707172      Precision: 53.01901806296059      F1-score1: 50.657278820075355       F1-score2: 45.981871395417606\n","THRESHOLD IS =====>  0.32\n","Recall: 48.18260869421866      Precision: 53.555962453951466      F1-score1: 50.7273879127488       F1-score2: 46.06660750147901\n","THRESHOLD IS =====>  0.33\n","Recall: 47.94590322103052      Precision: 54.130173032976195      F1-score1: 50.85070141447253       F1-score2: 46.158456213087916\n","THRESHOLD IS =====>  0.34\n","Recall: 47.6481239675915      Precision: 54.84098187840595      F1-score1: 50.99214948705253       F1-score2: 46.2456462877697\n","THRESHOLD IS =====>  0.35\n","Recall: 47.39126652249631      Precision: 55.336269114047155      F1-score1: 51.05653244175553       F1-score2: 46.283956540141766\n","THRESHOLD IS =====>  0.36\n","Recall: 47.1634150467725      Precision: 55.9806153454806      F1-score1: 51.19514888204184       F1-score2: 46.38065415023689\n","THRESHOLD IS =====>  0.37\n","Recall: 46.98987814222601      Precision: 56.47863104362716      F1-score1: 51.29916360566725       F1-score2: 46.49481620432411\n","THRESHOLD IS =====>  0.38\n","Recall: 46.8183652600653      Precision: 57.12898828877272      F1-score1: 51.46231720820281       F1-score2: 46.61107065672915\n","THRESHOLD IS =====>  0.39\n","Recall: 46.54685581273787      Precision: 57.514368790510716      F1-score1: 51.452652829322155       F1-score2: 46.60499878847698\n","THRESHOLD IS =====>  0.4\n","Recall: 46.26102485524732      Precision: 57.8899127337971      F1-score1: 51.42626180502074       F1-score2: 46.57130637948681\n","THRESHOLD IS =====>  0.41\n","Recall: 46.02008639307284      Precision: 58.33899560514782      F1-score1: 51.45245754231098       F1-score2: 46.58980411101983\n","THRESHOLD IS =====>  0.42\n","Recall: 45.68434484083357      Precision: 58.65550539610512      F1-score1: 51.3636607536626       F1-score2: 46.50224421058098\n","THRESHOLD IS =====>  0.43\n","Recall: 45.25994308616897      Precision: 59.10573802784236      F1-score1: 51.26440628090755       F1-score2: 46.374784999768906\n","THRESHOLD IS =====>  0.44\n","Recall: 45.07280076807261      Precision: 59.75122351175215      F1-score1: 51.38430834909523       F1-score2: 46.42444189073954\n","THRESHOLD IS =====>  0.45\n","Recall: 44.77089884028538      Precision: 60.1908112867504      F1-score1: 51.348186304744495       F1-score2: 46.42184121697832\n","THRESHOLD IS =====>  0.46\n","Recall: 44.55228799676133      Precision: 60.65274507207688      F1-score1: 51.37051883206364       F1-score2: 46.38815189857112\n","THRESHOLD IS =====>  0.47\n","Recall: 44.218250452729805      Precision: 60.96664458012795      F1-score1: 51.259039778754       F1-score2: 46.249204941181645\n","THRESHOLD IS =====>  0.48\n","Recall: 43.84986042700053      Precision: 61.45980831540408      F1-score1: 51.18246118678539       F1-score2: 46.115479976852455\n","THRESHOLD IS =====>  0.49\n","Recall: 43.58796197228044      Precision: 61.89723513855348      F1-score1: 51.153610275265294       F1-score2: 46.101545877405506\n","THRESHOLD IS =====>  0.5\n","Recall: 43.3044889039511      Precision: 62.303815893114546      F1-score1: 51.09512758871889       F1-score2: 46.017811718470945\n","THRESHOLD IS =====>  0.51\n","Recall: 43.033341796003185      Precision: 62.648378748009584      F1-score1: 51.02053754898475       F1-score2: 45.901343090085284\n","THRESHOLD IS =====>  0.52\n","Recall: 42.72617461373577      Precision: 62.96047097290938      F1-score1: 50.906338480506975       F1-score2: 45.792949322166095\n","THRESHOLD IS =====>  0.53\n","Recall: 42.43736936954238      Precision: 63.213282291315146      F1-score1: 50.78256248279386       F1-score2: 45.653419095697195\n","THRESHOLD IS =====>  0.54\n","Recall: 42.12545732740568      Precision: 63.568832293583164      F1-score1: 50.671916935890415       F1-score2: 45.56703479651574\n","THRESHOLD IS =====>  0.55\n","Recall: 41.896030725988254      Precision: 63.998110993970045      F1-score1: 50.640512894458375       F1-score2: 45.45778846725938\n","THRESHOLD IS =====>  0.56\n","Recall: 41.62060256103086      Precision: 64.68054371435366      F1-score1: 50.64937298780333       F1-score2: 45.44321719780283\n","THRESHOLD IS =====>  0.57\n","Recall: 41.274935880041056      Precision: 65.20604945281755      F1-score1: 50.55128860317388       F1-score2: 45.331087348563855\n","THRESHOLD IS =====>  0.58\n","Recall: 41.026155063630746      Precision: 65.72855544419785      F1-score1: 50.51936153326676       F1-score2: 45.32163104621352\n","THRESHOLD IS =====>  0.59\n","Recall: 40.77184532717188      Precision: 66.15986239180155      F1-score1: 50.452007806602815       F1-score2: 45.2142941681538\n","THRESHOLD IS =====>  0.6\n","Recall: 40.570124491858486      Precision: 66.51714360390896      F1-score1: 50.40018005576662       F1-score2: 45.15242706133126\n","THRESHOLD IS =====>  0.61\n","Recall: 40.32989120868591      Precision: 66.99661913220942      F1-score1: 50.35039995933275       F1-score2: 45.10162091387818\n","THRESHOLD IS =====>  0.62\n","Recall: 40.05859345723018      Precision: 67.41125738745313      F1-score1: 50.254096993720395       F1-score2: 44.997235903112816\n","THRESHOLD IS =====>  0.63\n","Recall: 39.67054415223102      Precision: 67.85029817747478      F1-score1: 50.0676555590544       F1-score2: 44.78417574287722\n","THRESHOLD IS =====>  0.64\n","Recall: 39.3663972114228      Precision: 68.36047906309653      F1-score1: 49.96164124360743       F1-score2: 44.6546322962127\n","THRESHOLD IS =====>  0.65\n","Recall: 39.02544059581683      Precision: 68.79531517373067      F1-score1: 49.80056885005064       F1-score2: 44.49419021932496\n","THRESHOLD IS =====>  0.66\n","Recall: 38.72805765370318      Precision: 69.20321479302473      F1-score1: 49.66319828479179       F1-score2: 44.34732596546937\n","THRESHOLD IS =====>  0.67\n","Recall: 38.459107939961825      Precision: 69.67621292287606      F1-score1: 49.56169681223116       F1-score2: 44.232639980820764\n","THRESHOLD IS =====>  0.68\n","Recall: 38.22068518736093      Precision: 70.0349864449199      F1-score1: 49.45302409844698       F1-score2: 44.14566765484856\n","THRESHOLD IS =====>  0.69\n","Recall: 37.988422105146455      Precision: 70.46153322136594      F1-score1: 49.36327466673802       F1-score2: 44.0699635969483\n","THRESHOLD IS =====>  0.7\n","Recall: 37.58346242925219      Precision: 70.88336744846744      F1-score1: 49.12178922093821       F1-score2: 43.788588951480406\n","THRESHOLD IS =====>  0.71\n","Recall: 37.28478214168013      Precision: 71.1865242507065      F1-score1: 48.93780920291954       F1-score2: 43.59628466433663\n","THRESHOLD IS =====>  0.72\n","Recall: 37.073984466381      Precision: 71.7687053427286      F1-score1: 48.89169629517743       F1-score2: 43.51256275944559\n","THRESHOLD IS =====>  0.73\n","Recall: 36.80192999213238      Precision: 72.33176753493498      F1-score1: 48.7832576985244       F1-score2: 43.335282460875646\n","THRESHOLD IS =====>  0.74\n","Recall: 36.47702330552624      Precision: 72.71316162687778      F1-score1: 48.58238298477292       F1-score2: 43.08396340150227\n","THRESHOLD IS =====>  0.75\n","Recall: 36.19175912583022      Precision: 72.97097594134485      F1-score1: 48.38552245545613       F1-score2: 42.87521133772758\n","THRESHOLD IS =====>  0.76\n","Recall: 35.69483642574128      Precision: 73.49463801367467      F1-score1: 48.05186755473894       F1-score2: 42.60980832708748\n","THRESHOLD IS =====>  0.77\n","Recall: 35.36309657188645      Precision: 74.13288230627253      F1-score1: 47.88428402592103       F1-score2: 42.39397452680836\n","THRESHOLD IS =====>  0.78\n","Recall: 34.994641378671105      Precision: 74.84679127839834      F1-score1: 47.69123191080706       F1-score2: 42.1837337772607\n","THRESHOLD IS =====>  0.79\n","Recall: 34.5995477027831      Precision: 75.48500719074724      F1-score1: 47.44983725768194       F1-score2: 41.902539058457094\n","THRESHOLD IS =====>  0.8\n","Recall: 34.23068229229765      Precision: 76.14978081706786      F1-score1: 47.2304406114778       F1-score2: 41.67182019567907\n","THRESHOLD IS =====>  0.81\n","Recall: 33.89956342230142      Precision: 76.77411781495645      F1-score1: 47.0321226684416       F1-score2: 41.46819232827414\n","THRESHOLD IS =====>  0.82\n","Recall: 33.57189689990952      Precision: 77.54951022512998      F1-score1: 46.858372824364416       F1-score2: 41.276327127723015\n","THRESHOLD IS =====>  0.83\n","Recall: 33.16135013613448      Precision: 78.20964204104634      F1-score1: 46.57473679715102       F1-score2: 41.0001856073312\n","THRESHOLD IS =====>  0.84\n","Recall: 32.6930074337679      Precision: 78.7514983353206      F1-score1: 46.2045805260527       F1-score2: 40.658825303612375\n","THRESHOLD IS =====>  0.85\n","Recall: 32.24111114040352      Precision: 79.51693070135754      F1-score1: 45.87972655992331       F1-score2: 40.34040371721526\n","THRESHOLD IS =====>  0.86\n","Recall: 31.820568002455513      Precision: 80.18853119587885      F1-score1: 45.56138078420387       F1-score2: 40.04555438135772\n","THRESHOLD IS =====>  0.87\n","Recall: 31.413946270414      Precision: 81.13974670214475      F1-score1: 45.292510196313465       F1-score2: 39.80683122294189\n","THRESHOLD IS =====>  0.88\n","Recall: 30.944861640796113      Precision: 81.85300269579601      F1-score1: 44.91095391215532       F1-score2: 39.4734200049043\n","THRESHOLD IS =====>  0.89\n","Recall: 30.590000071519878      Precision: 82.35510387358968      F1-score1: 44.61003700713699       F1-score2: 39.208819671991044\n","THRESHOLD IS =====>  0.9\n","Recall: 30.046636285064853      Precision: 82.91872389645143      F1-score1: 44.109605531024485       F1-score2: 38.73522563225919\n","THRESHOLD IS =====>  0.91\n","Recall: 29.4890351070624      Precision: 83.74105409840044      F1-score1: 43.61813898652308       F1-score2: 38.33380563858087\n","THRESHOLD IS =====>  0.92\n","Recall: 28.839601254527246      Precision: 84.5216761364867      F1-score1: 43.005362911229724       F1-score2: 37.79705995500474\n","THRESHOLD IS =====>  0.93\n","Recall: 28.07726904231338      Precision: 85.49081138277863      F1-score1: 42.27153444621582       F1-score2: 37.17017427567662\n","THRESHOLD IS =====>  0.94\n","Recall: 27.428590231961756      Precision: 86.60082721742033      F1-score1: 41.66185632843317       F1-score2: 36.743263028458834\n","THRESHOLD IS =====>  0.95\n","Recall: 26.649698646324588      Precision: 87.82708951535585      F1-score1: 40.891529298713856       F1-score2: 36.13823503413081\n","THRESHOLD IS =====>  0.96\n","Recall: 25.720018508720603      Precision: 89.15622655445618      F1-score1: 39.92295876118162       F1-score2: 35.492688080846314\n","THRESHOLD IS =====>  0.97\n","Recall: 24.76934751168486      Precision: 90.92287683976336      F1-score1: 38.93261359319746       F1-score2: 34.81513321433089\n","THRESHOLD IS =====>  0.98\n","Recall: 23.586285528381694      Precision: 92.36589347893333      F1-score1: 37.577014167897126       F1-score2: 33.8871411895261\n","THRESHOLD IS =====>  0.99\n","Recall: 21.61997338022865      Precision: 94.59019153887921      F1-score1: 35.19549988634501       F1-score2: 32.185385511126086\n","THRESHOLD IS =====>  1.0\n","Recall: 0.5825434696884333      Precision: 100.0      F1-score1: 1.1583391105316176       F1-score2: 0.9893301798074189\n","AUPR: 0.493\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"m3JKiOQd7oAY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622261264676,"user_tz":-330,"elapsed":7276,"user":{"displayName":"Bikku Kumar","photoUrl":"","userId":"05745485641699477877"}},"outputId":"35166faa-7552-4f4a-8398-3b164abb8d64"},"source":["# Testing\n","def test_fun1(file):\n","    X_test_new, Y_test_new = final_model(file)\n","    print(X_test_new.shape, Y_test_new.shape)\n","    test_preds = model1.predict(X_test_new)\n","    Y_test_new = np.array(Y_test_new).astype(None)\n","    test_preds[test_preds>=th_set] = int(1)\n","    test_preds[test_preds<th_set] = int(0)\n","    rec = recall(Y_test_new, test_preds)*100\n","    pre = precision(Y_test_new, test_preds)*100\n","    f1 = f_score(Y_test_new, test_preds)*100\n","    print('      Recall: {0}'.format(rec),  '       Precision: {0}'.format(pre),  '       F1-score: {0}'.format(f1))\n","\n","test_fun1(\"testData200.csv\")\n","test_fun1(\"testData500.csv\")\n","test_fun1(\"testData1000.csv\")\n","test_fun1(\"testData16000.csv\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Extracting features based on LSTM model...... \n","(289, 677) (289, 677)\n","      Recall: 42.63199067591191        Precision: 41.76765451185193        F1-score: 37.54190768424841\n","Extracting features based on LSTM model...... \n","(499, 677) (499, 677)\n","      Recall: 48.30382252763581        Precision: 60.88838500104931        F1-score: 49.156560912618346\n","Extracting features based on LSTM model...... \n","(248, 677) (248, 677)\n","      Recall: 49.38668652916166        Precision: 66.47595874766179        F1-score: 52.25345571498969\n","Extracting features based on LSTM model...... \n","(101, 677) (101, 677)\n","      Recall: 45.15178509735992        Precision: 59.559065796689545        F1-score: 46.13064458652721\n"],"name":"stdout"}]}]}