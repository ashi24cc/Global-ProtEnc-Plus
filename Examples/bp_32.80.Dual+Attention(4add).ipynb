{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"32.200.80.Simple+Rank+Attention(4add).ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"tLKiBOouMMv4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622449685561,"user_tz":-330,"elapsed":24287,"user":{"displayName":"Bikku Kumar","photoUrl":"","userId":"05745485641699477877"}},"outputId":"b1ac162f-9449-4d10-f56f-595ec584e3a1"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XJRU8PeYdddG"},"source":["import numpy as np\n","\n","def accuracy(y_true, y_pred, normalize=True, sample_weight=None):\n","    acc_list = []\n","    for i in range(y_true.shape[0]):\n","        set_true = set( np.where(y_true[i])[0] )\n","        set_pred = set( np.where(y_pred[i])[0] )\n","        #print('\\nset_true: {0}'.format(set_true), ', set_pred: {0}'.format(set_pred))\n","        tmp_a = None\n","        if len(set_true) == 0 and len(set_pred) == 0:\n","            tmp_a = 1\n","        else:\n","            tmp_a = len(set_true.intersection(set_pred))/\\\n","                    float( len(set_true.union(set_pred)) )\n","        acc_list.append(tmp_a)\n","    return np.mean(acc_list)\n","\n","def precision(y_true, y_pred, normalize=True, sample_weight=None):\n","    pre_list = []\n","    for i in range(y_true.shape[0]):\n","        set_true = set( np.where(y_true[i])[0] )\n","        set_pred = set( np.where(y_pred[i])[0] )\n","        tmp_prec = None\n","        if len(set_true) == 0 and len(set_pred) == 0:\n","            tmp_prec = 1\n","            pre_list.append(tmp_prec)\n","        elif len(set_pred) > 0:\n","            tmp_prec = len(set_true.intersection(set_pred))/\\\n","                    float(len(set_pred))\n","            pre_list.append(tmp_prec)\n","        else:\n","            None\n","    return np.mean(pre_list)\n","\n","def recall(y_true, y_pred, normalize=True, sample_weight=None):\n","    rec_list = []\n","    for i in range(y_true.shape[0]):\n","        set_true = set( np.where(y_true[i])[0] )\n","        set_pred = set( np.where(y_pred[i])[0] )\n","        tmp_rec = None\n","        if len(set_true) == 0 and len(set_pred) == 0:\n","            tmp_rec = 1\n","        else:\n","            tmp_rec = len(set_true.intersection(set_pred))/\\\n","                    float(len(set_true))\n","        rec_list.append(tmp_rec)\n","    return np.mean(rec_list)\n","\n","def f_score(y_true, y_pred, normalize=True, sample_weight=None):\n","    acc_list = []\n","    for i in range(y_true.shape[0]):\n","        set_true = set( np.where(y_true[i])[0] )\n","        set_pred = set( np.where(y_pred[i])[0] )\n","        tmp_a = None\n","        if len(set_true) == 0 and len(set_pred) == 0:\n","            tmp_a = 1\n","        else:\n","            tmp_a = (2*len(set_true.intersection(set_pred)))/\\\n","                    float( len(set_true) + len(set_pred))\n","        acc_list.append(tmp_a)\n","    return np.mean(acc_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MJ3-760liiG3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622449710795,"user_tz":-330,"elapsed":4045,"user":{"displayName":"Bikku Kumar","photoUrl":"","userId":"05745485641699477877"}},"outputId":"24c37975-eb25-4ae1-e2ab-fc2d12a7ada5"},"source":["from csv import writer\n","import pandas as pd\n","\n","def test_segment(filename, low, up):\n","    myFile = open(filename, 'w', newline = '')\n","    with myFile:\n","        csv_writer = writer(myFile)\n","        for j, row in enumerate(seqData):\n","            segment = [ ]\n","            if(len(row) > low and len(row) < up):\n","                segment.append(row)\n","                for item in label[j]:\n","                    segment.append(item)\n","                csv_writer.writerow(segment)\n","    myFile.close()\n","\n","dataframe = pd.read_csv(\"/content/gdrive/My Drive/Multi-Attn/CAFA3/bp/test_data_bp1.csv\", header=None)\n","dataset = dataframe.values\n","seqData = dataset[:,0]\n","label = dataset[:,1:len(dataset[0])]\n","print('Original Dataset Size : %s' %len(dataset))\n","test_segment('testData200.csv', 0, 201)\n","test_segment('testData500.csv', 200, 501)\n","test_segment('testData1000.csv', 500, 1001)\n","test_segment('testData16000.csv', 1000, 16000)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Original Dataset Size : 2392\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"35nv9VuTSZoV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622450073708,"user_tz":-330,"elapsed":362168,"user":{"displayName":"Bikku Kumar","photoUrl":"","userId":"05745485641699477877"}},"outputId":"c06ec654-dfc0-4b51-80cb-b7ae302d1c14"},"source":["from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","import math\n","\n","def segment(dataset, label, seg_size, overlap):\n","    print(\"Non-overlapping Region: %s\" %overlap)\n","    print(\"Segment Size: %s\" %seg_size)\n","  \n","    seq_data, label_data = [], []\n","    for j, row in enumerate(dataset):\n","        if(len(row) < 2001):\n","            pos = math.ceil(len(row)/overlap)\n","            if(pos < math.ceil(seg_size/overlap)):\n","                pos = math.ceil(seg_size/overlap)\n","            for itr in range(pos - math.ceil(seg_size/overlap) + 1):\n","                init = itr * overlap\n","                if(len(row[init : init + seg_size]) > 40):\n","                    seq_data.append(row[init : init + seg_size])\n","                    label_data.append(label[j])\n","    return seq_data, label_data\n","\n","dataframe = pd.read_csv('/content/gdrive/My Drive/Multi-Attn/CAFA3/bp/train_data_bp1.csv', header=None)\n","dataset = dataframe.values\n","print('Original Dataset Size : %s' %len(dataset))\n","X = dataset[:,0]\n","Y = dataset[:,1:len(dataset[0])]\n","del dataframe, dataset\n","print(X.shape, Y.shape)\n","\n","# Preparing For Training\n","segmentSize = 80\n","nonOL = 40\n","SEG = str(segmentSize)\n","\n","X, Y = segment(X, Y, segmentSize, nonOL)\n","nb_of_cls = len(Y[0])\n","\n","#Split the dataset\n","x_tr, x_val, y_tr, y_val = train_test_split(X, Y, test_size = 0.1, random_state = 42)\n","del X, Y\n","\n","y_train = np.array(y_tr, dtype=None)\n","y_validate = np.array(y_val, dtype=None)\n","print(len(x_tr), len(x_val))\n","print(y_train.shape, y_validate.shape)\n","\n","del y_tr, y_val"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Original Dataset Size : 53500\n","(53500,) (53500, 3992)\n","Non-overlapping Region: 40\n","Segment Size: 80\n","564680 62743\n","(564680, 3992) (62743, 3992)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dSSTBBiyzk9f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622451076948,"user_tz":-330,"elapsed":34271,"user":{"displayName":"Bikku Kumar","photoUrl":"","userId":"05745485641699477877"}},"outputId":"ee82fb31-854e-49a6-975d-3b80e7b0ea18"},"source":["%tensorflow_version 1.x\n","import math\n","import pandas as pd\n","import tensorflow as tf\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, CuDNNGRU, Bidirectional, Input, Dropout, Add\n","from keras.layers import Flatten, Activation, RepeatVector, Permute, multiply, Lambda\n","from keras import backend as K\n","from keras.layers.embeddings import Embedding\n","from keras.preprocessing import sequence\n","from keras.callbacks import EarlyStopping\n","import matplotlib.pyplot as plt\n","np.random.seed(7)\n","\n","def epsilon():\n","    _EPSILON = 1e-7\n","    return _EPSILON\n","\n","def _to_tensor(x, dtype):\n","    return tf.convert_to_tensor(x, dtype=dtype)\n","\n","def categorical_crossentropy(target, output, from_logits=False):\n","    if not from_logits:\n","        output /= tf.reduce_sum(output, len(output.get_shape()) - 1, True)      # scale preds so that the class probas of each sample sum to 1\n","        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)               # manual computation of crossentropy\n","        output = tf.clip_by_value(output, _epsilon, 1. - _epsilon)\n","        return - tf.reduce_sum(target * tf.log(output), len(output.get_shape()) - 1)\n","    else:\n","        return tf.nn.softmax_cross_entropy_with_logits(labels=target, logits=output)\n","\n","def dictionary(chunk_size):\n","    dataframe = pd.read_csv(\"/content/gdrive/My Drive/Multi-Attn/CAFA3/bp/train_data_bp1.csv\", header=None)\n","    dataset = dataframe.values\n","    del dataframe\n","\n","    seq_dataset = dataset[:,0]\n","    print('Creating Dictionary:')\n","    dict = {}\n","    j = 0\n","    for row in seq_dataset:\n","        for i in range(len(row) - chunk_size + 1):\n","            key = row[i:i + chunk_size]\n","            if key not in dict:\n","                dict[key] = j\n","                j = j + 1\n","    del dataset, seq_dataset\n","    return(dict)\n","\n","def nGram(dataset, chunk_size, dictI):\n","    dict1 = list()\n","    for j, row in enumerate(dataset):\n","        string = row\n","        dict2 = list()\n","        for i in range(len(string) - chunk_size + 1):\n","            try:\n","                dict2.append(dictI[string[i:i + chunk_size]])\n","            except:\n","                None\n","        dict1.append(dict2)   \n","    return(dict1)\n","\n","# CREATING DICTIONARY\n","chunkSize = 4\n","dict_Prop = dictionary(chunkSize)\n","max_seq_len = segmentSize - chunkSize + 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Creating Dictionary:\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wH3YAz-2gqXZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622460900903,"user_tz":-330,"elapsed":9577644,"user":{"displayName":"Bikku Kumar","photoUrl":"","userId":"05745485641699477877"}},"outputId":"87d55a33-7eb6-4335-af41-5e10b12f7cd8"},"source":["def create_rec_model1(top_words, seq_len, o_dim):\n","    embedding_vecor_length = 32\n","\n","    _input = Input(shape=[seq_len])\n","    embdd = Embedding(top_words, embedding_vecor_length, input_length = seq_len)(_input)\n","    drop1 = Dropout(0.4)(embdd)\n","    activations = Bidirectional(CuDNNGRU(200, return_sequences=True))(drop1)\n","\n","    # compute importance for each step\n","    attention1 = Dense(1, activation='tanh')(activations)\n","    attention1 = Flatten()(attention1)\n","    attention1 = Activation('softmax')(attention1)\n","    \n","    attention2 = Dense(1, activation='tanh')(activations)\n","    attention2 = Flatten()(attention2)\n","    attention2 = Activation('softmax')(attention2)\n","\n","    attention3 = Dense(1, activation='tanh')(activations)\n","    attention3 = Flatten()(attention3)\n","    attention3 = Activation('softmax')(attention3)\n","\n","    attention4 = Dense(1, activation='tanh')(activations)\n","    attention4 = Flatten()(attention4)\n","    attention4 = Activation('softmax')(attention4)\n","    \n","    attention = Add()([attention1,attention2,attention3,attention4])\n","    attention = RepeatVector(400)(attention)\n","    attention = Permute([2, 1])(attention)\n","    \n","    sent_representation = multiply([activations, attention])\n","    sent_representation = Lambda(lambda xin: K.sum(xin, axis=1))(sent_representation)\n","\n","    drop2 = Dropout(0.5)(sent_representation)\n","\n","    den1 = Dense(o_dim, kernel_initializer='normal', activation='softmax', name='RANKING')(drop2)\n","    den2 = Dense(o_dim, kernel_initializer='normal', activation='sigmoid', name='CLASSIFIER')(drop2)\n","\n","    r_model = Model(inputs = [_input], outputs = [den1,den2])\n","    r_model.compile(loss=[categorical_crossentropy,'binary_crossentropy'], loss_weights=[0.30, 1.0],\n","                    optimizer='adam', metrics=['accuracy'])\n","    return r_model\n","\n","#CREATING N-GRAM\n","x_train = nGram(x_tr, chunkSize, dict_Prop)\n","x_validate = nGram(x_val, chunkSize, dict_Prop)\n","del x_tr, x_val\n","\n","# truncate and pad input sequences\n","x_train = sequence.pad_sequences(x_train, maxlen=max_seq_len)\n","x_validate = sequence.pad_sequences(x_validate, maxlen=max_seq_len)\n","\n","# Create & Compile the model\n","model = create_rec_model1(len(dict_Prop), max_seq_len, nb_of_cls)\n","print(model.summary())\n","early_stopping_monitor1 = EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 1)\n","history = model.fit(x_train, [y_train, y_train],\n","          validation_data = (x_validate, [y_validate, y_validate]),\n","          epochs = 1000,\n","          batch_size = 150,\n","          callbacks=[early_stopping_monitor1],\n","          verbose=1)\n","\n","del y_train, y_validate"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 77)           0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 77, 32)       5151776     input_1[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 77, 32)       0           embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","bidirectional_1 (Bidirectional) (None, 77, 400)      280800      dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 77, 1)        401         bidirectional_1[0][0]            \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 77, 1)        401         bidirectional_1[0][0]            \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 77, 1)        401         bidirectional_1[0][0]            \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 77, 1)        401         bidirectional_1[0][0]            \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 77)           0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","flatten_2 (Flatten)             (None, 77)           0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","flatten_3 (Flatten)             (None, 77)           0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","flatten_4 (Flatten)             (None, 77)           0           dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 77)           0           flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 77)           0           flatten_2[0][0]                  \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 77)           0           flatten_3[0][0]                  \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 77)           0           flatten_4[0][0]                  \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 77)           0           activation_1[0][0]               \n","                                                                 activation_2[0][0]               \n","                                                                 activation_3[0][0]               \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","repeat_vector_1 (RepeatVector)  (None, 400, 77)      0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","permute_1 (Permute)             (None, 77, 400)      0           repeat_vector_1[0][0]            \n","__________________________________________________________________________________________________\n","multiply_1 (Multiply)           (None, 77, 400)      0           bidirectional_1[0][0]            \n","                                                                 permute_1[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 400)          0           multiply_1[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 400)          0           lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","RANKING (Dense)                 (None, 3992)         1600792     dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","CLASSIFIER (Dense)              (None, 3992)         1600792     dropout_2[0][0]                  \n","==================================================================================================\n","Total params: 8,635,764\n","Trainable params: 8,635,764\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 564680 samples, validate on 62743 samples\n","Epoch 1/1000\n","564680/564680 [==============================] - 226s 400us/step - loss: 115.4676 - RANKING_loss: 384.7184 - CLASSIFIER_loss: 0.0546 - RANKING_accuracy: 0.0064 - CLASSIFIER_accuracy: 0.9857 - val_loss: 113.1628 - val_RANKING_loss: 376.9251 - val_CLASSIFIER_loss: 0.0479 - val_RANKING_accuracy: 0.0044 - val_CLASSIFIER_accuracy: 0.9868\n","Epoch 2/1000\n","564680/564680 [==============================] - 222s 392us/step - loss: 111.5258 - RANKING_loss: 371.5907 - CLASSIFIER_loss: 0.0461 - RANKING_accuracy: 0.0071 - CLASSIFIER_accuracy: 0.9870 - val_loss: 111.1888 - val_RANKING_loss: 370.3608 - val_CLASSIFIER_loss: 0.0457 - val_RANKING_accuracy: 0.0054 - val_CLASSIFIER_accuracy: 0.9870\n","Epoch 3/1000\n","564680/564680 [==============================] - 221s 391us/step - loss: 109.1334 - RANKING_loss: 363.6321 - CLASSIFIER_loss: 0.0436 - RANKING_accuracy: 0.0082 - CLASSIFIER_accuracy: 0.9873 - val_loss: 110.2056 - val_RANKING_loss: 367.0868 - val_CLASSIFIER_loss: 0.0447 - val_RANKING_accuracy: 0.0064 - val_CLASSIFIER_accuracy: 0.9871\n","Epoch 4/1000\n","564680/564680 [==============================] - 221s 392us/step - loss: 107.6599 - RANKING_loss: 358.7265 - CLASSIFIER_loss: 0.0421 - RANKING_accuracy: 0.0097 - CLASSIFIER_accuracy: 0.9875 - val_loss: 109.4236 - val_RANKING_loss: 364.4834 - val_CLASSIFIER_loss: 0.0438 - val_RANKING_accuracy: 0.0058 - val_CLASSIFIER_accuracy: 0.9872\n","Epoch 5/1000\n","564680/564680 [==============================] - 221s 392us/step - loss: 106.6001 - RANKING_loss: 355.1972 - CLASSIFIER_loss: 0.0410 - RANKING_accuracy: 0.0102 - CLASSIFIER_accuracy: 0.9877 - val_loss: 108.8018 - val_RANKING_loss: 362.4119 - val_CLASSIFIER_loss: 0.0432 - val_RANKING_accuracy: 0.0078 - val_CLASSIFIER_accuracy: 0.9873\n","Epoch 6/1000\n","564680/564680 [==============================] - 221s 392us/step - loss: 105.7369 - RANKING_loss: 352.3269 - CLASSIFIER_loss: 0.0401 - RANKING_accuracy: 0.0107 - CLASSIFIER_accuracy: 0.9878 - val_loss: 108.3618 - val_RANKING_loss: 360.9480 - val_CLASSIFIER_loss: 0.0427 - val_RANKING_accuracy: 0.0058 - val_CLASSIFIER_accuracy: 0.9874\n","Epoch 7/1000\n","564680/564680 [==============================] - 220s 390us/step - loss: 105.0329 - RANKING_loss: 349.9749 - CLASSIFIER_loss: 0.0393 - RANKING_accuracy: 0.0114 - CLASSIFIER_accuracy: 0.9879 - val_loss: 107.9695 - val_RANKING_loss: 359.6419 - val_CLASSIFIER_loss: 0.0423 - val_RANKING_accuracy: 0.0078 - val_CLASSIFIER_accuracy: 0.9874\n","Epoch 8/1000\n","564680/564680 [==============================] - 221s 391us/step - loss: 104.4220 - RANKING_loss: 347.9437 - CLASSIFIER_loss: 0.0386 - RANKING_accuracy: 0.0121 - CLASSIFIER_accuracy: 0.9880 - val_loss: 107.5826 - val_RANKING_loss: 358.3554 - val_CLASSIFIER_loss: 0.0419 - val_RANKING_accuracy: 0.0083 - val_CLASSIFIER_accuracy: 0.9875\n","Epoch 9/1000\n","564680/564680 [==============================] - 221s 391us/step - loss: 103.8917 - RANKING_loss: 346.1815 - CLASSIFIER_loss: 0.0381 - RANKING_accuracy: 0.0125 - CLASSIFIER_accuracy: 0.9881 - val_loss: 107.3467 - val_RANKING_loss: 357.5714 - val_CLASSIFIER_loss: 0.0417 - val_RANKING_accuracy: 0.0106 - val_CLASSIFIER_accuracy: 0.9875\n","Epoch 10/1000\n","564680/564680 [==============================] - 221s 391us/step - loss: 103.4633 - RANKING_loss: 344.7462 - CLASSIFIER_loss: 0.0376 - RANKING_accuracy: 0.0128 - CLASSIFIER_accuracy: 0.9881 - val_loss: 107.0310 - val_RANKING_loss: 356.5193 - val_CLASSIFIER_loss: 0.0414 - val_RANKING_accuracy: 0.0115 - val_CLASSIFIER_accuracy: 0.9875\n","Epoch 11/1000\n","564680/564680 [==============================] - 221s 391us/step - loss: 103.0796 - RANKING_loss: 343.4781 - CLASSIFIER_loss: 0.0372 - RANKING_accuracy: 0.0131 - CLASSIFIER_accuracy: 0.9882 - val_loss: 106.7220 - val_RANKING_loss: 355.4899 - val_CLASSIFIER_loss: 0.0413 - val_RANKING_accuracy: 0.0122 - val_CLASSIFIER_accuracy: 0.9875\n","Epoch 12/1000\n","564680/564680 [==============================] - 219s 388us/step - loss: 102.7368 - RANKING_loss: 342.3337 - CLASSIFIER_loss: 0.0367 - RANKING_accuracy: 0.0138 - CLASSIFIER_accuracy: 0.9883 - val_loss: 106.3894 - val_RANKING_loss: 354.3790 - val_CLASSIFIER_loss: 0.0408 - val_RANKING_accuracy: 0.0074 - val_CLASSIFIER_accuracy: 0.9876\n","Epoch 13/1000\n","564680/564680 [==============================] - 221s 392us/step - loss: 102.4735 - RANKING_loss: 341.4619 - CLASSIFIER_loss: 0.0364 - RANKING_accuracy: 0.0140 - CLASSIFIER_accuracy: 0.9883 - val_loss: 106.4118 - val_RANKING_loss: 354.4528 - val_CLASSIFIER_loss: 0.0408 - val_RANKING_accuracy: 0.0137 - val_CLASSIFIER_accuracy: 0.9876\n","Epoch 14/1000\n","564680/564680 [==============================] - 222s 393us/step - loss: 102.1976 - RANKING_loss: 340.5347 - CLASSIFIER_loss: 0.0361 - RANKING_accuracy: 0.0143 - CLASSIFIER_accuracy: 0.9884 - val_loss: 106.0379 - val_RANKING_loss: 353.2118 - val_CLASSIFIER_loss: 0.0404 - val_RANKING_accuracy: 0.0148 - val_CLASSIFIER_accuracy: 0.9877\n","Epoch 15/1000\n","564680/564680 [==============================] - 225s 399us/step - loss: 101.9731 - RANKING_loss: 339.7872 - CLASSIFIER_loss: 0.0358 - RANKING_accuracy: 0.0142 - CLASSIFIER_accuracy: 0.9884 - val_loss: 106.1126 - val_RANKING_loss: 353.4635 - val_CLASSIFIER_loss: 0.0404 - val_RANKING_accuracy: 0.0114 - val_CLASSIFIER_accuracy: 0.9877\n","Epoch 16/1000\n","564680/564680 [==============================] - 225s 398us/step - loss: 101.7662 - RANKING_loss: 339.0952 - CLASSIFIER_loss: 0.0356 - RANKING_accuracy: 0.0143 - CLASSIFIER_accuracy: 0.9885 - val_loss: 105.9911 - val_RANKING_loss: 353.0582 - val_CLASSIFIER_loss: 0.0403 - val_RANKING_accuracy: 0.0154 - val_CLASSIFIER_accuracy: 0.9877\n","Epoch 17/1000\n","564680/564680 [==============================] - 214s 379us/step - loss: 101.5632 - RANKING_loss: 338.4225 - CLASSIFIER_loss: 0.0353 - RANKING_accuracy: 0.0145 - CLASSIFIER_accuracy: 0.9885 - val_loss: 105.8716 - val_RANKING_loss: 352.6618 - val_CLASSIFIER_loss: 0.0403 - val_RANKING_accuracy: 0.0147 - val_CLASSIFIER_accuracy: 0.9877\n","Epoch 18/1000\n","564680/564680 [==============================] - 217s 384us/step - loss: 101.3940 - RANKING_loss: 337.8604 - CLASSIFIER_loss: 0.0351 - RANKING_accuracy: 0.0146 - CLASSIFIER_accuracy: 0.9886 - val_loss: 105.9376 - val_RANKING_loss: 352.8801 - val_CLASSIFIER_loss: 0.0403 - val_RANKING_accuracy: 0.0098 - val_CLASSIFIER_accuracy: 0.9877\n","Epoch 19/1000\n","564680/564680 [==============================] - 217s 384us/step - loss: 101.2288 - RANKING_loss: 337.3289 - CLASSIFIER_loss: 0.0349 - RANKING_accuracy: 0.0147 - CLASSIFIER_accuracy: 0.9886 - val_loss: 105.4505 - val_RANKING_loss: 351.2582 - val_CLASSIFIER_loss: 0.0399 - val_RANKING_accuracy: 0.0120 - val_CLASSIFIER_accuracy: 0.9877\n","Epoch 20/1000\n","564680/564680 [==============================] - 220s 389us/step - loss: 101.0753 - RANKING_loss: 336.8107 - CLASSIFIER_loss: 0.0347 - RANKING_accuracy: 0.0148 - CLASSIFIER_accuracy: 0.9886 - val_loss: 105.4674 - val_RANKING_loss: 351.3138 - val_CLASSIFIER_loss: 0.0402 - val_RANKING_accuracy: 0.0135 - val_CLASSIFIER_accuracy: 0.9877\n","Epoch 21/1000\n","564680/564680 [==============================] - 220s 390us/step - loss: 100.9447 - RANKING_loss: 336.3712 - CLASSIFIER_loss: 0.0346 - RANKING_accuracy: 0.0148 - CLASSIFIER_accuracy: 0.9887 - val_loss: 105.1616 - val_RANKING_loss: 350.3002 - val_CLASSIFIER_loss: 0.0396 - val_RANKING_accuracy: 0.0082 - val_CLASSIFIER_accuracy: 0.9878\n","Epoch 22/1000\n","564680/564680 [==============================] - 221s 391us/step - loss: 100.8092 - RANKING_loss: 335.9157 - CLASSIFIER_loss: 0.0344 - RANKING_accuracy: 0.0148 - CLASSIFIER_accuracy: 0.9887 - val_loss: 105.3699 - val_RANKING_loss: 350.9926 - val_CLASSIFIER_loss: 0.0399 - val_RANKING_accuracy: 0.0121 - val_CLASSIFIER_accuracy: 0.9877\n","Epoch 23/1000\n","564680/564680 [==============================] - 221s 391us/step - loss: 100.6941 - RANKING_loss: 335.5329 - CLASSIFIER_loss: 0.0342 - RANKING_accuracy: 0.0150 - CLASSIFIER_accuracy: 0.9887 - val_loss: 105.1984 - val_RANKING_loss: 350.4172 - val_CLASSIFIER_loss: 0.0395 - val_RANKING_accuracy: 0.0130 - val_CLASSIFIER_accuracy: 0.9878\n","Epoch 24/1000\n","564680/564680 [==============================] - 219s 388us/step - loss: 100.5750 - RANKING_loss: 335.1387 - CLASSIFIER_loss: 0.0341 - RANKING_accuracy: 0.0148 - CLASSIFIER_accuracy: 0.9888 - val_loss: 105.1920 - val_RANKING_loss: 350.3969 - val_CLASSIFIER_loss: 0.0395 - val_RANKING_accuracy: 0.0120 - val_CLASSIFIER_accuracy: 0.9878\n","Epoch 25/1000\n","564680/564680 [==============================] - 218s 386us/step - loss: 100.4804 - RANKING_loss: 334.8273 - CLASSIFIER_loss: 0.0340 - RANKING_accuracy: 0.0147 - CLASSIFIER_accuracy: 0.9888 - val_loss: 104.9360 - val_RANKING_loss: 349.5493 - val_CLASSIFIER_loss: 0.0394 - val_RANKING_accuracy: 0.0103 - val_CLASSIFIER_accuracy: 0.9878\n","Epoch 26/1000\n","564680/564680 [==============================] - 215s 380us/step - loss: 100.3679 - RANKING_loss: 334.4463 - CLASSIFIER_loss: 0.0338 - RANKING_accuracy: 0.0149 - CLASSIFIER_accuracy: 0.9888 - val_loss: 105.0310 - val_RANKING_loss: 349.8659 - val_CLASSIFIER_loss: 0.0393 - val_RANKING_accuracy: 0.0136 - val_CLASSIFIER_accuracy: 0.9878\n","Epoch 27/1000\n","564680/564680 [==============================] - 216s 382us/step - loss: 100.2822 - RANKING_loss: 334.1618 - CLASSIFIER_loss: 0.0337 - RANKING_accuracy: 0.0146 - CLASSIFIER_accuracy: 0.9888 - val_loss: 105.0226 - val_RANKING_loss: 349.8372 - val_CLASSIFIER_loss: 0.0395 - val_RANKING_accuracy: 0.0138 - val_CLASSIFIER_accuracy: 0.9878\n","Epoch 28/1000\n","564680/564680 [==============================] - 215s 381us/step - loss: 100.1956 - RANKING_loss: 333.8755 - CLASSIFIER_loss: 0.0336 - RANKING_accuracy: 0.0148 - CLASSIFIER_accuracy: 0.9889 - val_loss: 104.8736 - val_RANKING_loss: 349.3430 - val_CLASSIFIER_loss: 0.0392 - val_RANKING_accuracy: 0.0160 - val_CLASSIFIER_accuracy: 0.9878\n","Epoch 29/1000\n","564680/564680 [==============================] - 214s 379us/step - loss: 100.0984 - RANKING_loss: 333.5500 - CLASSIFIER_loss: 0.0335 - RANKING_accuracy: 0.0149 - CLASSIFIER_accuracy: 0.9889 - val_loss: 104.8676 - val_RANKING_loss: 349.3206 - val_CLASSIFIER_loss: 0.0392 - val_RANKING_accuracy: 0.0144 - val_CLASSIFIER_accuracy: 0.9878\n","Epoch 30/1000\n","564680/564680 [==============================] - 211s 374us/step - loss: 100.0311 - RANKING_loss: 333.3286 - CLASSIFIER_loss: 0.0334 - RANKING_accuracy: 0.0148 - CLASSIFIER_accuracy: 0.9889 - val_loss: 104.9104 - val_RANKING_loss: 349.4651 - val_CLASSIFIER_loss: 0.0394 - val_RANKING_accuracy: 0.0143 - val_CLASSIFIER_accuracy: 0.9877\n","Epoch 31/1000\n","564680/564680 [==============================] - 211s 373us/step - loss: 99.9603 - RANKING_loss: 333.0965 - CLASSIFIER_loss: 0.0333 - RANKING_accuracy: 0.0151 - CLASSIFIER_accuracy: 0.9889 - val_loss: 104.6521 - val_RANKING_loss: 348.6024 - val_CLASSIFIER_loss: 0.0390 - val_RANKING_accuracy: 0.0123 - val_CLASSIFIER_accuracy: 0.9879\n","Epoch 32/1000\n","564680/564680 [==============================] - 211s 373us/step - loss: 99.8907 - RANKING_loss: 332.8629 - CLASSIFIER_loss: 0.0332 - RANKING_accuracy: 0.0147 - CLASSIFIER_accuracy: 0.9889 - val_loss: 105.0803 - val_RANKING_loss: 350.0311 - val_CLASSIFIER_loss: 0.0393 - val_RANKING_accuracy: 0.0168 - val_CLASSIFIER_accuracy: 0.9879\n","Epoch 33/1000\n","564680/564680 [==============================] - 211s 374us/step - loss: 99.8196 - RANKING_loss: 332.6200 - CLASSIFIER_loss: 0.0331 - RANKING_accuracy: 0.0150 - CLASSIFIER_accuracy: 0.9890 - val_loss: 104.5211 - val_RANKING_loss: 348.1692 - val_CLASSIFIER_loss: 0.0387 - val_RANKING_accuracy: 0.0120 - val_CLASSIFIER_accuracy: 0.9880\n","Epoch 34/1000\n","564680/564680 [==============================] - 210s 372us/step - loss: 99.7505 - RANKING_loss: 332.3871 - CLASSIFIER_loss: 0.0330 - RANKING_accuracy: 0.0148 - CLASSIFIER_accuracy: 0.9890 - val_loss: 104.7133 - val_RANKING_loss: 348.8049 - val_CLASSIFIER_loss: 0.0389 - val_RANKING_accuracy: 0.0140 - val_CLASSIFIER_accuracy: 0.9879\n","Epoch 35/1000\n","564680/564680 [==============================] - 211s 373us/step - loss: 99.6923 - RANKING_loss: 332.2051 - CLASSIFIER_loss: 0.0329 - RANKING_accuracy: 0.0150 - CLASSIFIER_accuracy: 0.9890 - val_loss: 104.8571 - val_RANKING_loss: 349.2827 - val_CLASSIFIER_loss: 0.0391 - val_RANKING_accuracy: 0.0154 - val_CLASSIFIER_accuracy: 0.9879\n","Epoch 36/1000\n","564680/564680 [==============================] - 210s 373us/step - loss: 99.6270 - RANKING_loss: 331.9763 - CLASSIFIER_loss: 0.0329 - RANKING_accuracy: 0.0154 - CLASSIFIER_accuracy: 0.9890 - val_loss: 104.3416 - val_RANKING_loss: 347.5679 - val_CLASSIFIER_loss: 0.0387 - val_RANKING_accuracy: 0.0190 - val_CLASSIFIER_accuracy: 0.9879\n","Epoch 37/1000\n","564680/564680 [==============================] - 211s 373us/step - loss: 99.5771 - RANKING_loss: 331.8123 - CLASSIFIER_loss: 0.0328 - RANKING_accuracy: 0.0147 - CLASSIFIER_accuracy: 0.9890 - val_loss: 104.5328 - val_RANKING_loss: 348.1998 - val_CLASSIFIER_loss: 0.0387 - val_RANKING_accuracy: 0.0220 - val_CLASSIFIER_accuracy: 0.9879\n","Epoch 38/1000\n","564680/564680 [==============================] - 211s 374us/step - loss: 99.5127 - RANKING_loss: 331.5956 - CLASSIFIER_loss: 0.0327 - RANKING_accuracy: 0.0151 - CLASSIFIER_accuracy: 0.9890 - val_loss: 104.3567 - val_RANKING_loss: 347.6176 - val_CLASSIFIER_loss: 0.0387 - val_RANKING_accuracy: 0.0102 - val_CLASSIFIER_accuracy: 0.9879\n","Epoch 39/1000\n","564680/564680 [==============================] - 210s 373us/step - loss: 99.4569 - RANKING_loss: 331.4169 - CLASSIFIER_loss: 0.0326 - RANKING_accuracy: 0.0151 - CLASSIFIER_accuracy: 0.9891 - val_loss: 104.1433 - val_RANKING_loss: 346.9111 - val_CLASSIFIER_loss: 0.0382 - val_RANKING_accuracy: 0.0127 - val_CLASSIFIER_accuracy: 0.9880\n","Epoch 40/1000\n","564680/564680 [==============================] - 211s 373us/step - loss: 99.4121 - RANKING_loss: 331.2606 - CLASSIFIER_loss: 0.0326 - RANKING_accuracy: 0.0149 - CLASSIFIER_accuracy: 0.9891 - val_loss: 104.3259 - val_RANKING_loss: 347.5207 - val_CLASSIFIER_loss: 0.0385 - val_RANKING_accuracy: 0.0119 - val_CLASSIFIER_accuracy: 0.9880\n","Epoch 41/1000\n","564680/564680 [==============================] - 211s 374us/step - loss: 99.3545 - RANKING_loss: 331.0681 - CLASSIFIER_loss: 0.0325 - RANKING_accuracy: 0.0151 - CLASSIFIER_accuracy: 0.9891 - val_loss: 104.3874 - val_RANKING_loss: 347.7253 - val_CLASSIFIER_loss: 0.0385 - val_RANKING_accuracy: 0.0176 - val_CLASSIFIER_accuracy: 0.9880\n","Epoch 42/1000\n","564680/564680 [==============================] - 211s 373us/step - loss: 99.2940 - RANKING_loss: 330.8712 - CLASSIFIER_loss: 0.0324 - RANKING_accuracy: 0.0152 - CLASSIFIER_accuracy: 0.9891 - val_loss: 104.3897 - val_RANKING_loss: 347.7382 - val_CLASSIFIER_loss: 0.0385 - val_RANKING_accuracy: 0.0190 - val_CLASSIFIER_accuracy: 0.9880\n","Epoch 43/1000\n","564680/564680 [==============================] - 211s 373us/step - loss: 99.2620 - RANKING_loss: 330.7616 - CLASSIFIER_loss: 0.0324 - RANKING_accuracy: 0.0153 - CLASSIFIER_accuracy: 0.9891 - val_loss: 104.4266 - val_RANKING_loss: 347.8575 - val_CLASSIFIER_loss: 0.0385 - val_RANKING_accuracy: 0.0128 - val_CLASSIFIER_accuracy: 0.9880\n","Epoch 44/1000\n","564680/564680 [==============================] - 211s 373us/step - loss: 99.2175 - RANKING_loss: 330.6151 - CLASSIFIER_loss: 0.0323 - RANKING_accuracy: 0.0152 - CLASSIFIER_accuracy: 0.9891 - val_loss: 104.7248 - val_RANKING_loss: 348.8542 - val_CLASSIFIER_loss: 0.0389 - val_RANKING_accuracy: 0.0172 - val_CLASSIFIER_accuracy: 0.9879\n","Epoch 00044: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X5GOjLGM8Do0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622461630288,"user_tz":-330,"elapsed":720251,"user":{"displayName":"Bikku Kumar","photoUrl":"","userId":"05745485641699477877"}},"outputId":"a83044fa-9553-4619-a7ac-9bde697ba987"},"source":["from keras.models import load_model\n","\n","def cls_predict(pred, normalize=True, sample_weight=None):\n","    pred1 = pred[0]\n","    pred2 = pred[1]\n","    y_pred1 = (pred2)**(1-pred1)\n","    y_pred2 = (pred1)**(1-pred2)\n","    y_pred = y_pred1 + y_pred2\n","    s_mean = np.mean(y_pred, axis=0)\n","    m = max(s_mean)\n","    s_mean = (s_mean/m)\n","    return(list(s_mean))\n","\n","def final_model(filename):\n","    print('Extracting features based on LSTM model...... ')\n","    dataframe2 = pd.read_csv(filename, header=None)\n","    dataset2 = dataframe2.values\n","    overlap = 30\n","    X_test = dataset2[:,0]\n","    Y_test = dataset2[:,1:len(dataset2[0])]\n","    c_p = []\n","    for tag, row in enumerate(X_test):\n","        pos = math.ceil(len(row) / overlap)\n","        if(pos < math.ceil(segmentSize/ overlap)):\n","            pos = math.ceil(segmentSize/ overlap)\n","        segment = [ ]\n","        for itr in range(pos - math.ceil(segmentSize/overlap) + 1):\n","            init = itr * overlap\n","            segment.append(row[init : init + segmentSize])\n","        seg_nGram = nGram(segment, chunkSize, dict_Prop)\n","        test_seg = sequence.pad_sequences(seg_nGram, maxlen=max_seq_len)\n","        preds = model.predict(test_seg)\n","        c_p.append(cls_predict(preds))\n","    c_p = np.array(c_p)\n","    return c_p, Y_test\n","\n","def create_nn_model(dim):\n","    n_model = Sequential()\n","    n_model.add(Dense(dim, input_dim = dim, kernel_initializer='normal', activation='relu'))\n","    n_model.add(Dense(dim, kernel_initializer='normal', activation='sigmoid'))\n","    n_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    return n_model\n","\n","# Creates a HDF5 file 'my_model.h5'\n","model_path = '/content/gdrive/My Drive/Multi-Attn/CAFA3/bp/simple+rank/0.3(4L)/32.200.model_'+str(nonOL)+'_'+ SEG +'.h5'\n","model.save(model_path)\n","#del model  \n","#model = load_model(model_path, custom_objects={'categorical_crossentropy': categorical_crossentropy})\n","\n","# Training\n","X_train_new, Y_train_new = final_model(\"/content/gdrive/My Drive/Multi-Attn/CAFA3/bp/train_data_bp1.csv\")\n","\n","# Training model 2\n","model1 = create_nn_model(Y_train_new[0].shape[0])\n","print(model1.summary())\n","early_stopping_monitor = EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 1)\n","model1.fit(X_train_new, Y_train_new.astype(None),\n","           callbacks = [early_stopping_monitor],\n","           validation_split = 0.1,\n","           epochs = 1000,\n","           batch_size = 150,\n","           verbose = True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Extracting features based on LSTM model...... \n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_5 (Dense)              (None, 3992)              15940056  \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 3992)              15940056  \n","=================================================================\n","Total params: 31,880,112\n","Trainable params: 31,880,112\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Train on 48150 samples, validate on 5350 samples\n","Epoch 1/1000\n","48150/48150 [==============================] - 12s 258us/step - loss: 0.0424 - accuracy: 0.9885 - val_loss: 0.0246 - val_accuracy: 0.9924\n","Epoch 2/1000\n","48150/48150 [==============================] - 12s 254us/step - loss: 0.0245 - accuracy: 0.9922 - val_loss: 0.0229 - val_accuracy: 0.9927\n","Epoch 3/1000\n","48150/48150 [==============================] - 12s 254us/step - loss: 0.0232 - accuracy: 0.9925 - val_loss: 0.0222 - val_accuracy: 0.9929\n","Epoch 4/1000\n","48150/48150 [==============================] - 12s 254us/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 0.0217 - val_accuracy: 0.9930\n","Epoch 5/1000\n","48150/48150 [==============================] - 12s 253us/step - loss: 0.0218 - accuracy: 0.9927 - val_loss: 0.0214 - val_accuracy: 0.9930\n","Epoch 6/1000\n","48150/48150 [==============================] - 12s 254us/step - loss: 0.0214 - accuracy: 0.9928 - val_loss: 0.0211 - val_accuracy: 0.9931\n","Epoch 7/1000\n","48150/48150 [==============================] - 12s 253us/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.0209 - val_accuracy: 0.9931\n","Epoch 8/1000\n","48150/48150 [==============================] - 12s 254us/step - loss: 0.0207 - accuracy: 0.9930 - val_loss: 0.0207 - val_accuracy: 0.9932\n","Epoch 9/1000\n","48150/48150 [==============================] - 12s 254us/step - loss: 0.0203 - accuracy: 0.9930 - val_loss: 0.0206 - val_accuracy: 0.9932\n","Epoch 10/1000\n","48150/48150 [==============================] - 12s 253us/step - loss: 0.0200 - accuracy: 0.9931 - val_loss: 0.0206 - val_accuracy: 0.9932\n","Epoch 11/1000\n","48150/48150 [==============================] - 12s 254us/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.0205 - val_accuracy: 0.9932\n","Epoch 12/1000\n","48150/48150 [==============================] - 12s 253us/step - loss: 0.0195 - accuracy: 0.9932 - val_loss: 0.0204 - val_accuracy: 0.9932\n","Epoch 13/1000\n","48150/48150 [==============================] - 12s 254us/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 0.0208 - val_accuracy: 0.9932\n","Epoch 14/1000\n","48150/48150 [==============================] - 12s 254us/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 0.0203 - val_accuracy: 0.9933\n","Epoch 15/1000\n","48150/48150 [==============================] - 12s 253us/step - loss: 0.0188 - accuracy: 0.9934 - val_loss: 0.0204 - val_accuracy: 0.9933\n","Epoch 16/1000\n","48150/48150 [==============================] - 12s 253us/step - loss: 0.0186 - accuracy: 0.9934 - val_loss: 0.0205 - val_accuracy: 0.9932\n","Epoch 17/1000\n","48150/48150 [==============================] - 12s 253us/step - loss: 0.0184 - accuracy: 0.9935 - val_loss: 0.0204 - val_accuracy: 0.9933\n","Epoch 18/1000\n","48150/48150 [==============================] - 12s 253us/step - loss: 0.0182 - accuracy: 0.9935 - val_loss: 0.0204 - val_accuracy: 0.9932\n","Epoch 19/1000\n","48150/48150 [==============================] - 12s 254us/step - loss: 0.0180 - accuracy: 0.9936 - val_loss: 0.0205 - val_accuracy: 0.9932\n","Epoch 00019: early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f9325df84d0>"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"H-f87om6sPbj"},"source":["#pip install 'h5py==2.10.0' --force-reinstall"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EuauMPDKEDVw","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1622461741068,"user_tz":-330,"elapsed":110787,"user":{"displayName":"Bikku Kumar","photoUrl":"","userId":"05745485641699477877"}},"outputId":"54a7a829-d777-44b3-e0b9-51be286cbf50"},"source":["from matplotlib import pyplot as plt\n","\n","# Testing\n","def test_fun(file):\n","    X_test_new, Y_test_new = final_model(file)\n","    print(X_test_new.shape, Y_test_new.shape)\n","    Y_test_new = np.array(Y_test_new).astype(None)\n","\n","    fmax, tmax = 0.0, 0.0\n","    precisions, recalls = [], []\n","    for t in range(1, 101, 1):\n","        test_preds = model1.predict(X_test_new)\n","\n","        threshold = t / 100.0\n","        print(\"THRESHOLD IS =====> \", threshold)\n","        test_preds[test_preds>=threshold] = int(1)\n","        test_preds[test_preds<threshold] = int(0)\n","\n","        rec = recall(Y_test_new, test_preds)\n","        pre = precision(Y_test_new, test_preds)\n","        recalls.append(rec)\n","        precisions.append(pre)\n","\n","        f1 = f_score(Y_test_new, test_preds)*100\n","        f = 2 * pre * rec / (pre + rec)\n","        print('Recall: {0}'.format(rec*100), '     Precision: {0}'.format(pre*100),\n","              '     F1-score1: {0}'.format(f*100), '      F1-score2: {0}'.format(f1))\n","\n","        if fmax < f:\n","            fmax = f\n","            tmax = threshold\n","    \n","    precisions = np.array(precisions)\n","    recalls = np.array(recalls)\n","    sorted_index = np.argsort(recalls)\n","    recalls = recalls[sorted_index]\n","    precisions = precisions[sorted_index]\n","    aupr = np.trapz(precisions, recalls)\n","    print(f'AUPR: {aupr:0.3f}')\n","\n","    plt.figure()\n","    plt.plot(recalls, precisions, color='darkorange', lw=2, label=f'AUPR curve (area = {aupr:0.2f})')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Recall')\n","    plt.ylabel('Precision')\n","    plt.title('Area Under the Precision-Recall curve')\n","    plt.legend(loc=\"upper right\")\n","    plt.savefig(f'aupr.pdf')\n","\n","    return tmax\n","\n","th_set = test_fun(\"/content/gdrive/My Drive/Multi-Attn/CAFA3/bp/test_data_bp1.csv\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Extracting features based on LSTM model...... \n","(2392, 3992) (2392, 3992)\n","THRESHOLD IS =====>  0.01\n","Recall: 82.86543082114527      Precision: 10.945004339763981      F1-score1: 19.336068495965737       F1-score2: 17.77630740017112\n","THRESHOLD IS =====>  0.02\n","Recall: 78.30901411647088      Precision: 15.353016761177313      F1-score1: 25.6727212727642       F1-score2: 23.391854640233632\n","THRESHOLD IS =====>  0.03\n","Recall: 75.25035767724027      Precision: 18.65183877730619      F1-score1: 29.894030008337563       F1-score2: 27.126199043744986\n","THRESHOLD IS =====>  0.04\n","Recall: 73.03494525525002      Precision: 21.36742116418046      F1-score1: 33.062061771591026       F1-score2: 29.931758144284558\n","THRESHOLD IS =====>  0.05\n","Recall: 71.1791348027269      Precision: 23.677080011207977      F1-score1: 35.534078039241805       F1-score2: 32.079477298004235\n","THRESHOLD IS =====>  0.06\n","Recall: 69.5464231465817      Precision: 25.743833485703245      F1-score1: 37.577641204615276       F1-score2: 33.847450294151656\n","THRESHOLD IS =====>  0.07\n","Recall: 68.27256159658401      Precision: 27.695054361071836      F1-score1: 39.405215726549045       F1-score2: 35.427810639351684\n","THRESHOLD IS =====>  0.08\n","Recall: 67.00872700462325      Precision: 29.425977743457942      F1-score1: 40.893935738310574       F1-score2: 36.704828696208494\n","THRESHOLD IS =====>  0.09\n","Recall: 65.8228261995206      Precision: 31.0301349636075      F1-score1: 42.17715506327296       F1-score2: 37.79455050734756\n","THRESHOLD IS =====>  0.1\n","Recall: 64.75713363433857      Precision: 32.519027750105806      F1-score1: 43.29609630359273       F1-score2: 38.75242620265635\n","THRESHOLD IS =====>  0.11\n","Recall: 63.74982116200877      Precision: 33.879199520646324      F1-score1: 44.244895533135846       F1-score2: 39.54784722732668\n","THRESHOLD IS =====>  0.12\n","Recall: 62.78439384583978      Precision: 35.17212724303036      F1-score1: 45.08654788217694       F1-score2: 40.248375492137626\n","THRESHOLD IS =====>  0.13\n","Recall: 61.92762309668346      Precision: 36.43288376928737      F1-score1: 45.87617462085829       F1-score2: 40.9259116715661\n","THRESHOLD IS =====>  0.14\n","Recall: 61.111733757282686      Precision: 37.655222234949115      F1-score1: 46.598093313203115       F1-score2: 41.50643271662822\n","THRESHOLD IS =====>  0.15\n","Recall: 60.392199962031654      Precision: 38.789093975729635      F1-score1: 47.237914060655726       F1-score2: 42.01308557076722\n","THRESHOLD IS =====>  0.16\n","Recall: 59.71035468646255      Precision: 39.887692313462956      F1-score1: 47.82640478207651       F1-score2: 42.43692653549951\n","THRESHOLD IS =====>  0.17\n","Recall: 59.01989585681366      Precision: 40.942445796117816      F1-score1: 48.34658426470042       F1-score2: 42.799610613549675\n","THRESHOLD IS =====>  0.18\n","Recall: 58.32666565380297      Precision: 42.026923115699674      F1-score1: 48.85306690242537       F1-score2: 43.16942690831117\n","THRESHOLD IS =====>  0.19\n","Recall: 57.75373050820573      Precision: 43.064909450655854      F1-score1: 49.33927249541018       F1-score2: 43.51547496429622\n","THRESHOLD IS =====>  0.2\n","Recall: 57.147277786203865      Precision: 44.0127906459668      F1-score1: 49.72735214938267       F1-score2: 43.7905109914123\n","THRESHOLD IS =====>  0.21\n","Recall: 56.421053245127176      Precision: 44.900889289755106      F1-score1: 50.00605795726175       F1-score2: 43.95594116244776\n","THRESHOLD IS =====>  0.22\n","Recall: 55.82242271678022      Precision: 45.7727797274992      F1-score1: 50.300553518202115       F1-score2: 44.14018538493607\n","THRESHOLD IS =====>  0.23\n","Recall: 55.20792088735915      Precision: 46.605376717539066      F1-score1: 50.54322001694366       F1-score2: 44.26189992667859\n","THRESHOLD IS =====>  0.24\n","Recall: 54.53078063492619      Precision: 47.40902173362749      F1-score1: 50.72112961188916       F1-score2: 44.36444977874432\n","THRESHOLD IS =====>  0.25\n","Recall: 53.891935273345126      Precision: 48.26600725595905      F1-score1: 50.92405885513617       F1-score2: 44.44116987191697\n","THRESHOLD IS =====>  0.26\n","Recall: 53.296335126149586      Precision: 49.04443204258486      F1-score1: 51.08205768877265       F1-score2: 44.51818953497765\n","THRESHOLD IS =====>  0.27\n","Recall: 52.690842390209056      Precision: 49.82861716285064      F1-score1: 51.21977476073166       F1-score2: 44.551965904870436\n","THRESHOLD IS =====>  0.28\n","Recall: 52.11047728481206      Precision: 50.63412164814308      F1-score1: 51.36169245652981       F1-score2: 44.57263390601199\n","THRESHOLD IS =====>  0.29\n","Recall: 51.598133603264806      Precision: 51.42417930004495      F1-score1: 51.51100958978218       F1-score2: 44.62695742589368\n","THRESHOLD IS =====>  0.3\n","Recall: 51.115085727584955      Precision: 52.21916650003523      F1-score1: 51.66122780649274       F1-score2: 44.64739420254346\n","THRESHOLD IS =====>  0.31\n","Recall: 50.62854819552943      Precision: 52.99952871741746      F1-score1: 51.78691478110168       F1-score2: 44.682168862550135\n","THRESHOLD IS =====>  0.32\n","Recall: 50.04241496089137      Precision: 53.692304435165426      F1-score1: 51.803149309973286       F1-score2: 44.59819914047953\n","THRESHOLD IS =====>  0.33\n","Recall: 49.481388057409234      Precision: 54.43958777194907      F1-score1: 51.84220696026611       F1-score2: 44.52332885332606\n","THRESHOLD IS =====>  0.34\n","Recall: 48.9360085628328      Precision: 55.02251043436567      F1-score1: 51.80108504310718       F1-score2: 44.37890958870997\n","THRESHOLD IS =====>  0.35\n","Recall: 48.44660073452436      Precision: 55.74601169112474      F1-score1: 51.84061917766475       F1-score2: 44.30946444255775\n","THRESHOLD IS =====>  0.36\n","Recall: 47.8939876061448      Precision: 56.40160901653387      F1-score1: 51.80080560787762       F1-score2: 44.16334646187406\n","THRESHOLD IS =====>  0.37\n","Recall: 47.3326333324056      Precision: 57.054968761657186      F1-score1: 51.74104705947592       F1-score2: 43.992765373073475\n","THRESHOLD IS =====>  0.38\n","Recall: 46.87528801721164      Precision: 57.6586555553306      F1-score1: 51.7107839515442       F1-score2: 43.8860447484817\n","THRESHOLD IS =====>  0.39\n","Recall: 46.371397513295406      Precision: 58.431684935506766      F1-score1: 51.70761825330239       F1-score2: 43.72336252000486\n","THRESHOLD IS =====>  0.4\n","Recall: 45.90697723263757      Precision: 59.04384006870258      F1-score1: 51.653227510917375       F1-score2: 43.580077595310215\n","THRESHOLD IS =====>  0.41\n","Recall: 45.3938557594362      Precision: 59.63380525186675      F1-score1: 51.548484045516794       F1-score2: 43.39598832703754\n","THRESHOLD IS =====>  0.42\n","Recall: 44.903112956925675      Precision: 60.25884871892432      F1-score1: 51.45985958345874       F1-score2: 43.23114013765666\n","THRESHOLD IS =====>  0.43\n","Recall: 44.42927775121374      Precision: 60.91841883597151      F1-score1: 51.38339875116703       F1-score2: 43.031751555052125\n","THRESHOLD IS =====>  0.44\n","Recall: 43.879733512773235      Precision: 61.620461654646085      F1-score1: 51.258472689061904       F1-score2: 42.80442006466122\n","THRESHOLD IS =====>  0.45\n","Recall: 43.37483430349553      Precision: 62.24264365654088      F1-score1: 51.12343917614688       F1-score2: 42.56492543957102\n","THRESHOLD IS =====>  0.46\n","Recall: 42.928602394583514      Precision: 62.88828837351805      F1-score1: 51.025999861951924       F1-score2: 42.34677751120846\n","THRESHOLD IS =====>  0.47\n","Recall: 42.40636192293314      Precision: 63.51019947684495      F1-score1: 50.85581460008404       F1-score2: 42.06323028400891\n","THRESHOLD IS =====>  0.48\n","Recall: 41.93874793778991      Precision: 64.16880395980348      F1-score1: 50.725122700728164       F1-score2: 41.853618851328385\n","THRESHOLD IS =====>  0.49\n","Recall: 41.43773176553169      Precision: 64.67742902618087      F1-score1: 50.51278130806747       F1-score2: 41.59088240370906\n","THRESHOLD IS =====>  0.5\n","Recall: 40.89533445229991      Precision: 65.28103497146111      F1-score1: 50.287832839625125       F1-score2: 41.29671125789215\n","THRESHOLD IS =====>  0.51\n","Recall: 40.43390243513793      Precision: 65.82752683890057      F1-score1: 50.09651791688859       F1-score2: 41.03516797393406\n","THRESHOLD IS =====>  0.52\n","Recall: 39.93565252564677      Precision: 66.41530097507015      F1-score1: 49.87897700623382       F1-score2: 40.70923128802863\n","THRESHOLD IS =====>  0.53\n","Recall: 39.48225534241305      Precision: 67.08983711806923      F1-score1: 49.71016368020974       F1-score2: 40.445470211501686\n","THRESHOLD IS =====>  0.54\n","Recall: 38.96761681934      Precision: 67.70819000359025      F1-score1: 49.46626385438005       F1-score2: 40.154308417764476\n","THRESHOLD IS =====>  0.55\n","Recall: 38.48823813034185      Precision: 68.38936855843761      F1-score1: 49.25608617576203       F1-score2: 39.88038662245371\n","THRESHOLD IS =====>  0.56\n","Recall: 37.96665409383824      Precision: 69.13296441776461      F1-score1: 49.01506434864731       F1-score2: 39.578412303789115\n","THRESHOLD IS =====>  0.57\n","Recall: 37.421413467817445      Precision: 69.66107195652111      F1-score1: 48.687995351737726       F1-score2: 39.19411261479535\n","THRESHOLD IS =====>  0.58\n","Recall: 36.92001714338894      Precision: 70.2251709954268      F1-score1: 48.396284743828055       F1-score2: 38.86194743838852\n","THRESHOLD IS =====>  0.59\n","Recall: 36.45517626962077      Precision: 70.87093823130485      F1-score1: 48.14508673177285       F1-score2: 38.57308640768796\n","THRESHOLD IS =====>  0.6\n","Recall: 35.9364879594224      Precision: 71.69352168665756      F1-score1: 47.87537207017233       F1-score2: 38.23291119378968\n","THRESHOLD IS =====>  0.61\n","Recall: 35.420674286064816      Precision: 72.3823002288578      F1-score1: 47.565104618289155       F1-score2: 37.839309568498386\n","THRESHOLD IS =====>  0.62\n","Recall: 34.93204619778315      Precision: 73.02794786400611      F1-score1: 47.25853628807586       F1-score2: 37.50468138335223\n","THRESHOLD IS =====>  0.63\n","Recall: 34.5039696832114      Precision: 73.59752906797578      F1-score1: 46.981900178193754       F1-score2: 37.210010657405604\n","THRESHOLD IS =====>  0.64\n","Recall: 34.02567200725571      Precision: 74.18902065881011      F1-score1: 46.65413210137547       F1-score2: 36.84647810962243\n","THRESHOLD IS =====>  0.65\n","Recall: 33.50150651441993      Precision: 74.85491944164241      F1-score1: 46.28710386456334       F1-score2: 36.46793043298503\n","THRESHOLD IS =====>  0.66\n","Recall: 33.01273793245323      Precision: 75.65215033491593      F1-score1: 45.96672674779899       F1-score2: 36.13247126294859\n","THRESHOLD IS =====>  0.67\n","Recall: 32.4652844827547      Precision: 76.49941204865685      F1-score1: 45.584950979185635       F1-score2: 35.74990726511468\n","THRESHOLD IS =====>  0.68\n","Recall: 31.91564719149971      Precision: 77.11810354434243      F1-score1: 45.1470149048022       F1-score2: 35.32229817648592\n","THRESHOLD IS =====>  0.69\n","Recall: 31.43500009114591      Precision: 77.73100722086845      F1-score1: 44.76621027439453       F1-score2: 34.957786729533005\n","THRESHOLD IS =====>  0.7\n","Recall: 30.885589881164634      Precision: 78.27687126785519      F1-score1: 44.29411571912701       F1-score2: 34.50159585913647\n","THRESHOLD IS =====>  0.71\n","Recall: 30.33137385878821      Precision: 78.90762788344249      F1-score1: 43.819088850526896       F1-score2: 34.07626809362673\n","THRESHOLD IS =====>  0.72\n","Recall: 29.7896683235855      Precision: 79.63202639926085      F1-score1: 43.35907354346042       F1-score2: 33.61240232847326\n","THRESHOLD IS =====>  0.73\n","Recall: 29.28079788747246      Precision: 80.16626689714977      F1-score1: 42.89438484308126       F1-score2: 33.14980116760925\n","THRESHOLD IS =====>  0.74\n","Recall: 28.707464839140467      Precision: 80.77610677581062      F1-score1: 42.36027763625814       F1-score2: 32.66539165996682\n","THRESHOLD IS =====>  0.75\n","Recall: 28.13370487312249      Precision: 81.43658758890606      F1-score1: 41.81996542346468       F1-score2: 32.18640112003801\n","THRESHOLD IS =====>  0.76\n","Recall: 27.65673244917212      Precision: 82.08099310367797      F1-score1: 41.373047491083256       F1-score2: 31.813823941707525\n","THRESHOLD IS =====>  0.77\n","Recall: 27.059618703855655      Precision: 82.55197801280593      F1-score1: 40.75891812888901       F1-score2: 31.269918534906644\n","THRESHOLD IS =====>  0.78\n","Recall: 26.42062671944293      Precision: 83.14691354944333      F1-score1: 40.099349868994985       F1-score2: 30.695111274546385\n","THRESHOLD IS =====>  0.79\n","Recall: 25.803568571851354      Precision: 83.84429059035216      F1-score1: 39.46236466698207       F1-score2: 30.16809595426325\n","THRESHOLD IS =====>  0.8\n","Recall: 25.193090327409163      Precision: 84.40566022378343      F1-score1: 38.80408146020135       F1-score2: 29.627043883992815\n","THRESHOLD IS =====>  0.81\n","Recall: 24.6201859200643      Precision: 85.04774952256604      F1-score1: 38.186027609209354       F1-score2: 29.11053986257758\n","THRESHOLD IS =====>  0.82\n","Recall: 24.098937352943413      Precision: 85.75409696188446      F1-score1: 37.624497554069706       F1-score2: 28.679969779208044\n","THRESHOLD IS =====>  0.83\n","Recall: 23.380038898273085      Precision: 86.25478666725256      F1-score1: 36.788315337580805       F1-score2: 28.008589031330917\n","THRESHOLD IS =====>  0.84\n","Recall: 22.7229434073217      Precision: 86.6894460455009      F1-score1: 36.00761095439485       F1-score2: 27.40817433830456\n","THRESHOLD IS =====>  0.85\n","Recall: 22.04326339445161      Precision: 87.26399078205304      F1-score1: 35.19589158380419       F1-score2: 26.79780690898315\n","THRESHOLD IS =====>  0.86\n","Recall: 21.409539424656305      Precision: 87.79184920004587      F1-score1: 34.4241603569991       F1-score2: 26.22423454980862\n","THRESHOLD IS =====>  0.87\n","Recall: 20.734837134442582      Precision: 88.27793484870348      F1-score1: 33.58191096976772       F1-score2: 25.582117288622246\n","THRESHOLD IS =====>  0.88\n","Recall: 20.034176666280313      Precision: 88.81805228449834      F1-score1: 32.693800903740396       F1-score2: 24.94220815334738\n","THRESHOLD IS =====>  0.89\n","Recall: 19.315325030167767      Precision: 89.44094966356866      F1-score1: 31.76977178785619       F1-score2: 24.259529346043742\n","THRESHOLD IS =====>  0.9\n","Recall: 18.649229517907784      Precision: 90.06103994133991      F1-score1: 30.899914292221116       F1-score2: 23.62805106292551\n","THRESHOLD IS =====>  0.91\n","Recall: 17.86809009189675      Precision: 90.64369779091848      F1-score1: 29.851683213253754       F1-score2: 22.90351755797963\n","THRESHOLD IS =====>  0.92\n","Recall: 17.172666196031734      Precision: 91.33944944612242      F1-score1: 28.90998607086853       F1-score2: 22.238320355830467\n","THRESHOLD IS =====>  0.93\n","Recall: 16.418429834004566      Precision: 91.88984982533927      F1-score1: 27.859126865642057       F1-score2: 21.511825148802668\n","THRESHOLD IS =====>  0.94\n","Recall: 15.58824643895763      Precision: 92.54519569380183      F1-score1: 26.682167676589604       F1-score2: 20.67025400721848\n","THRESHOLD IS =====>  0.95\n","Recall: 14.747768873141329      Precision: 93.14600256393678      F1-score1: 25.463855771713128       F1-score2: 19.832683158830296\n","THRESHOLD IS =====>  0.96\n","Recall: 13.881851920057809      Precision: 93.89113308986478      F1-score1: 24.187560658915423       F1-score2: 18.987714776007522\n","THRESHOLD IS =====>  0.97\n","Recall: 12.90173935479231      Precision: 94.7196757714097      F1-score1: 22.71013751566325       F1-score2: 18.014290444844093\n","THRESHOLD IS =====>  0.98\n","Recall: 11.792651970412283      Precision: 95.73018748582228      F1-score1: 20.99856718427019       F1-score2: 16.896659673649076\n","THRESHOLD IS =====>  0.99\n","Recall: 10.316581687674638      Precision: 97.26346557019421      F1-score1: 18.654509146589792       F1-score2: 15.442846113548022\n","THRESHOLD IS =====>  1.0\n","Recall: 0.607294656192838      Precision: 99.3371212121212      F1-score1: 1.2072090741555317       F1-score2: 1.0196187133033079\n","AUPR: 0.505\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"m3JKiOQd7oAY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622461763511,"user_tz":-330,"elapsed":22451,"user":{"displayName":"Bikku Kumar","photoUrl":"","userId":"05745485641699477877"}},"outputId":"fc4ee8da-5a2a-4d35-e5c7-e9d8edb6231e"},"source":["# Testing\n","def test_fun1(file):\n","    X_test_new, Y_test_new = final_model(file)\n","    print(X_test_new.shape, Y_test_new.shape)\n","    test_preds = model1.predict(X_test_new)\n","    Y_test_new = np.array(Y_test_new).astype(None)\n","    test_preds[test_preds>=th_set] = int(1)\n","    test_preds[test_preds<th_set] = int(0)\n","    rec = recall(Y_test_new, test_preds)*100\n","    pre = precision(Y_test_new, test_preds)*100\n","    f1 = f_score(Y_test_new, test_preds)*100\n","    print('      Recall: {0}'.format(rec),  '       Precision: {0}'.format(pre),  '       F1-score: {0}'.format(f1))\n","\n","test_fun1(\"testData200.csv\")\n","test_fun1(\"testData500.csv\")\n","test_fun1(\"testData1000.csv\")\n","test_fun1(\"testData16000.csv\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Extracting features based on LSTM model...... \n","(334, 3992) (334, 3992)\n","      Recall: 39.99452083004831        Precision: 37.997636740357386        F1-score: 31.67493222735473\n","Extracting features based on LSTM model...... \n","(1315, 3992) (1315, 3992)\n","      Recall: 54.81165788030155        Precision: 58.30189660518129        F1-score: 50.08498693095653\n","Extracting features based on LSTM model...... \n","(540, 3992) (540, 3992)\n","      Recall: 46.60144450416361        Precision: 55.90681932103535        F1-score: 42.779240125570645\n","Extracting features based on LSTM model...... \n","(203, 3992) (203, 3992)\n","      Recall: 38.222660745033764        Precision: 52.569491675124965        F1-score: 34.27501365124864\n"],"name":"stdout"}]}]}